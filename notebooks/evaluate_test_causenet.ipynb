{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ca3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_path = \"..\"\n",
    "sys.path.append(os.path.abspath(parent_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70b8817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300249/3829021575.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from health_causenet import constants\n",
    "import json\n",
    "import pathlib\n",
    "from tqdm.autonotebook import tqdm\n",
    "import operator\n",
    "from nltk import agreement\n",
    "import nltk\n",
    "import sklearn.metrics\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bedaa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_mean_threshold_combiner(cause, effect, p):\n",
    "    if p == 0:\n",
    "        return np.sqrt(cause * effect)\n",
    "    if p == float(\"inf\"):\n",
    "        return np.maximum(cause, effect)\n",
    "    if p == -float(\"inf\"):\n",
    "        return np.minimum(cause, effect)\n",
    "    return ((cause ** p + effect ** p) / 2) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288046ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>support</th>\n",
       "      <th>count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cause_origin</th>\n",
       "      <th>effect_origin</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>medical_score-cause-term_domain_specificity-pubmed-(1, 1)-1</th>\n",
       "      <th>medical_score-effect-term_domain_specificity-pubmed-(1, 1)-1</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_score-effect-discriminative_weight-pubmed-(1, 3)-neg_1</th>\n",
       "      <th>medical_score-effect-discriminative_weight-textbook-(1, 3)-neg_1</th>\n",
       "      <th>medical_score-effect-discriminative_weight-pubmed_central-(1, 3)-neg_1</th>\n",
       "      <th>medical_score-effect-discriminative_weight-encyclopedia-(1, 3)-neg_1</th>\n",
       "      <th>medical_score-effect-discriminative_weight-pubmed-(1, 3)-0</th>\n",
       "      <th>medical_score-effect-discriminative_weight-textbook-(1, 3)-0</th>\n",
       "      <th>medical_score-effect-discriminative_weight-pubmed_central-(1, 3)-0</th>\n",
       "      <th>medical_score-effect-discriminative_weight-encyclopedia-(1, 3)-0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>manual_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>material</td>\n",
       "      <td>death</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>random_support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868993</td>\n",
       "      <td>0.580596</td>\n",
       "      <td>...</td>\n",
       "      <td>65.054640</td>\n",
       "      <td>21.417447</td>\n",
       "      <td>57.204029</td>\n",
       "      <td>18.803064</td>\n",
       "      <td>65.054640</td>\n",
       "      <td>21.417447</td>\n",
       "      <td>57.204029</td>\n",
       "      <td>18.803064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lack of foresight</td>\n",
       "      <td>mesothelioma diagnosis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>random_support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739327</td>\n",
       "      <td>3.534990</td>\n",
       "      <td>...</td>\n",
       "      <td>356.915862</td>\n",
       "      <td>10.842975</td>\n",
       "      <td>320.990466</td>\n",
       "      <td>171.703867</td>\n",
       "      <td>367.002471</td>\n",
       "      <td>33.842025</td>\n",
       "      <td>328.022429</td>\n",
       "      <td>178.860266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asbestos</td>\n",
       "      <td>damage to the lungs</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>random_support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342630</td>\n",
       "      <td>1.236596</td>\n",
       "      <td>...</td>\n",
       "      <td>81.225197</td>\n",
       "      <td>16.476861</td>\n",
       "      <td>86.053039</td>\n",
       "      <td>27.965749</td>\n",
       "      <td>107.961097</td>\n",
       "      <td>22.650537</td>\n",
       "      <td>107.075274</td>\n",
       "      <td>75.998875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lactic acidosis</td>\n",
       "      <td>metabolic acidosis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>random_support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.205030</td>\n",
       "      <td>3.650117</td>\n",
       "      <td>...</td>\n",
       "      <td>435.895634</td>\n",
       "      <td>49.679707</td>\n",
       "      <td>376.593515</td>\n",
       "      <td>238.035163</td>\n",
       "      <td>436.969875</td>\n",
       "      <td>58.095478</td>\n",
       "      <td>379.705844</td>\n",
       "      <td>247.855855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embolism</td>\n",
       "      <td>condition</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>random_support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.311735</td>\n",
       "      <td>1.437818</td>\n",
       "      <td>...</td>\n",
       "      <td>174.290807</td>\n",
       "      <td>64.784479</td>\n",
       "      <td>204.719556</td>\n",
       "      <td>179.319512</td>\n",
       "      <td>174.290807</td>\n",
       "      <td>64.784479</td>\n",
       "      <td>204.719556</td>\n",
       "      <td>179.319512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>termination of the company 's pexelizumab prog...</td>\n",
       "      <td>non-recurrence of costs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The decrease in R&amp;D expenses in 2007 reflected...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>medical neglect of a patient at another nursin...</td>\n",
       "      <td>abuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.783367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>That dispute arose when HRS found indications ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>disorder</td>\n",
       "      <td>shoulder contractions</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.281044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is a disorder that causes severe neck and...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>car accidents</td>\n",
       "      <td>rib fracture in a child</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A rib fracture in a child is mainly caused by ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>internet marketing breach</td>\n",
       "      <td>refund of its hitch database</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Also in september 2006, opposite loreal sublim...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  cause  \\\n",
       "0                                              material   \n",
       "1                                     lack of foresight   \n",
       "2                                              asbestos   \n",
       "3                                       lactic acidosis   \n",
       "4                                              embolism   \n",
       "...                                                 ...   \n",
       "2995  termination of the company 's pexelizumab prog...   \n",
       "2996  medical neglect of a patient at another nursin...   \n",
       "2997                                           disorder   \n",
       "2998                                      car accidents   \n",
       "2999                          internet marketing breach   \n",
       "\n",
       "                            effect  support  count         dataset  \\\n",
       "0                            death      3.0    4.0  random_support   \n",
       "1           mesothelioma diagnosis      2.0    2.0  random_support   \n",
       "2              damage to the lungs      2.0    2.0  random_support   \n",
       "3               metabolic acidosis      2.0    4.0  random_support   \n",
       "4                        condition      2.0    3.0  random_support   \n",
       "...                            ...      ...    ...             ...   \n",
       "2995       non-recurrence of costs      1.0    3.0        sentence   \n",
       "2996                         abuse      1.0    2.0        sentence   \n",
       "2997         shoulder contractions      1.0    8.0        sentence   \n",
       "2998       rib fracture in a child      1.0    1.0        sentence   \n",
       "2999  refund of its hitch database      1.0    1.0        sentence   \n",
       "\n",
       "     cause_origin effect_origin  evaluation  \\\n",
       "0             NaN           NaN           0   \n",
       "1             NaN           NaN           1   \n",
       "2             NaN           NaN           1   \n",
       "3             NaN           NaN           1   \n",
       "4             NaN           NaN           1   \n",
       "...           ...           ...         ...   \n",
       "2995          NaN           NaN           0   \n",
       "2996          NaN           NaN           0   \n",
       "2997          NaN           NaN           1   \n",
       "2998          NaN           NaN           1   \n",
       "2999          NaN           NaN           0   \n",
       "\n",
       "      medical_score-cause-term_domain_specificity-pubmed-(1, 1)-1  \\\n",
       "0                                              0.868993             \n",
       "1                                              0.739327             \n",
       "2                                              1.342630             \n",
       "3                                              3.205030             \n",
       "4                                              3.311735             \n",
       "...                                                 ...             \n",
       "2995                                           0.765124             \n",
       "2996                                           0.783367             \n",
       "2997                                           1.281044             \n",
       "2998                                           0.831662             \n",
       "2999                                           0.568601             \n",
       "\n",
       "      medical_score-effect-term_domain_specificity-pubmed-(1, 1)-1  ...  \\\n",
       "0                                              0.580596             ...   \n",
       "1                                              3.534990             ...   \n",
       "2                                              1.236596             ...   \n",
       "3                                              3.650117             ...   \n",
       "4                                              1.437818             ...   \n",
       "...                                                 ...             ...   \n",
       "2995                                           0.000000             ...   \n",
       "2996                                           0.000000             ...   \n",
       "2997                                           0.000000             ...   \n",
       "2998                                           0.000000             ...   \n",
       "2999                                           0.000000             ...   \n",
       "\n",
       "      medical_score-effect-discriminative_weight-pubmed-(1, 3)-neg_1  \\\n",
       "0                                             65.054640                \n",
       "1                                            356.915862                \n",
       "2                                             81.225197                \n",
       "3                                            435.895634                \n",
       "4                                            174.290807                \n",
       "...                                                 ...                \n",
       "2995                                           0.000000                \n",
       "2996                                           0.000000                \n",
       "2997                                           0.000000                \n",
       "2998                                           0.000000                \n",
       "2999                                           0.000000                \n",
       "\n",
       "      medical_score-effect-discriminative_weight-textbook-(1, 3)-neg_1  \\\n",
       "0                                             21.417447                  \n",
       "1                                             10.842975                  \n",
       "2                                             16.476861                  \n",
       "3                                             49.679707                  \n",
       "4                                             64.784479                  \n",
       "...                                                 ...                  \n",
       "2995                                           0.000000                  \n",
       "2996                                           0.000000                  \n",
       "2997                                           0.000000                  \n",
       "2998                                           0.000000                  \n",
       "2999                                           0.000000                  \n",
       "\n",
       "      medical_score-effect-discriminative_weight-pubmed_central-(1, 3)-neg_1  \\\n",
       "0                                             57.204029                        \n",
       "1                                            320.990466                        \n",
       "2                                             86.053039                        \n",
       "3                                            376.593515                        \n",
       "4                                            204.719556                        \n",
       "...                                                 ...                        \n",
       "2995                                           0.000000                        \n",
       "2996                                           0.000000                        \n",
       "2997                                           0.000000                        \n",
       "2998                                           0.000000                        \n",
       "2999                                           0.000000                        \n",
       "\n",
       "      medical_score-effect-discriminative_weight-encyclopedia-(1, 3)-neg_1  \\\n",
       "0                                             18.803064                      \n",
       "1                                            171.703867                      \n",
       "2                                             27.965749                      \n",
       "3                                            238.035163                      \n",
       "4                                            179.319512                      \n",
       "...                                                 ...                      \n",
       "2995                                           0.000000                      \n",
       "2996                                           0.000000                      \n",
       "2997                                           0.000000                      \n",
       "2998                                           0.000000                      \n",
       "2999                                           0.000000                      \n",
       "\n",
       "      medical_score-effect-discriminative_weight-pubmed-(1, 3)-0  \\\n",
       "0                                             65.054640            \n",
       "1                                            367.002471            \n",
       "2                                            107.961097            \n",
       "3                                            436.969875            \n",
       "4                                            174.290807            \n",
       "...                                                 ...            \n",
       "2995                                           0.000000            \n",
       "2996                                           0.000000            \n",
       "2997                                           0.000000            \n",
       "2998                                           0.000000            \n",
       "2999                                           0.000000            \n",
       "\n",
       "      medical_score-effect-discriminative_weight-textbook-(1, 3)-0  \\\n",
       "0                                             21.417447              \n",
       "1                                             33.842025              \n",
       "2                                             22.650537              \n",
       "3                                             58.095478              \n",
       "4                                             64.784479              \n",
       "...                                                 ...              \n",
       "2995                                           0.000000              \n",
       "2996                                           0.000000              \n",
       "2997                                           0.000000              \n",
       "2998                                           0.000000              \n",
       "2999                                           0.000000              \n",
       "\n",
       "      medical_score-effect-discriminative_weight-pubmed_central-(1, 3)-0  \\\n",
       "0                                             57.204029                    \n",
       "1                                            328.022429                    \n",
       "2                                            107.075274                    \n",
       "3                                            379.705844                    \n",
       "4                                            204.719556                    \n",
       "...                                                 ...                    \n",
       "2995                                           0.000000                    \n",
       "2996                                           0.000000                    \n",
       "2997                                           0.000000                    \n",
       "2998                                           0.000000                    \n",
       "2999                                           0.000000                    \n",
       "\n",
       "      medical_score-effect-discriminative_weight-encyclopedia-(1, 3)-0  \\\n",
       "0                                             18.803064                  \n",
       "1                                            178.860266                  \n",
       "2                                             75.998875                  \n",
       "3                                            247.855855                  \n",
       "4                                            179.319512                  \n",
       "...                                                 ...                  \n",
       "2995                                           0.000000                  \n",
       "2996                                           0.000000                  \n",
       "2997                                           0.000000                  \n",
       "2998                                           0.000000                  \n",
       "2999                                           0.000000                  \n",
       "\n",
       "                                               sentence  manual_evaluation  \n",
       "0                                                   NaN                NaN  \n",
       "1                                                   NaN                NaN  \n",
       "2                                                   NaN                NaN  \n",
       "3                                                   NaN                NaN  \n",
       "4                                                   NaN                NaN  \n",
       "...                                                 ...                ...  \n",
       "2995  The decrease in R&D expenses in 2007 reflected...                0.0  \n",
       "2996  That dispute arose when HRS found indications ...                0.0  \n",
       "2997  This is a disorder that causes severe neck and...                1.0  \n",
       "2998  A rib fracture in a child is mainly caused by ...                1.0  \n",
       "2999  Also in september 2006, opposite loreal sublim...                0.0  \n",
       "\n",
       "[3000 rows x 938 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet = pd.read_pickle(os.path.join(constants.BASE_PATH, \"test_causenet.pkl\"))\n",
    "test_causenet_predictions = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_predictions.pkl\")\n",
    ")\n",
    "test_causenet = test_causenet.merge(\n",
    "    test_causenet_predictions, on=[\"cause\", \"effect\", \"dataset\"], how=\"left\"\n",
    ")\n",
    "\n",
    "sentence_test_causenet = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"sentence_test_causenet.pkl\")\n",
    ")\n",
    "sentence_test_causenet_predictions = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"sentence_test_causenet_predictions.pkl\")\n",
    ")\n",
    "sentence_test_causenet = sentence_test_causenet.merge(\n",
    "    sentence_test_causenet_predictions,\n",
    "    on=[\"cause\", \"effect\", \"dataset\", \"sentence\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "assert (\n",
    "    not test_causenet.loc[:, test_causenet.columns.str.startswith(\"medical_score\")]\n",
    "    .isna()\n",
    "    .any()\n",
    "    .any()\n",
    ")\n",
    "assert (\n",
    "    not sentence_test_causenet.loc[\n",
    "        :, sentence_test_causenet.columns.str.startswith(\"medical_score\")\n",
    "    ]\n",
    "    .isna()\n",
    "    .any()\n",
    "    .any()\n",
    ")\n",
    "\n",
    "test_causenet = test_causenet.loc[test_causenet.dataset.isin([\"random_full\", \"random_support\"])]\n",
    "sentence_test_causenet = sentence_test_causenet.loc[sentence_test_causenet.dataset == \"random_full\"]\n",
    "sentence_test_causenet[\"dataset\"] = \"sentence\"\n",
    "test_causenet = pd.concat([test_causenet, sentence_test_causenet]).reset_index(drop=True)\n",
    "test_causenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f79f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_full</th>\n",
       "      <td>214</td>\n",
       "      <td>0.214</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_support</th>\n",
       "      <td>503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>214</td>\n",
       "      <td>0.214</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum   mean  size\n",
       "dataset                         \n",
       "random_full     214  0.214  1000\n",
       "random_support  503  0.503  1000\n",
       "sentence        214  0.214  1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet.groupby(\"dataset\").evaluation.agg([\"sum\", \"mean\", \"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c69e33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases\n",
      "random_full 3.6\n",
      "random_support 1.7\n",
      "sentence 3.6\n",
      "-------------------\n",
      "sentences\n",
      "sentence 30.31\n"
     ]
    }
   ],
   "source": [
    "num_words = (\n",
    "    test_causenet.apply(\n",
    "        lambda x: pd.Series(x[[\"cause\", \"effect\"]].values.ravel()).map(\n",
    "            lambda y: len(nltk.tokenize.word_tokenize(y))\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    .sum(axis=1)\n",
    "    .groupby(test_causenet.dataset)\n",
    "    .mean()\n",
    "    / 2\n",
    ")\n",
    "print(\"phrases\")\n",
    "for dataset, word_count in num_words.round(2).to_dict().items():\n",
    "    print(dataset, word_count)\n",
    "print(\"-------------------\")\n",
    "print(\"sentences\")\n",
    "num_words = (\n",
    "    sentence_test_causenet.apply(\n",
    "        lambda x: pd.Series(x[[\"sentence\"]].values.ravel()).map(\n",
    "            lambda y: len(nltk.tokenize.word_tokenize(y))\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    .sum(axis=1)\n",
    "    .groupby(sentence_test_causenet.dataset)\n",
    "    .mean()\n",
    ")\n",
    "for dataset, word_count in num_words.round(2).to_dict().items():\n",
    "    print(dataset, word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c97995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa 0.7578139040430347\n",
      "fleiss 0.7546012269938649\n",
      "alpha 0.7541118421052632\n",
      "scotts 0.7532894736842104\n"
     ]
    }
   ],
   "source": [
    "with open(constants.MANUAL_EVALUATION_PATH, \"r\") as file:\n",
    "    manual_eval_dict = json.load(file)\n",
    "data = []\n",
    "for key, value in manual_eval_dict.items():\n",
    "    cause, effect = key.split(\"->\")\n",
    "    data.append({\"cause\": cause, \"effect\": effect, \"evaluation\": value})\n",
    "evals = pd.DataFrame(data).rename({\"evaluation\": \"rater\"}, axis=1)\n",
    "evals = evals.set_index([\"cause\", \"effect\"])\n",
    "evals = evals.add_suffix(\"-0\")\n",
    "\n",
    "iterator = enumerate(pathlib.Path(constants.BASE_PATH).glob(\"agreement_relations*.csv\"))\n",
    "\n",
    "for idx, path in iterator:\n",
    "    other_eval = pd.read_csv(path, index_col=0).set_index([\"cause\", \"effect\"])\n",
    "    other_eval = other_eval.rename({\"health-related\": \"rater\"}, axis=1)\n",
    "    other_eval = other_eval.add_suffix(f\"-{idx + 1}\")\n",
    "    evals = evals.join(other_eval, how=\"inner\")\n",
    "\n",
    "rating_data = evals.reset_index(drop=True).stack().swaplevel().reset_index().values\n",
    "rating_data = list(tuple(row) for row in rating_data)\n",
    "\n",
    "rating_task = agreement.AnnotationTask(data=rating_data)\n",
    "print(\"kappa \" + str(rating_task.kappa()))\n",
    "print(\"fleiss \" + str(rating_task.multi_kappa()))\n",
    "print(\"alpha \" + str(rating_task.alpha()))\n",
    "print(\"scotts \" + str(rating_task.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ac6d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa 0.14326511185149934\n",
      "fleiss 0.14326511185149934\n",
      "alpha 0.14714285714285713\n",
      "scotts 0.14285714285714296\n"
     ]
    }
   ],
   "source": [
    "evals = (\n",
    "    test_causenet.loc[test_causenet.dataset == \"practitioner_full\"]\n",
    "    .set_index([\"cause\", \"effect\"])\n",
    "    .evaluation\n",
    ")\n",
    "evals.name = \"rater-0\"\n",
    "evals = evals.to_frame()\n",
    "other_eval = pd.read_csv(\n",
    "    pathlib.Path(constants.BASE_PATH).joinpath(\"practitioner_other.csv\"), index_col=0\n",
    ")\n",
    "other_eval = other_eval.set_index([\"cause\", \"effect\"])\n",
    "other_eval = other_eval.loc[~other_eval.label.isna()]\n",
    "other_eval.label = other_eval.label.astype(int)\n",
    "other_eval = other_eval.rename({\"label\": \"rater-1\"}, axis=1)\n",
    "evals = evals.join(other_eval, how=\"inner\")\n",
    "\n",
    "rating_data = evals.reset_index(drop=True).stack().swaplevel().reset_index().values\n",
    "rating_data = list(tuple(row) for row in rating_data)\n",
    "\n",
    "rating_task = agreement.AnnotationTask(data=rating_data)\n",
    "print(\"kappa \" + str(rating_task.kappa()))\n",
    "print(\"fleiss \" + str(rating_task.multi_kappa()))\n",
    "print(\"alpha \" + str(rating_task.alpha()))\n",
    "print(\"scotts \" + str(rating_task.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0440ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rater-0</th>\n",
       "      <th>rater-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>respiratory illness</th>\n",
       "      <th>carbon dioxide on levels of pollutants</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical events</th>\n",
       "      <th>disorder</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viral replication in the cns</th>\n",
       "      <th>ability to detect features of the csf viral population</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fava beans</th>\n",
       "      <th>severe hypertensive reactions</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single processing nodes</th>\n",
       "      <th>problems</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problems</th>\n",
       "      <th>poor treatment</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor treatment</th>\n",
       "      <th>problems</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical activity</th>\n",
       "      <th>damage</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exposure to sun</th>\n",
       "      <th>recurrences of hsv-1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpleasant bacterium</th>\n",
       "      <th>laurel dieback disease</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumption of the two drugs</th>\n",
       "      <th>valvular heart disease</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>involuntary intercourse</th>\n",
       "      <th>unwanted consequences</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical intervention into human neutropenias</th>\n",
       "      <th>scn</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitamins or mineral</th>\n",
       "      <th>natural healthy weight loss</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prolonged abstinence</th>\n",
       "      <th>problems</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mutations in the rab27a gene</th>\n",
       "      <th>griscelli syndrome type 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dysgenesis of the trabeculum</th>\n",
       "      <th>impaired aqueous outflow</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remove the dead layers of skin</th>\n",
       "      <th>blackheads</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oatmeal shampoo</th>\n",
       "      <th>adverse reaction</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ketamin immobilisation</th>\n",
       "      <th>cramps</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th>reduced cell count</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mutation</th>\n",
       "      <th>temperature-sensitive phenotypes</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher chloramphenicol mbcs</th>\n",
       "      <th>borderline cerebrospinal-fluid bactericidal activity</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oral administration of acs</th>\n",
       "      <th>amelioration of acute colitis</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formaldehyde</th>\n",
       "      <th>cellular damage</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mutations in this gene</th>\n",
       "      <th>neurogenic di</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serious complications</th>\n",
       "      <th>irreversible damage</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excessive nutrients</th>\n",
       "      <th>uncontrolled growth of some species</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss of muscle bulk</th>\n",
       "      <th>problems</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chronic bullying</th>\n",
       "      <th>academic failure</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increased uric acid</th>\n",
       "      <th>changes</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trileptal</th>\n",
       "      <th>serious allergic reactions</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gap between the inner most skin layer</th>\n",
       "      <th>fluid inside</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administration of map kinase signaling inhibitors</th>\n",
       "      <th>toxicity in these mice</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persistance of this vitelline duct</th>\n",
       "      <th>meckel ’ s diverticulum</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxygen depletion</th>\n",
       "      <th>oxygen stratification</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      rater-0  \\\n",
       "cause                                             effect                                                        \n",
       "respiratory illness                               carbon dioxide on levels of pollutants                    0   \n",
       "critical events                                   disorder                                                  1   \n",
       "viral replication in the cns                      ability to detect features of the csf viral pop...        1   \n",
       "fava beans                                        severe hypertensive reactions                             0   \n",
       "single processing nodes                           problems                                                  1   \n",
       "problems                                          poor treatment                                            1   \n",
       "poor treatment                                    problems                                                  1   \n",
       "physical activity                                 damage                                                    1   \n",
       "exposure to sun                                   recurrences of hsv-1                                      0   \n",
       "unpleasant bacterium                              laurel dieback disease                                    0   \n",
       "consumption of the two drugs                      valvular heart disease                                    0   \n",
       "involuntary intercourse                           unwanted consequences                                     1   \n",
       "clinical intervention into human neutropenias     scn                                                       0   \n",
       "vitamins or mineral                               natural healthy weight loss                               0   \n",
       "prolonged abstinence                              problems                                                  1   \n",
       "mutations in the rab27a gene                      griscelli syndrome type 2                                 0   \n",
       "dysgenesis of the trabeculum                      impaired aqueous outflow                                  0   \n",
       "remove the dead layers of skin                    blackheads                                                0   \n",
       "oatmeal shampoo                                   adverse reaction                                          0   \n",
       "ketamin immobilisation                            cramps                                                    0   \n",
       "stroke                                            reduced cell count                                        0   \n",
       "mutation                                          temperature-sensitive phenotypes                          1   \n",
       "higher chloramphenicol mbcs                       borderline cerebrospinal-fluid bactericidal act...        1   \n",
       "oral administration of acs                        amelioration of acute colitis                             0   \n",
       "formaldehyde                                      cellular damage                                           1   \n",
       "mutations in this gene                            neurogenic di                                             0   \n",
       "serious complications                             irreversible damage                                       1   \n",
       "excessive nutrients                               uncontrolled growth of some species                       1   \n",
       "loss of muscle bulk                               problems                                                  1   \n",
       "chronic bullying                                  academic failure                                          1   \n",
       "increased uric acid                               changes                                                   1   \n",
       "trileptal                                         serious allergic reactions                                0   \n",
       "gap between the inner most skin layer             fluid inside                                              1   \n",
       "administration of map kinase signaling inhibitors toxicity in these mice                                    1   \n",
       "persistance of this vitelline duct                meckel ’ s diverticulum                                   1   \n",
       "oxygen depletion                                  oxygen stratification                                     0   \n",
       "\n",
       "                                                                                                      rater-1  \n",
       "cause                                             effect                                                       \n",
       "respiratory illness                               carbon dioxide on levels of pollutants                    1  \n",
       "critical events                                   disorder                                                  0  \n",
       "viral replication in the cns                      ability to detect features of the csf viral pop...        0  \n",
       "fava beans                                        severe hypertensive reactions                             1  \n",
       "single processing nodes                           problems                                                  0  \n",
       "problems                                          poor treatment                                            0  \n",
       "poor treatment                                    problems                                                  0  \n",
       "physical activity                                 damage                                                    0  \n",
       "exposure to sun                                   recurrences of hsv-1                                      1  \n",
       "unpleasant bacterium                              laurel dieback disease                                    1  \n",
       "consumption of the two drugs                      valvular heart disease                                    1  \n",
       "involuntary intercourse                           unwanted consequences                                     0  \n",
       "clinical intervention into human neutropenias     scn                                                       1  \n",
       "vitamins or mineral                               natural healthy weight loss                               1  \n",
       "prolonged abstinence                              problems                                                  0  \n",
       "mutations in the rab27a gene                      griscelli syndrome type 2                                 1  \n",
       "dysgenesis of the trabeculum                      impaired aqueous outflow                                  1  \n",
       "remove the dead layers of skin                    blackheads                                                1  \n",
       "oatmeal shampoo                                   adverse reaction                                          1  \n",
       "ketamin immobilisation                            cramps                                                    1  \n",
       "stroke                                            reduced cell count                                        1  \n",
       "mutation                                          temperature-sensitive phenotypes                          0  \n",
       "higher chloramphenicol mbcs                       borderline cerebrospinal-fluid bactericidal act...        0  \n",
       "oral administration of acs                        amelioration of acute colitis                             1  \n",
       "formaldehyde                                      cellular damage                                           0  \n",
       "mutations in this gene                            neurogenic di                                             1  \n",
       "serious complications                             irreversible damage                                       0  \n",
       "excessive nutrients                               uncontrolled growth of some species                       0  \n",
       "loss of muscle bulk                               problems                                                  0  \n",
       "chronic bullying                                  academic failure                                          0  \n",
       "increased uric acid                               changes                                                   0  \n",
       "trileptal                                         serious allergic reactions                                1  \n",
       "gap between the inner most skin layer             fluid inside                                              0  \n",
       "administration of map kinase signaling inhibitors toxicity in these mice                                    0  \n",
       "persistance of this vitelline duct                meckel ’ s diverticulum                                   0  \n",
       "oxygen depletion                                  oxygen stratification                                     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.loc[evals[\"rater-0\"] != evals[\"rater-1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78813e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa 0.9649254080344198\n",
      "fleiss 0.9649254080344198\n",
      "alpha 0.964937821198674\n",
      "scotts 0.9649202813393436\n"
     ]
    }
   ],
   "source": [
    "evals = sentence_test_causenet.set_index([\"cause\", \"effect\"]).dropna(\n",
    "    subset=[\"manual_evaluation\"]\n",
    ")\n",
    "evals = evals.loc[:, [\"evaluation\", \"manual_evaluation\"]].astype(int)\n",
    "rating_data = evals.reset_index(drop=True).stack().swaplevel().reset_index().values\n",
    "rating_data = list(tuple(row) for row in rating_data)\n",
    "\n",
    "rating_task = agreement.AnnotationTask(data=rating_data)\n",
    "print(\"kappa \" + str(rating_task.kappa()))\n",
    "print(\"fleiss \" + str(rating_task.multi_kappa()))\n",
    "print(\"alpha \" + str(rating_task.alpha()))\n",
    "print(\"scotts \" + str(rating_task.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c020963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation            1\n",
      "manual_evaluation    11\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "      <th>manual_evaluation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opportunistic condition</th>\n",
       "      <th>life forms in the blood</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hl</th>\n",
       "      <th>discomfort to the infant</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faulty engineering of toyota</th>\n",
       "      <th>deaths</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuts already inflicted</th>\n",
       "      <th>pain</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <th>particular feeling</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh produce</th>\n",
       "      <th>public health from pathogens</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haplotypes</th>\n",
       "      <th>susceptibility</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>limitation</th>\n",
       "      <th>efficiency</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images they will encounter</th>\n",
       "      <th>involuntary physical/psychological reaction</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduced brain size</th>\n",
       "      <th>larger relative motion</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disc</th>\n",
       "      <th>fatigue</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>razor point teeth unrelenting</th>\n",
       "      <th>sharp pain shocks</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           evaluation  \\\n",
       "cause                         effect                                                    \n",
       "opportunistic condition       life forms in the blood                               0   \n",
       "hl                            discomfort to the infant                              0   \n",
       "faulty engineering of toyota  deaths                                                0   \n",
       "cuts already inflicted        pain                                                  1   \n",
       "sound                         particular feeling                                    0   \n",
       "fresh produce                 public health from pathogens                          0   \n",
       "haplotypes                    susceptibility                                        0   \n",
       "limitation                    efficiency                                            0   \n",
       "images they will encounter    involuntary physical/psychological reaction           0   \n",
       "reduced brain size            larger relative motion                                0   \n",
       "disc                          fatigue                                               0   \n",
       "razor point teeth unrelenting sharp pain shocks                                     0   \n",
       "\n",
       "                                                                           manual_evaluation  \n",
       "cause                         effect                                                          \n",
       "opportunistic condition       life forms in the blood                                      1  \n",
       "hl                            discomfort to the infant                                     1  \n",
       "faulty engineering of toyota  deaths                                                       1  \n",
       "cuts already inflicted        pain                                                         0  \n",
       "sound                         particular feeling                                           1  \n",
       "fresh produce                 public health from pathogens                                 1  \n",
       "haplotypes                    susceptibility                                               1  \n",
       "limitation                    efficiency                                                   1  \n",
       "images they will encounter    involuntary physical/psychological reaction                  1  \n",
       "reduced brain size            larger relative motion                                       1  \n",
       "disc                          fatigue                                                      1  \n",
       "razor point teeth unrelenting sharp pain shocks                                            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((evals.loc[evals[\"evaluation\"] != evals[\"manual_evaluation\"]]).sum())\n",
    "evals.loc[evals[\"evaluation\"] != evals[\"manual_evaluation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f88378af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec73b03502a4474ca5a52dd72fdddf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3378491/115610357.py:8: RuntimeWarning: divide by zero encountered in power\n",
      "  return ((cause ** p + effect ** p) / 2) ** (1 / p)\n",
      "/tmp/ipykernel_3378491/115610357.py:8: RuntimeWarning: divide by zero encountered in power\n",
      "  return ((cause ** p + effect ** p) / 2) ** (1 / p)\n",
      "/tmp/ipykernel_3378491/115610357.py:8: RuntimeWarning: divide by zero encountered in power\n",
      "  return ((cause ** p + effect ** p) / 2) ** (1 / p)\n",
      "/tmp/ipykernel_3378491/115610357.py:8: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return ((cause ** p + effect ** p) / 2) ** (1 / p)\n"
     ]
    }
   ],
   "source": [
    "def parse_test_causenet_combined(test_causenet, ops):\n",
    "    test_causenet_combined = []\n",
    "\n",
    "    total = len(ops)\n",
    "\n",
    "    for op_name, op in tqdm(ops.items()):\n",
    "        column_names = sorted(test_causenet.filter(regex=\"medical_score\"))\n",
    "        filtered = test_causenet[column_names]\n",
    "        half = filtered.shape[1] // 2\n",
    "        combined = op(filtered.iloc[:, :half].values, filtered.iloc[:, half:].values,)\n",
    "        test_causenet_combined.append(\n",
    "            pd.DataFrame(\n",
    "                combined,\n",
    "                columns=list(\n",
    "                    name[20:] + \"-\" + op_name for name in filtered.iloc[:, :half]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    test_causenet_combined = pd.concat(test_causenet_combined, axis=1)\n",
    "    return test_causenet_combined\n",
    "\n",
    "\n",
    "# or and p=inf_mean are the same\n",
    "ops = {\n",
    "    \"p=neg_inf_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, -float(\"inf\")),\n",
    "    \"p=neg_10_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, -10),\n",
    "    \"p=neg_5_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, -5),\n",
    "    \"p=neg_2_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, -2),\n",
    "    \"p=neg_1_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, -1),\n",
    "    \"p=0_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, 0),\n",
    "    \"p=1_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, 1),\n",
    "    \"p=2_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, 2),\n",
    "    \"p=5_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, 5),\n",
    "    \"p=10_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, 10),\n",
    "    \"p=inf_mean\": lambda cause, effect: p_mean_threshold_combiner(cause, effect, float(\"inf\")),\n",
    "}\n",
    "test_causenet_combined = parse_test_causenet_combined(test_causenet, ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90c5c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_causenet_combined.to_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_combined.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77470239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-0-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-1-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-10-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-2-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-5-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-inf-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_1-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_10-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_2-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_5-p=neg_inf_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-1-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-10-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-2-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-5-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-inf-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_1-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_10-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_2-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_5-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_inf-p=inf_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>65.933325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.668799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.111194</td>\n",
       "      <td>38.700827</td>\n",
       "      <td>65.379759</td>\n",
       "      <td>48.931429</td>\n",
       "      <td>59.373694</td>\n",
       "      <td>72.933463</td>\n",
       "      <td>54.235982</td>\n",
       "      <td>46.243061</td>\n",
       "      <td>52.537026</td>\n",
       "      <td>48.897504</td>\n",
       "      <td>...</td>\n",
       "      <td>2.227317</td>\n",
       "      <td>3.755851</td>\n",
       "      <td>2.743111</td>\n",
       "      <td>3.392185</td>\n",
       "      <td>4.191259</td>\n",
       "      <td>0.681375</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>0.472301</td>\n",
       "      <td>0.379012</td>\n",
       "      <td>0.280792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.146614</td>\n",
       "      <td>62.146614</td>\n",
       "      <td>62.146614</td>\n",
       "      <td>62.146614</td>\n",
       "      <td>62.146614</td>\n",
       "      <td>62.146614</td>\n",
       "      <td>57.645719</td>\n",
       "      <td>41.854913</td>\n",
       "      <td>53.506999</td>\n",
       "      <td>46.222332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537442</td>\n",
       "      <td>0.975680</td>\n",
       "      <td>0.667126</td>\n",
       "      <td>0.874176</td>\n",
       "      <td>1.110644</td>\n",
       "      <td>0.448074</td>\n",
       "      <td>0.448074</td>\n",
       "      <td>0.448074</td>\n",
       "      <td>0.448074</td>\n",
       "      <td>0.448074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.115528</td>\n",
       "      <td>81.745700</td>\n",
       "      <td>86.408299</td>\n",
       "      <td>82.371051</td>\n",
       "      <td>84.132450</td>\n",
       "      <td>91.876372</td>\n",
       "      <td>80.490215</td>\n",
       "      <td>76.146956</td>\n",
       "      <td>79.879143</td>\n",
       "      <td>78.206791</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148534</td>\n",
       "      <td>1.361173</td>\n",
       "      <td>1.180650</td>\n",
       "      <td>1.268464</td>\n",
       "      <td>1.513839</td>\n",
       "      <td>1.087559</td>\n",
       "      <td>0.945712</td>\n",
       "      <td>1.060885</td>\n",
       "      <td>1.000154</td>\n",
       "      <td>0.855794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>80.481637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "      <td>1.014004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404084</td>\n",
       "      <td>3.258437</td>\n",
       "      <td>0.965237</td>\n",
       "      <td>2.274515</td>\n",
       "      <td>5.057795</td>\n",
       "      <td>0.409407</td>\n",
       "      <td>0.213249</td>\n",
       "      <td>0.345938</td>\n",
       "      <td>0.269523</td>\n",
       "      <td>0.146197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>2.976322</td>\n",
       "      <td>1.296982</td>\n",
       "      <td>2.292776</td>\n",
       "      <td>4.191259</td>\n",
       "      <td>0.331804</td>\n",
       "      <td>0.044245</td>\n",
       "      <td>0.171360</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.029749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731866</td>\n",
       "      <td>2.844768</td>\n",
       "      <td>1.186969</td>\n",
       "      <td>2.134502</td>\n",
       "      <td>4.150999</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.105215</td>\n",
       "      <td>0.238152</td>\n",
       "      <td>0.140124</td>\n",
       "      <td>0.073085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560239</td>\n",
       "      <td>2.946324</td>\n",
       "      <td>1.027860</td>\n",
       "      <td>2.174583</td>\n",
       "      <td>4.150999</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.141116</td>\n",
       "      <td>0.059895</td>\n",
       "      <td>0.030593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211595</td>\n",
       "      <td>0.924786</td>\n",
       "      <td>0.376888</td>\n",
       "      <td>0.673100</td>\n",
       "      <td>1.440562</td>\n",
       "      <td>0.224859</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>0.160212</td>\n",
       "      <td>0.087382</td>\n",
       "      <td>0.044656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contrastive_weight-encyclopedia-(1, 1)-0-p=neg_inf_mean  \\\n",
       "0                                             65.933325         \n",
       "1                                             56.111194         \n",
       "2                                             62.146614         \n",
       "3                                             81.115528         \n",
       "4                                             80.481637         \n",
       "...                                                 ...         \n",
       "2995                                           0.000000         \n",
       "2996                                           0.000000         \n",
       "2997                                           0.000000         \n",
       "2998                                           0.000000         \n",
       "2999                                           0.000000         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-1-p=neg_inf_mean  \\\n",
       "0                                             65.933325         \n",
       "1                                             38.700827         \n",
       "2                                             62.146614         \n",
       "3                                             81.745700         \n",
       "4                                             80.481637         \n",
       "...                                                 ...         \n",
       "2995                                           0.000000         \n",
       "2996                                           0.000000         \n",
       "2997                                           0.000000         \n",
       "2998                                           0.000000         \n",
       "2999                                           0.000000         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-10-p=neg_inf_mean  \\\n",
       "0                                             65.933325          \n",
       "1                                             65.379759          \n",
       "2                                             62.146614          \n",
       "3                                             86.408299          \n",
       "4                                             80.481637          \n",
       "...                                                 ...          \n",
       "2995                                           0.000000          \n",
       "2996                                           0.000000          \n",
       "2997                                           0.000000          \n",
       "2998                                           0.000000          \n",
       "2999                                           0.000000          \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-2-p=neg_inf_mean  \\\n",
       "0                                             65.933325         \n",
       "1                                             48.931429         \n",
       "2                                             62.146614         \n",
       "3                                             82.371051         \n",
       "4                                             80.481637         \n",
       "...                                                 ...         \n",
       "2995                                           0.000000         \n",
       "2996                                           0.000000         \n",
       "2997                                           0.000000         \n",
       "2998                                           0.000000         \n",
       "2999                                           0.000000         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-5-p=neg_inf_mean  \\\n",
       "0                                             65.933325         \n",
       "1                                             59.373694         \n",
       "2                                             62.146614         \n",
       "3                                             84.132450         \n",
       "4                                             80.481637         \n",
       "...                                                 ...         \n",
       "2995                                           0.000000         \n",
       "2996                                           0.000000         \n",
       "2997                                           0.000000         \n",
       "2998                                           0.000000         \n",
       "2999                                           0.000000         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-inf-p=neg_inf_mean  \\\n",
       "0                                             65.933325           \n",
       "1                                             72.933463           \n",
       "2                                             62.146614           \n",
       "3                                             91.876372           \n",
       "4                                             80.481637           \n",
       "...                                                 ...           \n",
       "2995                                           0.000000           \n",
       "2996                                           0.000000           \n",
       "2997                                           0.000000           \n",
       "2998                                           0.000000           \n",
       "2999                                           0.000000           \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_1-p=neg_inf_mean  \\\n",
       "0                                             65.933325             \n",
       "1                                             54.235982             \n",
       "2                                             57.645719             \n",
       "3                                             80.490215             \n",
       "4                                             80.481637             \n",
       "...                                                 ...             \n",
       "2995                                           0.000000             \n",
       "2996                                           0.000000             \n",
       "2997                                           0.000000             \n",
       "2998                                           0.000000             \n",
       "2999                                           0.000000             \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_10-p=neg_inf_mean  \\\n",
       "0                                             65.933325              \n",
       "1                                             46.243061              \n",
       "2                                             41.854913              \n",
       "3                                             76.146956              \n",
       "4                                             80.481637              \n",
       "...                                                 ...              \n",
       "2995                                           0.000000              \n",
       "2996                                           0.000000              \n",
       "2997                                           0.000000              \n",
       "2998                                           0.000000              \n",
       "2999                                           0.000000              \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_2-p=neg_inf_mean  \\\n",
       "0                                             65.933325             \n",
       "1                                             52.537026             \n",
       "2                                             53.506999             \n",
       "3                                             79.879143             \n",
       "4                                             80.481637             \n",
       "...                                                 ...             \n",
       "2995                                           0.000000             \n",
       "2996                                           0.000000             \n",
       "2997                                           0.000000             \n",
       "2998                                           0.000000             \n",
       "2999                                           0.000000             \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_5-p=neg_inf_mean  ...  \\\n",
       "0                                             65.933325            ...   \n",
       "1                                             48.897504            ...   \n",
       "2                                             46.222332            ...   \n",
       "3                                             78.206791            ...   \n",
       "4                                             80.481637            ...   \n",
       "...                                                 ...            ...   \n",
       "2995                                           0.000000            ...   \n",
       "2996                                           0.000000            ...   \n",
       "2997                                           0.000000            ...   \n",
       "2998                                           0.000000            ...   \n",
       "2999                                           0.000000            ...   \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-1-p=inf_mean  \\\n",
       "0                                              0.668799      \n",
       "1                                              2.227317      \n",
       "2                                              0.537442      \n",
       "3                                              1.148534      \n",
       "4                                              1.014004      \n",
       "...                                                 ...      \n",
       "2995                                           0.404084      \n",
       "2996                                           0.743492      \n",
       "2997                                           0.731866      \n",
       "2998                                           0.560239      \n",
       "2999                                           0.211595      \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-10-p=inf_mean  \\\n",
       "0                                              0.668799       \n",
       "1                                              3.755851       \n",
       "2                                              0.975680       \n",
       "3                                              1.361173       \n",
       "4                                              1.014004       \n",
       "...                                                 ...       \n",
       "2995                                           3.258437       \n",
       "2996                                           2.976322       \n",
       "2997                                           2.844768       \n",
       "2998                                           2.946324       \n",
       "2999                                           0.924786       \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-2-p=inf_mean  \\\n",
       "0                                              0.668799      \n",
       "1                                              2.743111      \n",
       "2                                              0.667126      \n",
       "3                                              1.180650      \n",
       "4                                              1.014004      \n",
       "...                                                 ...      \n",
       "2995                                           0.965237      \n",
       "2996                                           1.296982      \n",
       "2997                                           1.186969      \n",
       "2998                                           1.027860      \n",
       "2999                                           0.376888      \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-5-p=inf_mean  \\\n",
       "0                                              0.668799      \n",
       "1                                              3.392185      \n",
       "2                                              0.874176      \n",
       "3                                              1.268464      \n",
       "4                                              1.014004      \n",
       "...                                                 ...      \n",
       "2995                                           2.274515      \n",
       "2996                                           2.292776      \n",
       "2997                                           2.134502      \n",
       "2998                                           2.174583      \n",
       "2999                                           0.673100      \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-inf-p=inf_mean  \\\n",
       "0                                              0.668799        \n",
       "1                                              4.191259        \n",
       "2                                              1.110644        \n",
       "3                                              1.513839        \n",
       "4                                              1.014004        \n",
       "...                                                 ...        \n",
       "2995                                           5.057795        \n",
       "2996                                           4.191259        \n",
       "2997                                           4.150999        \n",
       "2998                                           4.150999        \n",
       "2999                                           1.440562        \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_1-p=inf_mean  \\\n",
       "0                                              0.668799          \n",
       "1                                              0.681375          \n",
       "2                                              0.448074          \n",
       "3                                              1.087559          \n",
       "4                                              1.014004          \n",
       "...                                                 ...          \n",
       "2995                                           0.409407          \n",
       "2996                                           0.331804          \n",
       "2997                                           0.342500          \n",
       "2998                                           0.254529          \n",
       "2999                                           0.224859          \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_10-p=inf_mean  \\\n",
       "0                                              0.668799           \n",
       "1                                              0.332689           \n",
       "2                                              0.448074           \n",
       "3                                              0.945712           \n",
       "4                                              1.014004           \n",
       "...                                                 ...           \n",
       "2995                                           0.213249           \n",
       "2996                                           0.044245           \n",
       "2997                                           0.105215           \n",
       "2998                                           0.042841           \n",
       "2999                                           0.063232           \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_2-p=inf_mean  \\\n",
       "0                                              0.668799          \n",
       "1                                              0.472301          \n",
       "2                                              0.448074          \n",
       "3                                              1.060885          \n",
       "4                                              1.014004          \n",
       "...                                                 ...          \n",
       "2995                                           0.345938          \n",
       "2996                                           0.171360          \n",
       "2997                                           0.238152          \n",
       "2998                                           0.141116          \n",
       "2999                                           0.160212          \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_5-p=inf_mean  \\\n",
       "0                                              0.668799          \n",
       "1                                              0.379012          \n",
       "2                                              0.448074          \n",
       "3                                              1.000154          \n",
       "4                                              1.014004          \n",
       "...                                                 ...          \n",
       "2995                                           0.269523          \n",
       "2996                                           0.065425          \n",
       "2997                                           0.140124          \n",
       "2998                                           0.059895          \n",
       "2999                                           0.087382          \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_inf-p=inf_mean  \n",
       "0                                              0.668799           \n",
       "1                                              0.280792           \n",
       "2                                              0.448074           \n",
       "3                                              0.855794           \n",
       "4                                              1.014004           \n",
       "...                                                 ...           \n",
       "2995                                           0.146197           \n",
       "2996                                           0.029749           \n",
       "2997                                           0.073085           \n",
       "2998                                           0.030593           \n",
       "2999                                           0.044656           \n",
       "\n",
       "[3000 rows x 5104 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet_combined = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_combined.pkl\")\n",
    ")\n",
    "test_causenet_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bedfe68",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3b329eb3684d018f34f0dc01c234be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_test_causenet_medical(test_causenet_combined, method_threshold_dict):\n",
    "    test_causenet_medical = []\n",
    "\n",
    "    total = 0\n",
    "    for thresholds in method_threshold_dict.values():\n",
    "        total += len(thresholds)\n",
    "\n",
    "    pg = tqdm(total=total)\n",
    "    for method_name, thresholds in method_threshold_dict.items():\n",
    "        for threshold in thresholds:\n",
    "            column_names = sorted(test_causenet_combined.filter(regex=method_name))\n",
    "            filtered = test_causenet_combined[column_names]\n",
    "            medical = filtered >= threshold\n",
    "            medical = medical.add_suffix(f\"-{threshold}-medical\")\n",
    "            test_causenet_medical.append(medical)\n",
    "            pg.update()\n",
    "    test_causenet_medical = pd.concat(test_causenet_medical, axis=1)\n",
    "    return test_causenet_medical\n",
    "\n",
    "\n",
    "taggers = [\"quickumls\", \"scispacy\", \"metamap\", \"ctakes\"]\n",
    "method_threshold_dict = {\n",
    "    \"|\".join(taggers): [round(thresh, 4) for thresh in np.linspace(0, 1, 100)],\n",
    "    \"term_domain_specificity\": [round(thresh, 4) for thresh in np.linspace(0, 6, 100)],\n",
    "    \"contrastive_weight\": [round(thresh, 4) for thresh in np.linspace(50, 140, 100)],\n",
    "    \"discriminative_weight\": [round(thresh, 4) for thresh in np.linspace(0, 1100, 100)],\n",
    "    \"health_bert\": [round(thresh, 4) for thresh in np.linspace(0, 1, 100)],\n",
    "}\n",
    "\n",
    "test_causenet_medical = parse_test_causenet_medical(\n",
    "    test_causenet_combined, method_threshold_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bef304e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_causenet_medical.to_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_medical.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbbb523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctakes-full-p=0-0.0-medical</th>\n",
       "      <th>ctakes-full-p=10_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=1_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=2_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=5_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=inf_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=neg_10_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=neg_1_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=neg_2_mean-0.0-medical</th>\n",
       "      <th>ctakes-full-p=neg_5_mean-0.0-medical</th>\n",
       "      <th>...</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=10_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=1_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=2_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=5_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=inf_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=neg_10_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=neg_1_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=neg_2_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=neg_5_mean-1.0-medical</th>\n",
       "      <th>health_bert-scibert-pubmed-sentence-p=neg_inf_mean-1.0-medical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 510400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ctakes-full-p=0-0.0-medical  ctakes-full-p=10_mean-0.0-medical  \\\n",
       "0                            True                               True   \n",
       "1                            True                               True   \n",
       "2                            True                               True   \n",
       "3                            True                               True   \n",
       "4                            True                               True   \n",
       "...                           ...                                ...   \n",
       "2995                         True                               True   \n",
       "2996                         True                               True   \n",
       "2997                         True                               True   \n",
       "2998                         True                               True   \n",
       "2999                         True                               True   \n",
       "\n",
       "      ctakes-full-p=1_mean-0.0-medical  ctakes-full-p=2_mean-0.0-medical  \\\n",
       "0                                 True                              True   \n",
       "1                                 True                              True   \n",
       "2                                 True                              True   \n",
       "3                                 True                              True   \n",
       "4                                 True                              True   \n",
       "...                                ...                               ...   \n",
       "2995                              True                              True   \n",
       "2996                              True                              True   \n",
       "2997                              True                              True   \n",
       "2998                              True                              True   \n",
       "2999                              True                              True   \n",
       "\n",
       "      ctakes-full-p=5_mean-0.0-medical  ctakes-full-p=inf_mean-0.0-medical  \\\n",
       "0                                 True                                True   \n",
       "1                                 True                                True   \n",
       "2                                 True                                True   \n",
       "3                                 True                                True   \n",
       "4                                 True                                True   \n",
       "...                                ...                                 ...   \n",
       "2995                              True                                True   \n",
       "2996                              True                                True   \n",
       "2997                              True                                True   \n",
       "2998                              True                                True   \n",
       "2999                              True                                True   \n",
       "\n",
       "      ctakes-full-p=neg_10_mean-0.0-medical  \\\n",
       "0                                      True   \n",
       "1                                      True   \n",
       "2                                      True   \n",
       "3                                      True   \n",
       "4                                      True   \n",
       "...                                     ...   \n",
       "2995                                   True   \n",
       "2996                                   True   \n",
       "2997                                   True   \n",
       "2998                                   True   \n",
       "2999                                   True   \n",
       "\n",
       "      ctakes-full-p=neg_1_mean-0.0-medical  \\\n",
       "0                                     True   \n",
       "1                                     True   \n",
       "2                                     True   \n",
       "3                                     True   \n",
       "4                                     True   \n",
       "...                                    ...   \n",
       "2995                                  True   \n",
       "2996                                  True   \n",
       "2997                                  True   \n",
       "2998                                  True   \n",
       "2999                                  True   \n",
       "\n",
       "      ctakes-full-p=neg_2_mean-0.0-medical  \\\n",
       "0                                     True   \n",
       "1                                     True   \n",
       "2                                     True   \n",
       "3                                     True   \n",
       "4                                     True   \n",
       "...                                    ...   \n",
       "2995                                  True   \n",
       "2996                                  True   \n",
       "2997                                  True   \n",
       "2998                                  True   \n",
       "2999                                  True   \n",
       "\n",
       "      ctakes-full-p=neg_5_mean-0.0-medical  ...  \\\n",
       "0                                     True  ...   \n",
       "1                                     True  ...   \n",
       "2                                     True  ...   \n",
       "3                                     True  ...   \n",
       "4                                     True  ...   \n",
       "...                                    ...  ...   \n",
       "2995                                  True  ...   \n",
       "2996                                  True  ...   \n",
       "2997                                  True  ...   \n",
       "2998                                  True  ...   \n",
       "2999                                  True  ...   \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=10_mean-1.0-medical  \\\n",
       "0                                                 False           \n",
       "1                                                 False           \n",
       "2                                                 False           \n",
       "3                                                 False           \n",
       "4                                                 False           \n",
       "...                                                 ...           \n",
       "2995                                              False           \n",
       "2996                                              False           \n",
       "2997                                              False           \n",
       "2998                                              False           \n",
       "2999                                              False           \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=1_mean-1.0-medical  \\\n",
       "0                                                 False          \n",
       "1                                                 False          \n",
       "2                                                 False          \n",
       "3                                                 False          \n",
       "4                                                 False          \n",
       "...                                                 ...          \n",
       "2995                                              False          \n",
       "2996                                              False          \n",
       "2997                                              False          \n",
       "2998                                              False          \n",
       "2999                                              False          \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=2_mean-1.0-medical  \\\n",
       "0                                                 False          \n",
       "1                                                 False          \n",
       "2                                                 False          \n",
       "3                                                 False          \n",
       "4                                                 False          \n",
       "...                                                 ...          \n",
       "2995                                              False          \n",
       "2996                                              False          \n",
       "2997                                              False          \n",
       "2998                                              False          \n",
       "2999                                              False          \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=5_mean-1.0-medical  \\\n",
       "0                                                 False          \n",
       "1                                                 False          \n",
       "2                                                 False          \n",
       "3                                                 False          \n",
       "4                                                 False          \n",
       "...                                                 ...          \n",
       "2995                                              False          \n",
       "2996                                              False          \n",
       "2997                                              False          \n",
       "2998                                              False          \n",
       "2999                                              False          \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=inf_mean-1.0-medical  \\\n",
       "0                                                 False            \n",
       "1                                                 False            \n",
       "2                                                 False            \n",
       "3                                                 False            \n",
       "4                                                 False            \n",
       "...                                                 ...            \n",
       "2995                                              False            \n",
       "2996                                              False            \n",
       "2997                                              False            \n",
       "2998                                              False            \n",
       "2999                                              False            \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=neg_10_mean-1.0-medical  \\\n",
       "0                                                 False               \n",
       "1                                                 False               \n",
       "2                                                 False               \n",
       "3                                                 False               \n",
       "4                                                 False               \n",
       "...                                                 ...               \n",
       "2995                                              False               \n",
       "2996                                              False               \n",
       "2997                                              False               \n",
       "2998                                              False               \n",
       "2999                                              False               \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=neg_1_mean-1.0-medical  \\\n",
       "0                                                 False              \n",
       "1                                                 False              \n",
       "2                                                 False              \n",
       "3                                                 False              \n",
       "4                                                 False              \n",
       "...                                                 ...              \n",
       "2995                                              False              \n",
       "2996                                              False              \n",
       "2997                                              False              \n",
       "2998                                              False              \n",
       "2999                                              False              \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=neg_2_mean-1.0-medical  \\\n",
       "0                                                 False              \n",
       "1                                                 False              \n",
       "2                                                 False              \n",
       "3                                                 False              \n",
       "4                                                 False              \n",
       "...                                                 ...              \n",
       "2995                                              False              \n",
       "2996                                              False              \n",
       "2997                                              False              \n",
       "2998                                              False              \n",
       "2999                                              False              \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=neg_5_mean-1.0-medical  \\\n",
       "0                                                 False              \n",
       "1                                                 False              \n",
       "2                                                 False              \n",
       "3                                                 False              \n",
       "4                                                 False              \n",
       "...                                                 ...              \n",
       "2995                                              False              \n",
       "2996                                              False              \n",
       "2997                                              False              \n",
       "2998                                              False              \n",
       "2999                                              False              \n",
       "\n",
       "      health_bert-scibert-pubmed-sentence-p=neg_inf_mean-1.0-medical  \n",
       "0                                                 False               \n",
       "1                                                 False               \n",
       "2                                                 False               \n",
       "3                                                 False               \n",
       "4                                                 False               \n",
       "...                                                 ...               \n",
       "2995                                              False               \n",
       "2996                                              False               \n",
       "2997                                              False               \n",
       "2998                                              False               \n",
       "2999                                              False               \n",
       "\n",
       "[3000 rows x 510400 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet_medical = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_medical.pkl\")\n",
    ")\n",
    "test_causenet_medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2291ae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 938), (600, 938))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "sample_idcs = test_causenet_medical.groupby(test_causenet.dataset).sample(800, random_state=seed).index\n",
    "\n",
    "validation_causenet_medical = test_causenet_medical.loc[sample_idcs]\n",
    "test_causenet_medical = test_causenet_medical.loc[~test_causenet_medical.index.isin(sample_idcs.values)]\n",
    "\n",
    "validation_causenet = test_causenet.loc[sample_idcs]\n",
    "test_causenet = test_causenet.loc[~test_causenet.index.isin(sample_idcs.values)]\n",
    "\n",
    "validation_causenet_combined = test_causenet_combined.loc[sample_idcs]\n",
    "test_causenet_combined = test_causenet_combined.loc[~test_causenet_combined.index.isin(sample_idcs.values)]\n",
    "\n",
    "validation_causenet.shape, test_causenet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e54707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a67ed07db6419ea359bf55b085e38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2787688/2601433928.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "  denominator = np.log([tp + fp, tp + fn, tn + fp, tn + fn]).sum(axis=0) * (1 / 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67fe5a2398b4a378392d02157fa40b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2787688/2601433928.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "  denominator = np.log([tp + fp, tp + fn, tn + fp, tn + fn]).sum(axis=0) * (1 / 2)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_test_causenet_medical(test_causenet, test_causenet_medical):\n",
    "    _tp = []\n",
    "    _fp = []\n",
    "    _tn = []\n",
    "    _fn = []\n",
    "    test_causenet_medical = test_causenet_medical.loc[~test_causenet.evaluation.isna()]\n",
    "    test_causenet = test_causenet.loc[~test_causenet.evaluation.isna()]\n",
    "    test_causenet.evaluation = test_causenet.evaluation.astype(int)\n",
    "    for _dataset in tqdm(test_causenet.dataset.drop_duplicates().values):\n",
    "        dataset_bool = test_causenet.dataset == _dataset\n",
    "        _test_causenet_medical = test_causenet_medical.loc[dataset_bool]\n",
    "        _test_causenet = test_causenet.loc[dataset_bool]\n",
    "        _tp.append(\n",
    "            (_test_causenet_medical & _test_causenet.evaluation.values[:, np.newaxis])\n",
    "            .sum()\n",
    "            .rename(_dataset)\n",
    "        )\n",
    "        _fp.append(\n",
    "            (_test_causenet_medical & ~_test_causenet.evaluation.values[:, np.newaxis])\n",
    "            .sum()\n",
    "            .rename(_dataset)\n",
    "        )\n",
    "        _tn.append(\n",
    "            (~_test_causenet_medical & ~_test_causenet.evaluation.values[:, np.newaxis])\n",
    "            .loc[dataset_bool]\n",
    "            .sum()\n",
    "            .rename(_dataset)\n",
    "        )\n",
    "        _fn.append(\n",
    "            (~_test_causenet_medical & _test_causenet.evaluation.values[:, np.newaxis])\n",
    "            .loc[dataset_bool]\n",
    "            .sum()\n",
    "            .rename(_dataset)\n",
    "        )\n",
    "    tp = pd.concat(_tp, axis=1)\n",
    "    fp = pd.concat(_fp, axis=1)\n",
    "    tn = pd.concat(_tn, axis=1)\n",
    "    fn = pd.concat(_fn, axis=1)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    numerator = tp * tn - fp * fn\n",
    "    denominator = np.log([tp + fp, tp + fn, tn + fp, tn + fn]).sum(axis=0) * (1 / 2)\n",
    "    mcc = numerator / np.exp(denominator)\n",
    "    test_causenet_metrics = (\n",
    "        pd.concat(\n",
    "            [tp, fp, tn, fn, precision, recall, f1, accuracy, mcc],\n",
    "            keys=[\n",
    "                \"tp\",\n",
    "                \"fp\",\n",
    "                \"tn\",\n",
    "                \"fn\",\n",
    "                \"precision\",\n",
    "                \"recall\",\n",
    "                \"f1\",\n",
    "                \"accuracy\",\n",
    "                \"mcc\",\n",
    "            ],\n",
    "        )\n",
    "        .stack()\n",
    "        .unstack(0)\n",
    "        .reset_index()\n",
    "    )\n",
    "    test_causenet_metrics = test_causenet_metrics.rename(\n",
    "        {\"level_1\": \"dataset\", \"level_0\": \"method\"}, axis=1\n",
    "    )\n",
    "    test_causenet_metrics = pd.concat(\n",
    "        [\n",
    "            test_causenet_metrics.drop(\"method\", axis=1),\n",
    "            test_causenet_metrics.method.str.rsplit(\"-\", expand=True, n=3)\n",
    "            .drop(3, axis=1)\n",
    "            .rename({0: \"method\", 1: \"operator\", 2: \"threshold\"}, axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    test_causenet_metrics = test_causenet_metrics[\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"method\",\n",
    "            \"operator\",\n",
    "            \"threshold\",\n",
    "            \"tp\",\n",
    "            \"fp\",\n",
    "            \"tn\",\n",
    "            \"fn\",\n",
    "            \"precision\",\n",
    "            \"recall\",\n",
    "            \"f1\",\n",
    "            \"accuracy\",\n",
    "            \"mcc\",\n",
    "        ]\n",
    "    ]\n",
    "    test_causenet_metrics = test_causenet_metrics.replace([np.inf, -np.inf], np.nan)\n",
    "    return test_causenet_metrics\n",
    "\n",
    "\n",
    "validation_causenet_metrics = evaluate_test_causenet_medical(\n",
    "    validation_causenet.loc[:, [\"evaluation\", \"dataset\"]], validation_causenet_medical,\n",
    ")\n",
    "test_causenet_metrics = evaluate_test_causenet_medical(\n",
    "    test_causenet.loc[:, [\"evaluation\", \"dataset\"]], test_causenet_medical,\n",
    ")\n",
    "\n",
    "test_causenet_metrics = test_causenet_metrics.loc[\n",
    "    test_causenet_metrics.dataset.isin([\"random_support\", \"random_full\"]) | \n",
    "    (test_causenet_metrics.operator == \"p=inf_mean\")\n",
    "]\n",
    "validation_causenet_metrics = validation_causenet_metrics.loc[\n",
    "    validation_causenet_metrics.dataset.isin([\"random_support\", \"random_full\"]) | \n",
    "    (validation_causenet_metrics.operator == \"p=inf_mean\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ae97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_causenet_metrics = test_causenet_metrics.loc[\n",
    "    test_causenet_metrics.dataset.isin([\"random_support\", \"random_full\"]) | \n",
    "    (test_causenet_metrics.operator == \"p=inf_mean\")\n",
    "]\n",
    "validation_causenet_metrics = validation_causenet_metrics.loc[\n",
    "    validation_causenet_metrics.dataset.isin([\"random_support\", \"random_full\"]) | \n",
    "    (validation_causenet_metrics.operator == \"p=inf_mean\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f44042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_causenet_metrics.to_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_metrics.pkl\")\n",
    ")\n",
    "validation_causenet_metrics.to_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"validation_causenet_metrics.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b55884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_support</td>\n",
       "      <td>ctakes-full</td>\n",
       "      <td>p=0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_full</td>\n",
       "      <td>ctakes-full</td>\n",
       "      <td>p=0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_support</td>\n",
       "      <td>ctakes-full</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_full</td>\n",
       "      <td>ctakes-full</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_support</td>\n",
       "      <td>ctakes-full</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531192</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-pubmed-sentence</td>\n",
       "      <td>p=neg_2_mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531194</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-scibert-pubmed-sentence</td>\n",
       "      <td>p=neg_5_mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531195</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-pubmed-sentence</td>\n",
       "      <td>p=neg_5_mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531197</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-scibert-pubmed-sentence</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531198</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-pubmed-sentence</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset                               method        operator  \\\n",
       "0        random_support                          ctakes-full             p=0   \n",
       "1           random_full                          ctakes-full             p=0   \n",
       "3        random_support                          ctakes-full       p=10_mean   \n",
       "4           random_full                          ctakes-full       p=10_mean   \n",
       "6        random_support                          ctakes-full        p=1_mean   \n",
       "...                 ...                                  ...             ...   \n",
       "1531192     random_full  health_bert-scibert-pubmed-sentence    p=neg_2_mean   \n",
       "1531194  random_support  health_bert-scibert-pubmed-sentence    p=neg_5_mean   \n",
       "1531195     random_full  health_bert-scibert-pubmed-sentence    p=neg_5_mean   \n",
       "1531197  random_support  health_bert-scibert-pubmed-sentence  p=neg_inf_mean   \n",
       "1531198     random_full  health_bert-scibert-pubmed-sentence  p=neg_inf_mean   \n",
       "\n",
       "        threshold     tp     fp     tn     fn  precision  recall        f1  \\\n",
       "0             0.0  112.0   88.0    0.0    0.0      0.560     1.0  0.717949   \n",
       "1             0.0   39.0  161.0    0.0    0.0      0.195     1.0  0.326360   \n",
       "3             0.0  112.0   88.0    0.0    0.0      0.560     1.0  0.717949   \n",
       "4             0.0   39.0  161.0    0.0    0.0      0.195     1.0  0.326360   \n",
       "6             0.0  112.0   88.0    0.0    0.0      0.560     1.0  0.717949   \n",
       "...           ...    ...    ...    ...    ...        ...     ...       ...   \n",
       "1531192       1.0    0.0    0.0  161.0   39.0        NaN     0.0       NaN   \n",
       "1531194       1.0    0.0    0.0   88.0  112.0        NaN     0.0       NaN   \n",
       "1531195       1.0    0.0    0.0  161.0   39.0        NaN     0.0       NaN   \n",
       "1531197       1.0    0.0    0.0   88.0  112.0        NaN     0.0       NaN   \n",
       "1531198       1.0    0.0    0.0  161.0   39.0        NaN     0.0       NaN   \n",
       "\n",
       "         accuracy  mcc  \n",
       "0           0.560  NaN  \n",
       "1           0.195  NaN  \n",
       "3           0.560  NaN  \n",
       "4           0.195  NaN  \n",
       "6           0.560  NaN  \n",
       "...           ...  ...  \n",
       "1531192     0.805  NaN  \n",
       "1531194     0.440  NaN  \n",
       "1531195     0.805  NaN  \n",
       "1531197     0.440  NaN  \n",
       "1531198     0.805  NaN  \n",
       "\n",
       "[1067200 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet_metrics = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"test_causenet_metrics.pkl\")\n",
    ")\n",
    "validation_causenet_metrics = pd.read_pickle(\n",
    "    os.path.join(constants.BASE_PATH, \"validation_causenet_metrics.pkl\")\n",
    ")\n",
    "test_causenet_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52cf7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_plot(methods, plot_ops, dataset, labels=None):\n",
    "    ax = None\n",
    "    idx = 0\n",
    "    styles = [\"solid\", \"dashed\", \"dashdot\", \"dotted\"]\n",
    "    for method in methods:\n",
    "        for op in plot_ops:\n",
    "            plot_data = test_causenet_metrics.loc[\n",
    "                (test_causenet_metrics.method == method)\n",
    "                & (test_causenet_metrics.operator == op)\n",
    "                & (test_causenet_metrics.dataset == dataset)\n",
    "            ]\n",
    "            plot_data = plot_data.groupby(\"recall\").precision.max().sort_index()\n",
    "            method_name = \" \".join(\n",
    "                name_dict.get(sub_method, sub_method.title())\n",
    "                for sub_method in method.split(\"_\")\n",
    "            )\n",
    "            if labels is None:\n",
    "                plot_data = plot_data.rename(\n",
    "                    f\"{method_name} ({' '.join(op.split('-')).title()})\"\n",
    "                )\n",
    "            else:\n",
    "                plot_data = plot_data.rename(labels[idx])\n",
    "            ax = plot_data.plot.line(\n",
    "                figsize=(8, 4), linewidth=2, linestyle=styles[idx % len(styles)]\n",
    "            )\n",
    "            idx += 1\n",
    "    ax.legend()\n",
    "    ax.set_xlim((0, 1.05))\n",
    "    ax.set_ylim(0.1, 1.05)\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    fig = ax.get_figure()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91b7144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc_curve(methods, ops, dataset, labels=None, ax=None, x_lim=(0, 1), y_lim=(0, 1)):\n",
    "    idx = 0\n",
    "    styles = [\"solid\", \"dashed\", \"dashdot\", \"dotted\"]\n",
    "    aucs = []\n",
    "    for method in methods:\n",
    "        for op in ops:\n",
    "            plot_data = validation_causenet_metrics.loc[\n",
    "                (validation_causenet_metrics.method == method)\n",
    "                & (validation_causenet_metrics.operator == op)\n",
    "                & (validation_causenet_metrics.dataset == dataset)\n",
    "            ].copy()\n",
    "            auc = sklearn.metrics.roc_auc_score(\n",
    "                    validation_causenet.loc[validation_causenet.dataset == dataset, \"evaluation\"],\n",
    "                    validation_causenet_combined.loc[validation_causenet.dataset == dataset].filter(\n",
    "                        like=\"-\".join((method, op))\n",
    "                    ),\n",
    "                )\n",
    "            aucs.append(auc)\n",
    "            plot_data[\"false_positive_rate\"] = plot_data[\"fp\"] / (\n",
    "                plot_data[\"fp\"] + plot_data[\"tn\"]\n",
    "            )\n",
    "            plot_data = (\n",
    "                plot_data.groupby(\"false_positive_rate\").recall.max().sort_index()\n",
    "            )\n",
    "            if labels is not None:\n",
    "                plot_data = plot_data.rename(labels[idx])\n",
    "            plot_data.plot.line(\n",
    "                linewidth=3, linestyle=styles[idx % len(styles)], ax=ax, xlabel=None\n",
    "            )\n",
    "            idx += 1\n",
    "    if labels is not None:\n",
    "        ax.legend()\n",
    "    ax.set_xlim(*x_lim)\n",
    "    ax.set_ylim(*y_lim)\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    fig = ax.get_figure()\n",
    "    return fig, aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c656876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.761926609631249, 0.8729117750249642, 0.9197545857735315, 0.9621443157998902]\n",
      "[0.9133531428571429, 0.9027565714285716, 0.8685348571428572, 0.9582537142857143]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Termhood score ROC plots + AUC\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "LARGE_SIZE = 18\n",
    "\n",
    "dataset = \"random_full\"\n",
    "\n",
    "plot_dict = {\n",
    "#     \"$n$-grams\": {\n",
    "#         \"methods\": [f\"discriminative_weight-encyclopedia-(1, {value})-1\" for value in (1, 2, 3)],\n",
    "#         \"ops\": [\"p=1_mean\"],\n",
    "#         \"labels\": [\"$n$=1\", \"$n$=2\", \"$n$=3\"],\n",
    "#     },\n",
    "#     \"$p_p$-values\": {\n",
    "#         \"methods\": [f\"discriminative_weight-encyclopedia-(1, 3)-{value}\" for value in (1, 2, 5, 10, \"inf\")],\n",
    "#         \"ops\": [\"p=1_mean\"],\n",
    "#         \"labels\": [\"1\", \"2\", \"5\", \"10\", \"$\\infty$\"],\n",
    "#     },\n",
    "#     \"Operators\": {\n",
    "#         \"methods\": [\"discriminative_weight-encyclopedia-(1, 3)-1\"],\n",
    "#         \"ops\": [\"and\"] + [f\"p={value}_mean\" for value in (1, 2, 5, 10, \"inf\")],\n",
    "#         \"labels\": [\"AND\", \"1\", \"2\", \"5\", \"10\", \"$\\infty$\"],\n",
    "#         \"x_lim\": (0.0, 0.6),\n",
    "#         \"y_lim\": (0.4, 1.0),\n",
    "#     },\n",
    "    \"PubMedBERT\": {\n",
    "        \"methods\": [f\"health_bert-pubmedbert-{corpus}-{text_format}\" for corpus in [\"pubmed\", \"encyclopedia\"] for text_format in [\"sentence\", \"noun_phrase\"]],\n",
    "        \"ops\": [\"p=inf_mean\"],\n",
    "        \"labels\": [\"PM, S\", \"PM, NP\", \"ENC, S\", \"ENC, NP\"],\n",
    "#         \"x_lim\": (0.0, 0.6),\n",
    "#         \"y_lim\": (0.4, 1.0),\n",
    "        \"dataset\": \"sentence\",\n",
    "    },\n",
    "    \"     Discriminative Weight\": {\n",
    "        \"methods\": [f\"discriminative_weight-{corpus}-(1, 1)-1\" for corpus in [\"pubmed\", \"pubmed_central\", \"textbook\", \"encyclopedia\"]],\n",
    "        \"ops\": [\"p=1_mean\"],\n",
    "        \"labels\": [\"PM\", \"PMC\", \"TB\", \"ENC\"],\n",
    "        \"dataset\": \"random_full\"\n",
    "#         \"x_lim\": (0.0, 0.6),\n",
    "#         \"y_lim\": (0.4, 1.0),\n",
    "    },\n",
    "}\n",
    "\n",
    "num_plots = len(plot_dict)\n",
    "fig, axes = plt.subplots(1, ncols=num_plots, figsize=(4 * num_plots, 3))\n",
    "for idx, (ax, (title, kwargs)) in enumerate(zip(axes, plot_dict.items())):\n",
    "    fig, aucs = auc_roc_curve(ax=ax, **kwargs)\n",
    "    for auc in aucs:\n",
    "        ax.plot([0, 1], [0, 1], alpha=0.0, label=f\"({auc:.2f})\")\n",
    "    _text = ax.text(0, 1.05, f\"({chr(97 + idx)})\", transform=ax.transAxes, size=LARGE_SIZE)\n",
    "    if idx % 2 == 1:\n",
    "        _text.set_in_layout(False)\n",
    "    print(aucs)\n",
    "    ax.set_xlabel(ax.get_xlabel(), size=LARGE_SIZE)\n",
    "    ax.set_title(title, size=LARGE_SIZE)\n",
    "    legend = ax.legend(fontsize=15, framealpha=0.0, ncol=2, columnspacing=-2.5)\n",
    "    ax.tick_params(labelsize=SMALL_SIZE)\n",
    "\n",
    "# set y_label\n",
    "axes[0].set_ylabel(\"True Positive Rate\", size=LARGE_SIZE)\n",
    "    \n",
    "plt.tight_layout(pad=0.2)\n",
    "fig.savefig(\"figures/roc_curves.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8ac1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umls-subset\n",
      "jaccard-threshold\n",
      "mesh-syn-operator\n",
      "approach\n",
      "discriminative-weight-corpora\n",
      "discriminative-weight-operator\n",
      "discriminative-weight-generalized-mean\n",
      "discriminative-weight-n-gram\n",
      "umls-subset\n",
      "jaccard-threshold\n",
      "mesh-syn-operator\n",
      "approach\n",
      "discriminative-weight-corpora\n",
      "discriminative-weight-operator\n",
      "discriminative-weight-generalized-mean\n",
      "discriminative-weight-n-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_plot_ops = [\"and\", \"or\"] + [f\"p={value}_mean\" for value in (1, 2, 5, 10, \"inf\")]\n",
    "all_plot_op_labels = [\"And\", \"Or\", \"p=1\", \"p=2\", \"p=5\", \"p=10\", \"p=inf\"]\n",
    "all_p_value_labels = [f\"p={p_value}\" for p_value in p_values]\n",
    "plot_dict = {\n",
    "    \"umls-subset\": {\n",
    "        \"methods\": [\"mesh_1.0\", \"mesh_syn_1.0\", \"umls_1.0\"],\n",
    "        \"plot_ops\": [\"and\"],\n",
    "        \"labels\": [\"MeSH\", \"MeSH Syn\", \"UMLS\"],\n",
    "    },\n",
    "    \"jaccard-threshold\": {\n",
    "        \"methods\": [\n",
    "            f\"mesh_syn_{jaccard_threshold}\"\n",
    "            for jaccard_threshold in jaccard_thresholds\n",
    "            if len(str(jaccard_threshold))\n",
    "        ][::-1],\n",
    "        \"plot_ops\": [\"and\"],\n",
    "        \"labels\": [\n",
    "            str(jaccard_threshold)\n",
    "            for jaccard_threshold in jaccard_thresholds\n",
    "            if len(str(jaccard_threshold))\n",
    "        ][::-1][::-1],\n",
    "    },\n",
    "    \"mesh-syn-operator\": {\n",
    "        \"methods\": [\"mesh_syn_1.0\"],\n",
    "        \"plot_ops\": all_plot_ops,\n",
    "        \"labels\": all_plot_op_labels,\n",
    "    },\n",
    "    \"approach\": {\n",
    "        \"methods\": [\n",
    "            \"mesh_syn_1.0\",\n",
    "            \"contrastive_weight_pubmed_(1, 1)_1\",\n",
    "            \"term_domain_specificity_pubmed_(1, 1)_1\",\n",
    "            \"discriminative_weight_pubmed_(1, 1)_1\",\n",
    "        ],\n",
    "        \"plot_ops\": [\"and\"],\n",
    "        \"labels\": [\n",
    "            \"MeSH Syn\",\n",
    "            \"Contrastive Weight\",\n",
    "            \"Term Domain Specificity\",\n",
    "            \"Discriminative Weight\",\n",
    "        ],\n",
    "    },\n",
    "    \"discriminative-weight-corpora\": {\n",
    "        \"methods\": [\n",
    "            f\"discriminative_weight_{corpus}_(1, 1)_1\" for corpus in medical_corpora\n",
    "        ],\n",
    "        \"plot_ops\": [\"and\"],\n",
    "        \"labels\": [\" \".join(corpus.split(\"_\")).title() for corpus in medical_corpora],\n",
    "    },\n",
    "    \"discriminative-weight-operator\": {\n",
    "        \"methods\": [\"discriminative_weight_encyclopedia_(1, 1)_1\"],\n",
    "        \"plot_ops\": all_plot_ops,\n",
    "        \"labels\": all_plot_op_labels,\n",
    "    },\n",
    "    \"discriminative-weight-generalized-mean\": {\n",
    "        \"methods\": [\n",
    "            f\"discriminative_weight_encyclopedia_(1, 1)_{p_value}\"\n",
    "            for p_value in p_values\n",
    "        ],\n",
    "        \"plot_ops\": [\"p=1_mean\"],\n",
    "        \"labels\": all_p_value_labels,\n",
    "    },\n",
    "    \"discriminative-weight-n-gram\": {\n",
    "        \"methods\": [\n",
    "            \"discriminative_weight_encyclopedia_(1, 1)_1\",\n",
    "            \"discriminative_weight_encyclopedia_(1, 2)_1\",\n",
    "            \"discriminative_weight_encyclopedia_(1, 3)_1\",\n",
    "        ],\n",
    "        \"plot_ops\": [\"p=1_mean\"],\n",
    "        \"labels\": [\"(1, 1)\", \"(1, 2)\", \"(1, 3)\"],\n",
    "    },\n",
    "}\n",
    "datasets = [\"random_full\", \"wikidata\"]\n",
    "for dataset in datasets:\n",
    "    for name, plot_values in plot_dict.items():\n",
    "        print(name)\n",
    "        fig = precision_recall_plot(dataset=dataset, **plot_values)\n",
    "        fig.savefig(f\"figures/{dataset}-{name}-comparison.pdf\", bbox_inches=\"tight\")\n",
    "        fig.clear(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a913a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# methods = [\"mesh_1.0\", \"mesh_syn_1.0\", \"umls_1.0\"]\n",
    "# methods = [f\"mesh_syn_{jaccard_threshold}\" for jaccard_threshold in jaccard_thresholds if len(str(jaccard_threshold))][::-1]\n",
    "# methods = [\"mesh_syn_1.0\"]\n",
    "# methods = [\"mesh_syn_1.0\", \"contrastive_weight_pubmed_(1, 1)_1\", \"term_domain_specificity_pubmed_(1, 1)_1\", \"discriminative_weight_pubmed_(1, 1)_1\"]\n",
    "methods = [f\"discriminative_weight_{corpus}_(1, 1)_1\" for corpus in medical_corpora]\n",
    "# methods = [\"discriminative_weight_encyclopedia_(1, 1)_1\"]\n",
    "# methods = [f\"discriminative_weight_encyclopedia_(1, 1)_{p_value}\" for p_value in p_values]\n",
    "# methods = [\"discriminative_weight_encyclopedia_(1, 1)_1\", \"discriminative_weight_encyclopedia_(1, 2)_1\"]\n",
    "# methods = [\"discriminative_weight_encyclopedia_(1, 1)_1\"]\n",
    "\n",
    "\n",
    "# plot_ops = [\"and\", \"or\", \"arithmetic_mean\", \"quadratic_mean\"]\n",
    "# plot_ops = [\"and\", \"arithmetic_mean\", \"quadratic_mean\"]\n",
    "# plot_ops = [\"and\", \"or\", \"arithmetic_mean\"]\n",
    "# plot_ops = [\"and\", \"arithmetic_mean\"]\n",
    "# plot_ops = [\"arithmetic_mean\"]\n",
    "plot_ops = [\"and\"]\n",
    "# plot_ops = [\"or\"]\n",
    "dataset = \"wikidata\"\n",
    "fig = precision_recall_plot(methods, plot_ops, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12b4ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"discriminative-weight-corpus\"\n",
    "fig.savefig(f\"figures/{name}-comparison.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "681919c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_approach(\n",
    "    validation_metrics,\n",
    "    test_metrics,\n",
    "    patterns,\n",
    "    datasets,\n",
    "    threshold_score,\n",
    "    threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    macro,\n",
    "    return_val=False,\n",
    "):\n",
    "    best_approaches = []\n",
    "\n",
    "    def best_run(df):\n",
    "        if threshold_score:\n",
    "            if ((df[threshold_score] < threshold) | df[threshold_score].isna()).all():\n",
    "                df = df.sort_values(threshold_score, ascending=False).iloc[[0]]\n",
    "            else:\n",
    "                df = df.loc[df[threshold_score] >= threshold]\n",
    "        df = df.sort_values(optimization_score, ascending=False).iloc[0]\n",
    "        df = df.map(lambda x: round(x, 4) if isinstance(x, (float)) else x)\n",
    "        return df\n",
    "\n",
    "    for pattern in patterns:\n",
    "        tmp = validation_metrics.loc[validation_metrics.method.str.contains(pattern)]\n",
    "        if datasets:\n",
    "            tmp = tmp.loc[tmp.dataset.isin(datasets)]\n",
    "        print(tmp.loc[~tmp.operator.isin(eval_ops)])\n",
    "        if eval_ops:\n",
    "            tmp = tmp.loc[tmp.operator.isin(eval_ops)]\n",
    "\n",
    "        best_runs = tmp.groupby(\"dataset\").apply(best_run)\n",
    "        best_approaches.append(best_runs)\n",
    "\n",
    "    idcs = np.tile(np.arange(len(patterns)), len(datasets)) * len(datasets) + np.repeat(\n",
    "        np.arange(len(datasets)), len(patterns)\n",
    "    )\n",
    "    best_approaches = (\n",
    "        pd.concat(best_approaches).reset_index(drop=True).iloc[idcs].reset_index()\n",
    "    )\n",
    "\n",
    "    if macro:\n",
    "        for pattern in patterns:\n",
    "            tmp = validation_metrics.loc[validation_metrics.method.str.contains(pattern)]\n",
    "            if datasets:\n",
    "                tmp = tmp.loc[tmp.dataset.isin(datasets)]\n",
    "            if eval_ops:\n",
    "                tmp = tmp.loc[tmp.operator.isin(eval_ops)]\n",
    "            tmp = tmp.groupby([\"method\", \"operator\", \"threshold\"]).mean().reset_index()\n",
    "            _best_run = best_run(tmp)\n",
    "            _best_run[\"dataset\"] = \"macro\"\n",
    "            best_approaches = pd.concat([best_approaches, _best_run])\n",
    "\n",
    "    best_approaches = best_approaches.drop(\"index\", axis=1)\n",
    "    best_approaches = best_approaches.reset_index(drop=True)\n",
    "    best_approaches[\"method_class\"] = best_approaches.method.apply(lambda x: x.split(\"-\")[0])\n",
    "    best_approaches.loc[best_approaches.method_class == \"health_bert\", \"method_class\"] = best_approaches.loc[best_approaches.method_class == \"health_bert\"].method.apply(lambda x: x.split(\"-\")[1])\n",
    "    validation_best_approaches = best_approaches.copy()\n",
    "    test_best_approaches = best_approaches.merge(test_metrics, how=\"left\", on=[\"dataset\", \"method\", \"operator\", \"threshold\"], suffixes=(\"_to_drop\", \"\"))\n",
    "    test_best_approaches = test_best_approaches.drop(test_best_approaches.filter(like=\"_to_drop\"), axis=1)\n",
    "    if return_val:\n",
    "        return validation_best_approaches, test_best_approaches\n",
    "    return test_best_approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93f944cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [dataset, method, operator, threshold, tp, fp, tn, fn, precision, recall, f1, accuracy, mcc]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>method_class</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_full</td>\n",
       "      <td>quickumls-rx_sno-0.8-st21pv</td>\n",
       "      <td>p=neg_1_mean</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>quickumls</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.070311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_full</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_sm-0.9-st21pv</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>0.202</td>\n",
       "      <td>scispacy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.078811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_full</td>\n",
       "      <td>ctakes-rx_sno-st21pv</td>\n",
       "      <td>p=neg_2_mean</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>ctakes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.060736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_full</td>\n",
       "      <td>metamap-rx_sno-st21pv</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>metamap</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.146909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>bert</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.801193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>scibert</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.84507</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.817903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>pubmedbert</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.852338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_full</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 2)-2</td>\n",
       "      <td>p=neg_1_mean</td>\n",
       "      <td>62.7273</td>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.733194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_full</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>1.5758</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.802674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>100.0</td>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.836723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_support</td>\n",
       "      <td>quickumls-rx_sno-1.0</td>\n",
       "      <td>p=neg_10_mean</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>quickumls</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.362565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_support</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_sm-0.7</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>scispacy</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.45122</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.180956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_support</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>ctakes</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.262266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_support</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=neg_10_mean</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>metamap</td>\n",
       "      <td>95.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.801688</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.520156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.798</td>\n",
       "      <td>bert</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.895928</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.767842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>scibert</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.852945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.798</td>\n",
       "      <td>pubmedbert</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.961165</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.92093</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.83279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>random_support</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 1)-10</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>80.9091</td>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.723214</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.680562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random_support</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>1.2121</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.80942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>random_support</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 2)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>88.8889</td>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894977</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.76903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sentence</td>\n",
       "      <td>quickumls-rx_sno-1.0-st21pv</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.303</td>\n",
       "      <td>quickumls</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.153915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sentence</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_lg-0.8</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>scispacy</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.376051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sentence</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>ctakes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.316983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sentence</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>metamap</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.153915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>bert</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.614911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>scibert</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.613713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>pubmedbert</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.639807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sentence</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 3)-5</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>62.7273</td>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.50443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.568834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sentence</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 3)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>44.4444</td>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.544879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset                                           method  \\\n",
       "0      random_full                      quickumls-rx_sno-0.8-st21pv   \n",
       "1      random_full        scispacy-rx_sno-en_core_sci_sm-0.9-st21pv   \n",
       "2      random_full                             ctakes-rx_sno-st21pv   \n",
       "3      random_full                            metamap-rx_sno-st21pv   \n",
       "4      random_full        health_bert-bert-encyclopedia-noun_phrase   \n",
       "5      random_full     health_bert-scibert-encyclopedia-noun_phrase   \n",
       "6      random_full  health_bert-pubmedbert-encyclopedia-noun_phrase   \n",
       "7      random_full         contrastive_weight-encyclopedia-(1, 2)-2   \n",
       "8      random_full    term_domain_specificity-encyclopedia-(1, 2)-1   \n",
       "9      random_full      discriminative_weight-encyclopedia-(1, 1)-1   \n",
       "10  random_support                             quickumls-rx_sno-1.0   \n",
       "11  random_support               scispacy-rx_sno-en_core_sci_sm-0.7   \n",
       "12  random_support                                    ctakes-rx_sno   \n",
       "13  random_support                                   metamap-rx_sno   \n",
       "14  random_support        health_bert-bert-encyclopedia-noun_phrase   \n",
       "15  random_support     health_bert-scibert-encyclopedia-noun_phrase   \n",
       "16  random_support  health_bert-pubmedbert-encyclopedia-noun_phrase   \n",
       "17  random_support        contrastive_weight-encyclopedia-(1, 1)-10   \n",
       "18  random_support    term_domain_specificity-encyclopedia-(1, 3)-1   \n",
       "19  random_support      discriminative_weight-encyclopedia-(1, 2)-1   \n",
       "20        sentence                      quickumls-rx_sno-1.0-st21pv   \n",
       "21        sentence               scispacy-rx_sno-en_core_sci_lg-0.8   \n",
       "22        sentence                                    ctakes-rx_sno   \n",
       "23        sentence                                   metamap-rx_sno   \n",
       "24        sentence        health_bert-bert-encyclopedia-noun_phrase   \n",
       "25        sentence     health_bert-scibert-encyclopedia-noun_phrase   \n",
       "26        sentence  health_bert-pubmedbert-encyclopedia-noun_phrase   \n",
       "27        sentence         contrastive_weight-encyclopedia-(1, 3)-5   \n",
       "28        sentence    term_domain_specificity-encyclopedia-(1, 1)-1   \n",
       "29        sentence      discriminative_weight-encyclopedia-(1, 3)-1   \n",
       "\n",
       "          operator threshold             method_class     tp    fp     tn  \\\n",
       "0     p=neg_1_mean    0.6061                quickumls    0.0   4.0  157.0   \n",
       "1   p=neg_inf_mean     0.202                 scispacy    0.0   5.0  156.0   \n",
       "2     p=neg_2_mean    0.6162                   ctakes    0.0   3.0  158.0   \n",
       "3   p=neg_inf_mean    0.6667                  metamap    2.0   1.0  160.0   \n",
       "4         p=1_mean    0.7677                     bert   30.0   3.0  158.0   \n",
       "5         p=5_mean    0.7374                  scibert   30.0   2.0  159.0   \n",
       "6         p=2_mean    0.7778               pubmedbert   32.0   2.0  159.0   \n",
       "7     p=neg_1_mean   62.7273       contrastive_weight   28.0   5.0  156.0   \n",
       "8         p=1_mean    1.5758  term_domain_specificity   27.0   0.0  161.0   \n",
       "9         p=1_mean     100.0    discriminative_weight   29.0   0.0  161.0   \n",
       "10   p=neg_10_mean    0.8889                quickumls   52.0  11.0   77.0   \n",
       "11        p=2_mean    0.8586                 scispacy   37.0  15.0   73.0   \n",
       "12  p=neg_inf_mean    0.8788                   ctakes   38.0  10.0   78.0   \n",
       "13   p=neg_10_mean    0.7475                  metamap   95.0  30.0   58.0   \n",
       "14        p=5_mean     0.798                     bert   99.0  10.0   78.0   \n",
       "15       p=10_mean    0.7576                  scibert  100.0   3.0   85.0   \n",
       "16        p=5_mean     0.798               pubmedbert   99.0   4.0   84.0   \n",
       "17        p=5_mean   80.9091       contrastive_weight   81.0   4.0   84.0   \n",
       "18        p=1_mean    1.2121  term_domain_specificity  100.0   7.0   81.0   \n",
       "19        p=1_mean   88.8889    discriminative_weight   98.0   9.0   79.0   \n",
       "20      p=inf_mean     0.303                quickumls    1.0   0.0  165.0   \n",
       "21      p=inf_mean    0.5758                 scispacy    7.0   1.0  164.0   \n",
       "22      p=inf_mean    0.6162                   ctakes    7.0   3.0  162.0   \n",
       "23      p=inf_mean    0.8586                  metamap    1.0   0.0  165.0   \n",
       "24      p=inf_mean    0.7879                     bert   18.0   3.0  162.0   \n",
       "25      p=inf_mean    0.7879                  scibert   17.0   2.0  163.0   \n",
       "26      p=inf_mean    0.7475               pubmedbert   20.0   4.0  161.0   \n",
       "27      p=inf_mean   62.7273       contrastive_weight   15.0   5.0  160.0   \n",
       "28      p=inf_mean    0.7273  term_domain_specificity   16.0   3.0  162.0   \n",
       "29      p=inf_mean   44.4444    discriminative_weight   15.0   3.0  162.0   \n",
       "\n",
       "      fn precision    recall        f1 accuracy       mcc  \n",
       "0   39.0       0.0       0.0       NaN    0.785 -0.070311  \n",
       "1   39.0       0.0       0.0       NaN     0.78 -0.078811  \n",
       "2   39.0       0.0       0.0       NaN     0.79 -0.060736  \n",
       "3   37.0  0.666667  0.051282  0.095238     0.81  0.146909  \n",
       "4    9.0  0.909091  0.769231  0.833333     0.94  0.801193  \n",
       "5    9.0    0.9375  0.769231   0.84507    0.945  0.817903  \n",
       "6    7.0  0.941176  0.820513  0.876712    0.955  0.852338  \n",
       "7   11.0  0.848485  0.717949  0.777778     0.92  0.733194  \n",
       "8   12.0       1.0  0.692308  0.818182     0.94  0.802674  \n",
       "9   10.0       1.0   0.74359  0.852941     0.95  0.836723  \n",
       "10  60.0  0.825397  0.464286  0.594286    0.645  0.362565  \n",
       "11  75.0  0.711538  0.330357   0.45122     0.55  0.180956  \n",
       "12  74.0  0.791667  0.339286     0.475     0.58  0.262266  \n",
       "13  17.0      0.76  0.848214  0.801688    0.765  0.520156  \n",
       "14  13.0  0.908257  0.883929  0.895928    0.885  0.767842  \n",
       "15  12.0  0.970874  0.892857  0.930233    0.925  0.852945  \n",
       "16  13.0  0.961165  0.883929   0.92093    0.915   0.83279  \n",
       "17  31.0  0.952941  0.723214  0.822335    0.825  0.680562  \n",
       "18  12.0  0.934579  0.892857  0.913242    0.905   0.80942  \n",
       "19  14.0  0.915888     0.875  0.894977    0.885   0.76903  \n",
       "20  34.0       1.0  0.028571  0.055556     0.83  0.153915  \n",
       "21  28.0     0.875       0.2  0.325581    0.855  0.376051  \n",
       "22  28.0       0.7       0.2  0.311111    0.845  0.316983  \n",
       "23  34.0       1.0  0.028571  0.055556     0.83  0.153915  \n",
       "24  17.0  0.857143  0.514286  0.642857      0.9  0.614911  \n",
       "25  18.0  0.894737  0.485714   0.62963      0.9  0.613713  \n",
       "26  15.0  0.833333  0.571429  0.677966    0.905  0.639807  \n",
       "27  20.0      0.75  0.428571  0.545455    0.875   0.50443  \n",
       "28  19.0  0.842105  0.457143  0.592593     0.89  0.568834  \n",
       "29  20.0  0.833333  0.428571  0.566038    0.885  0.544879  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = [\n",
    "    \"quickumls\",\n",
    "    \"scispacy\",\n",
    "    \"ctakes\",\n",
    "    \"metamap\",\n",
    "    \"-bert\",\n",
    "    \"scibert\",\n",
    "    \"pubmedbert\",\n",
    "    \"contrastive\",\n",
    "    \"specificity\",\n",
    "    \"discriminative\",\n",
    "]\n",
    "# patterns = [\"mesh_[0-9]\", \"mesh_syn_[0-9]\", \"umls_[0-9]\", \"contrastive_weight_1\", \"term_domain_specificity_1\", \"discriminative_weight_1\"]\n",
    "# patterns = [\"discriminative_weight_pubmed_(1, 2)_1\"]\n",
    "# patterns = [\"contrastive\", \"specificity\", \"discriminative\"]\n",
    "threshold_score = \"precision\"\n",
    "threshold = 0.9\n",
    "optimization_score = \"recall\"\n",
    "datasets = [\n",
    "    \"random_full\",\n",
    "    \"random_support\",\n",
    "    \"sentence\",\n",
    "]\n",
    "macro = False\n",
    "eval_ops = (\n",
    "    [\"p=0_mean\"]\n",
    "    + [f\"p={p}_mean\" for p in (1, 2, 5, 10, \"inf\")]\n",
    "    + [f\"p=neg_{p}_mean\" for p in (1, 2, 5, 10, \"inf\")]\n",
    ")\n",
    "\n",
    "validation_best_approaches, test_best_approaches = best_approach(\n",
    "    validation_causenet_metrics,\n",
    "    test_causenet_metrics,\n",
    "    patterns,\n",
    "    datasets,\n",
    "    threshold_score,\n",
    "    threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    macro,\n",
    "    return_val=True\n",
    ")\n",
    "\n",
    "if threshold_score:\n",
    "    validation_best_approaches.to_csv(f\"validation_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\")\n",
    "    test_best_approaches.to_csv(f\"test_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\")\n",
    "else:\n",
    "    validation_best_approaches.to_csv(f\"validation_best_approaches_{optimization_score}.csv\")\n",
    "    test_best_approaches.to_csv(f\"test_best_approaches_{optimization_score}.csv\")\n",
    "test_best_approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a465cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056000</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-0</td>\n",
       "      <td>p=0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056003</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-0</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056006</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-0</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056009</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-0</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056012</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-0</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491585</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-textbook-(1, 3)-neg_inf</td>\n",
       "      <td>p=neg_10_mean</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491588</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-textbook-(1, 3)-neg_inf</td>\n",
       "      <td>p=neg_1_mean</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491591</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-textbook-(1, 3)-neg_inf</td>\n",
       "      <td>p=neg_2_mean</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491594</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-textbook-(1, 3)-neg_inf</td>\n",
       "      <td>p=neg_5_mean</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491597</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-textbook-(1, 3)-neg_inf</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset                                         method  \\\n",
       "1056000  random_full    discriminative_weight-encyclopedia-(1, 1)-0   \n",
       "1056003  random_full    discriminative_weight-encyclopedia-(1, 1)-0   \n",
       "1056006  random_full    discriminative_weight-encyclopedia-(1, 1)-0   \n",
       "1056009  random_full    discriminative_weight-encyclopedia-(1, 1)-0   \n",
       "1056012  random_full    discriminative_weight-encyclopedia-(1, 1)-0   \n",
       "...              ...                                            ...   \n",
       "1491585  random_full  discriminative_weight-textbook-(1, 3)-neg_inf   \n",
       "1491588  random_full  discriminative_weight-textbook-(1, 3)-neg_inf   \n",
       "1491591  random_full  discriminative_weight-textbook-(1, 3)-neg_inf   \n",
       "1491594  random_full  discriminative_weight-textbook-(1, 3)-neg_inf   \n",
       "1491597  random_full  discriminative_weight-textbook-(1, 3)-neg_inf   \n",
       "\n",
       "               operator threshold     tp     fp     tn     fn  precision  \\\n",
       "1056000             p=0       0.0  175.0  625.0    0.0    0.0    0.21875   \n",
       "1056003       p=10_mean       0.0  175.0  625.0    0.0    0.0    0.21875   \n",
       "1056006        p=1_mean       0.0  175.0  625.0    0.0    0.0    0.21875   \n",
       "1056009        p=2_mean       0.0  175.0  625.0    0.0    0.0    0.21875   \n",
       "1056012        p=5_mean       0.0  175.0  625.0    0.0    0.0    0.21875   \n",
       "...                 ...       ...    ...    ...    ...    ...        ...   \n",
       "1491585   p=neg_10_mean    1100.0    0.0    0.0  625.0  175.0        NaN   \n",
       "1491588    p=neg_1_mean    1100.0    0.0    0.0  625.0  175.0        NaN   \n",
       "1491591    p=neg_2_mean    1100.0    0.0    0.0  625.0  175.0        NaN   \n",
       "1491594    p=neg_5_mean    1100.0    0.0    0.0  625.0  175.0        NaN   \n",
       "1491597  p=neg_inf_mean    1100.0    0.0    0.0  625.0  175.0        NaN   \n",
       "\n",
       "         recall        f1  accuracy  mcc  \n",
       "1056000     1.0  0.358974   0.21875  NaN  \n",
       "1056003     1.0  0.358974   0.21875  NaN  \n",
       "1056006     1.0  0.358974   0.21875  NaN  \n",
       "1056009     1.0  0.358974   0.21875  NaN  \n",
       "1056012     1.0  0.358974   0.21875  NaN  \n",
       "...         ...       ...       ...  ...  \n",
       "1491585     0.0       NaN   0.78125  NaN  \n",
       "1491588     0.0       NaN   0.78125  NaN  \n",
       "1491591     0.0       NaN   0.78125  NaN  \n",
       "1491594     0.0       NaN   0.78125  NaN  \n",
       "1491597     0.0       NaN   0.78125  NaN  \n",
       "\n",
       "[145200 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = validation_causenet_metrics.loc[(validation_causenet_metrics.dataset == \"random_full\") & validation_causenet_metrics.method.str.contains(\"discri\")]\n",
    "# tmp = tmp.loc[tmp.precision > 0.9].sort_values(\"recall\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "574afe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>method_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_full</td>\n",
       "      <td>quickumls-rx_sno-0.8-st21pv</td>\n",
       "      <td>p=neg_1_mean</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_full</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_sm-0.9-st21pv</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>0.202</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_full</td>\n",
       "      <td>ctakes-rx_sno-st21pv</td>\n",
       "      <td>p=neg_2_mean</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_full</td>\n",
       "      <td>metamap-rx_sno-st21pv</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>127.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>126.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9212</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>128.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.8101</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_full</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 2)-2</td>\n",
       "      <td>p=neg_1_mean</td>\n",
       "      <td>62.7273</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_full</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>1.5758</td>\n",
       "      <td>109.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.6229</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_support</td>\n",
       "      <td>quickumls-rx_sno-1.0</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>170.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.5601</td>\n",
       "      <td>0.6662</td>\n",
       "      <td>0.3629</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_support</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_sm-0.7</td>\n",
       "      <td>p=neg_inf_mean</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>133.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_support</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>132.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.3376</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_support</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=neg_5_mean</td>\n",
       "      <td>0.798</td>\n",
       "      <td>330.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.798</td>\n",
       "      <td>340.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>334.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.798</td>\n",
       "      <td>346.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>random_support</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 1)-10</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>80.9091</td>\n",
       "      <td>273.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random_support</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>1.2121</td>\n",
       "      <td>346.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>random_support</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 2)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>88.8889</td>\n",
       "      <td>338.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sentence</td>\n",
       "      <td>quickumls-rx_sno-1.0-st21pv</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.303</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.1826</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sentence</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_lg-0.8</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sentence</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sentence</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.1826</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.5307</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>125.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sentence</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 3)-5</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>62.7273</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>0.8762</td>\n",
       "      <td>0.6136</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sentence</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 3)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>44.4444</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.5363</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset                                           method  \\\n",
       "0      random_full                      quickumls-rx_sno-0.8-st21pv   \n",
       "1      random_full        scispacy-rx_sno-en_core_sci_sm-0.9-st21pv   \n",
       "2      random_full                             ctakes-rx_sno-st21pv   \n",
       "3      random_full                            metamap-rx_sno-st21pv   \n",
       "4      random_full        health_bert-bert-encyclopedia-noun_phrase   \n",
       "5      random_full     health_bert-scibert-encyclopedia-noun_phrase   \n",
       "6      random_full  health_bert-pubmedbert-encyclopedia-noun_phrase   \n",
       "7      random_full         contrastive_weight-encyclopedia-(1, 2)-2   \n",
       "8      random_full    term_domain_specificity-encyclopedia-(1, 2)-1   \n",
       "9      random_full      discriminative_weight-encyclopedia-(1, 1)-1   \n",
       "10  random_support                             quickumls-rx_sno-1.0   \n",
       "11  random_support               scispacy-rx_sno-en_core_sci_sm-0.7   \n",
       "12  random_support                                    ctakes-rx_sno   \n",
       "13  random_support                                   metamap-rx_sno   \n",
       "14  random_support        health_bert-bert-encyclopedia-noun_phrase   \n",
       "15  random_support     health_bert-scibert-encyclopedia-noun_phrase   \n",
       "16  random_support  health_bert-pubmedbert-encyclopedia-noun_phrase   \n",
       "17  random_support        contrastive_weight-encyclopedia-(1, 1)-10   \n",
       "18  random_support    term_domain_specificity-encyclopedia-(1, 3)-1   \n",
       "19  random_support      discriminative_weight-encyclopedia-(1, 2)-1   \n",
       "20        sentence                      quickumls-rx_sno-1.0-st21pv   \n",
       "21        sentence               scispacy-rx_sno-en_core_sci_lg-0.8   \n",
       "22        sentence                                    ctakes-rx_sno   \n",
       "23        sentence                                   metamap-rx_sno   \n",
       "24        sentence        health_bert-bert-encyclopedia-noun_phrase   \n",
       "25        sentence     health_bert-scibert-encyclopedia-noun_phrase   \n",
       "26        sentence  health_bert-pubmedbert-encyclopedia-noun_phrase   \n",
       "27        sentence         contrastive_weight-encyclopedia-(1, 3)-5   \n",
       "28        sentence    term_domain_specificity-encyclopedia-(1, 1)-1   \n",
       "29        sentence      discriminative_weight-encyclopedia-(1, 3)-1   \n",
       "\n",
       "          operator threshold     tp     fp     tn     fn  precision  recall  \\\n",
       "0     p=neg_1_mean    0.6061    6.0    0.0  625.0  169.0     1.0000  0.0343   \n",
       "1   p=neg_inf_mean     0.202    5.0    0.0  625.0  170.0     1.0000  0.0286   \n",
       "2     p=neg_2_mean    0.6162    4.0    0.0  625.0  171.0     1.0000  0.0229   \n",
       "3   p=neg_inf_mean    0.6667    2.0    0.0  625.0  173.0     1.0000  0.0114   \n",
       "4         p=1_mean    0.7677  127.0   14.0  611.0   48.0     0.9007  0.7257   \n",
       "5         p=5_mean    0.7374  126.0   14.0  611.0   49.0     0.9000  0.7200   \n",
       "6         p=2_mean    0.7778  128.0   13.0  612.0   47.0     0.9078  0.7314   \n",
       "7     p=neg_1_mean   62.7273   95.0   10.0  615.0   80.0     0.9048  0.5429   \n",
       "8         p=1_mean    1.5758  109.0   12.0  613.0   66.0     0.9008  0.6229   \n",
       "9         p=1_mean     100.0  108.0   12.0  613.0   67.0     0.9000  0.6171   \n",
       "10       p=10_mean    0.9899  170.0   46.0  363.0  221.0     0.7870  0.4348   \n",
       "11  p=neg_inf_mean    0.7475  133.0   41.0  368.0  258.0     0.7644  0.3402   \n",
       "12        p=1_mean    0.9293  132.0   35.0  374.0  259.0     0.7904  0.3376   \n",
       "13    p=neg_5_mean     0.798  330.0  141.0  268.0   61.0     0.7006  0.8440   \n",
       "14        p=5_mean     0.798  340.0   32.0  377.0   51.0     0.9140  0.8696   \n",
       "15       p=10_mean    0.7576  334.0   35.0  374.0   57.0     0.9051  0.8542   \n",
       "16        p=5_mean     0.798  346.0   36.0  373.0   45.0     0.9058  0.8849   \n",
       "17        p=5_mean   80.9091  273.0   30.0  379.0  118.0     0.9010  0.6982   \n",
       "18        p=1_mean    1.2121  346.0   37.0  372.0   45.0     0.9034  0.8849   \n",
       "19        p=1_mean   88.8889  338.0   36.0  373.0   53.0     0.9037  0.8645   \n",
       "20      p=inf_mean     0.303    9.0    1.0  620.0  170.0     0.9000  0.0503   \n",
       "21      p=inf_mean    0.5758   30.0    3.0  618.0  149.0     0.9091  0.1676   \n",
       "22      p=inf_mean    0.6162   29.0    3.0  618.0  150.0     0.9062  0.1620   \n",
       "23      p=inf_mean    0.8586    9.0    1.0  620.0  170.0     0.9000  0.0503   \n",
       "24      p=inf_mean    0.7879  121.0   12.0  609.0   58.0     0.9098  0.6760   \n",
       "25      p=inf_mean    0.7879   95.0   10.0  611.0   84.0     0.9048  0.5307   \n",
       "26      p=inf_mean    0.7475  125.0   13.0  608.0   54.0     0.9058  0.6983   \n",
       "27      p=inf_mean   62.7273   89.0    9.0  612.0   90.0     0.9082  0.4972   \n",
       "28      p=inf_mean    0.7273   92.0    7.0  614.0   87.0     0.9293  0.5140   \n",
       "29      p=inf_mean   44.4444   96.0    6.0  615.0   83.0     0.9412  0.5363   \n",
       "\n",
       "        f1  accuracy     mcc             method_class  \n",
       "0   0.0663    0.7887  0.1643                quickumls  \n",
       "1   0.0556    0.7875  0.1499                 scispacy  \n",
       "2   0.0447    0.7862  0.1340                   ctakes  \n",
       "3   0.0226    0.7837  0.0946                  metamap  \n",
       "4   0.8038    0.9225  0.7631                     bert  \n",
       "5   0.8000    0.9212  0.7590                  scibert  \n",
       "6   0.8101    0.9250  0.7710               pubmedbert  \n",
       "7   0.6786    0.8875  0.6450       contrastive_weight  \n",
       "8   0.7365    0.9025  0.6965  term_domain_specificity  \n",
       "9   0.7322    0.9012  0.6923    discriminative_weight  \n",
       "10  0.5601    0.6662  0.3629                quickumls  \n",
       "11  0.4708    0.6262  0.2907                 scispacy  \n",
       "12  0.4731    0.6325  0.3100                   ctakes  \n",
       "13  0.7657    0.7475  0.5072                  metamap  \n",
       "14  0.8912    0.8962  0.7931                     bert  \n",
       "15  0.8789    0.8850  0.7708                  scibert  \n",
       "16  0.8952    0.8988  0.7975               pubmedbert  \n",
       "17  0.7867    0.8150  0.6439       contrastive_weight  \n",
       "18  0.8941    0.8975  0.7950  term_domain_specificity  \n",
       "19  0.8837    0.8888  0.7779    discriminative_weight  \n",
       "20  0.0952    0.7862  0.1826                quickumls  \n",
       "21  0.2830    0.8100  0.3411                 scispacy  \n",
       "22  0.2749    0.8088  0.3343                   ctakes  \n",
       "23  0.0952    0.7862  0.1826                  metamap  \n",
       "24  0.7756    0.9125  0.7351                     bert  \n",
       "25  0.6690    0.8825  0.6351                  scibert  \n",
       "26  0.7886    0.9162  0.7472               pubmedbert  \n",
       "27  0.6426    0.8762  0.6136       contrastive_weight  \n",
       "28  0.6619    0.8825  0.6362  term_domain_specificity  \n",
       "29  0.6833    0.8888  0.6581    discriminative_weight  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_best_approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a9357134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>method_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>random_full</td>\n",
       "      <td>quickumls-rx_sno-0.8</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>158.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>random_full</td>\n",
       "      <td>scispacy-full-en_core_sci_lg-0.6</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>158.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3173</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>random_full</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>159.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>random_full</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>158.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.4136</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>159.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.7743</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>158.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>159.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.7571</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>random_full</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 3)-5</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>59.0909</td>\n",
       "      <td>160.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>random_full</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-0</td>\n",
       "      <td>p=neg_1_mean</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>161.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 3)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>55.5556</td>\n",
       "      <td>158.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.7194</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>random_support</td>\n",
       "      <td>quickumls-rx_sno-0.9</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>352.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>random_support</td>\n",
       "      <td>scispacy-full-en_core_sci_lg-0.7</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>362.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>random_support</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>371.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5621</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>random_support</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=neg_2_mean</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>370.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>352.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=5_mean</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>356.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>random_support</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>354.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.8917</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.7854</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>random_support</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 1)-10</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>352.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>random_support</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-1</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>1.1515</td>\n",
       "      <td>355.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>random_support</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 3)-10</td>\n",
       "      <td>p=1_mean</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>353.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>sentence</td>\n",
       "      <td>quickumls-rx_sno-1.0</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>162.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.5201</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>sentence</td>\n",
       "      <td>scispacy-full-en_core_sci_sm-0.8</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>162.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3227</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.4758</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>sentence</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>162.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2924</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>sentence</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>165.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.3852</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>162.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>162.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6022</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>sentence</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=2_mean</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>162.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>sentence</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 1)-10</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>66.3636</td>\n",
       "      <td>163.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-2</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>162.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.7431</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.6712</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>sentence</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 1)-2</td>\n",
       "      <td>p=10_mean</td>\n",
       "      <td>55.5556</td>\n",
       "      <td>163.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         dataset  \\\n",
       "0            0     random_full   \n",
       "1            1     random_full   \n",
       "2            2     random_full   \n",
       "3            3     random_full   \n",
       "4            4     random_full   \n",
       "5            5     random_full   \n",
       "6            6     random_full   \n",
       "7            7     random_full   \n",
       "8            8     random_full   \n",
       "9            9     random_full   \n",
       "10          10  random_support   \n",
       "11          11  random_support   \n",
       "12          12  random_support   \n",
       "13          13  random_support   \n",
       "14          14  random_support   \n",
       "15          15  random_support   \n",
       "16          16  random_support   \n",
       "17          17  random_support   \n",
       "18          18  random_support   \n",
       "19          19  random_support   \n",
       "20          20        sentence   \n",
       "21          21        sentence   \n",
       "22          22        sentence   \n",
       "23          23        sentence   \n",
       "24          24        sentence   \n",
       "25          25        sentence   \n",
       "26          26        sentence   \n",
       "27          27        sentence   \n",
       "28          28        sentence   \n",
       "29          29        sentence   \n",
       "\n",
       "                                             method      operator  threshold  \\\n",
       "0                              quickumls-rx_sno-0.8      p=2_mean     0.4949   \n",
       "1                  scispacy-full-en_core_sci_lg-0.6      p=2_mean     0.7879   \n",
       "2                                     ctakes-rx_sno      p=2_mean     0.3131   \n",
       "3                                    metamap-rx_sno      p=2_mean     0.7273   \n",
       "4         health_bert-bert-encyclopedia-noun_phrase      p=5_mean     0.7374   \n",
       "5      health_bert-scibert-encyclopedia-noun_phrase      p=2_mean     0.5859   \n",
       "6   health_bert-pubmedbert-encyclopedia-noun_phrase      p=1_mean     0.6061   \n",
       "7          contrastive_weight-encyclopedia-(1, 3)-5      p=2_mean    59.0909   \n",
       "8     term_domain_specificity-encyclopedia-(1, 2)-0  p=neg_1_mean     0.4242   \n",
       "9       discriminative_weight-encyclopedia-(1, 3)-1    p=inf_mean    55.5556   \n",
       "10                             quickumls-rx_sno-0.9      p=2_mean     0.6364   \n",
       "11                 scispacy-full-en_core_sci_lg-0.7      p=2_mean     0.7879   \n",
       "12                                    ctakes-rx_sno      p=2_mean     0.3131   \n",
       "13                                   metamap-rx_sno  p=neg_2_mean     0.6263   \n",
       "14        health_bert-bert-encyclopedia-noun_phrase     p=10_mean     0.8081   \n",
       "15     health_bert-scibert-encyclopedia-noun_phrase      p=5_mean     0.7172   \n",
       "16  health_bert-pubmedbert-encyclopedia-noun_phrase      p=2_mean     0.7273   \n",
       "17        contrastive_weight-encyclopedia-(1, 1)-10      p=2_mean    70.0000   \n",
       "18    term_domain_specificity-encyclopedia-(1, 2)-1      p=1_mean     1.1515   \n",
       "19     discriminative_weight-encyclopedia-(1, 3)-10      p=1_mean   100.0000   \n",
       "20                             quickumls-rx_sno-1.0     p=10_mean     0.2525   \n",
       "21                 scispacy-full-en_core_sci_sm-0.8      p=2_mean     0.3232   \n",
       "22                                    ctakes-rx_sno    p=inf_mean     0.1818   \n",
       "23                                   metamap-rx_sno    p=inf_mean     0.4949   \n",
       "24        health_bert-bert-encyclopedia-noun_phrase    p=inf_mean     0.5455   \n",
       "25     health_bert-scibert-encyclopedia-noun_phrase     p=10_mean     0.2828   \n",
       "26  health_bert-pubmedbert-encyclopedia-noun_phrase      p=2_mean     0.3030   \n",
       "27        contrastive_weight-encyclopedia-(1, 1)-10     p=10_mean    66.3636   \n",
       "28    term_domain_specificity-encyclopedia-(1, 1)-2     p=10_mean     0.6667   \n",
       "29      discriminative_weight-encyclopedia-(1, 1)-2     p=10_mean    55.5556   \n",
       "\n",
       "       tp     fp     tn    fn  precision  recall      f1  accuracy     mcc  \\\n",
       "0   158.0  278.0  347.0  17.0     0.3624  0.9029  0.5172    0.6312  0.3803   \n",
       "1   158.0  340.0  285.0  17.0     0.3173  0.9029  0.4695    0.5538  0.3060   \n",
       "2   159.0  363.0  262.0  16.0     0.3046  0.9086  0.4562    0.5262  0.2846   \n",
       "3   158.0  224.0  401.0  17.0     0.4136  0.9029  0.5673    0.6988  0.4506   \n",
       "4   159.0   52.0  573.0  16.0     0.7536  0.9086  0.8238    0.9150  0.7743   \n",
       "5   158.0   58.0  567.0  17.0     0.7315  0.9029  0.8082    0.9062  0.7543   \n",
       "6   159.0   51.0  574.0  16.0     0.7571  0.9086  0.8260    0.9162  0.7770   \n",
       "7   160.0   98.0  527.0  15.0     0.6202  0.9143  0.7390    0.8588  0.6699   \n",
       "8   161.0   75.0  550.0  14.0     0.6822  0.9200  0.7835    0.8888  0.7252   \n",
       "9   158.0   72.0  553.0  17.0     0.6870  0.9029  0.7802    0.8888  0.7194   \n",
       "10  352.0  214.0  195.0  39.0     0.6219  0.9003  0.7356    0.6838  0.4143   \n",
       "11  362.0  276.0  133.0  29.0     0.5674  0.9258  0.7036    0.6188  0.3122   \n",
       "12  371.0  289.0  120.0  20.0     0.5621  0.9488  0.7060    0.6138  0.3187   \n",
       "13  370.0  205.0  204.0  21.0     0.6435  0.9463  0.7660    0.7175  0.4948   \n",
       "14  352.0   50.0  359.0  39.0     0.8756  0.9003  0.8878    0.8888  0.7778   \n",
       "15  356.0   48.0  361.0  35.0     0.8812  0.9105  0.8956    0.8962  0.7930   \n",
       "16  354.0   49.0  360.0  37.0     0.8784  0.9054  0.8917    0.8925  0.7854   \n",
       "17  352.0   93.0  316.0  39.0     0.7910  0.9003  0.8421    0.8350  0.6770   \n",
       "18  355.0   44.0  365.0  36.0     0.8897  0.9079  0.8987    0.9000  0.8001   \n",
       "19  353.0   51.0  358.0  38.0     0.8738  0.9028  0.8881    0.8888  0.7780   \n",
       "20  162.0  282.0  339.0  17.0     0.3649  0.9050  0.5201    0.6262  0.3781   \n",
       "21  162.0  340.0  281.0  17.0     0.3227  0.9050  0.4758    0.5538  0.3082   \n",
       "22  162.0  392.0  229.0  17.0     0.2924  0.9050  0.4420    0.4888  0.2473   \n",
       "23  165.0  288.0  333.0  14.0     0.3642  0.9218  0.5222    0.6225  0.3852   \n",
       "24  162.0   80.0  541.0  17.0     0.6694  0.9050  0.7696    0.8788  0.7042   \n",
       "25  162.0  107.0  514.0  17.0     0.6022  0.9050  0.7232    0.8450  0.6464   \n",
       "26  162.0   76.0  545.0  17.0     0.6807  0.9050  0.7770    0.8838  0.7135   \n",
       "27  163.0   85.0  536.0  16.0     0.6573  0.9106  0.7635    0.8738  0.6972   \n",
       "28  162.0   95.0  526.0  17.0     0.6304  0.9050  0.7431    0.8600  0.6712   \n",
       "29  163.0   76.0  545.0  16.0     0.6820  0.9106  0.7799    0.8850  0.7177   \n",
       "\n",
       "               method_class  \n",
       "0                 quickumls  \n",
       "1                  scispacy  \n",
       "2                    ctakes  \n",
       "3                   metamap  \n",
       "4                      bert  \n",
       "5                   scibert  \n",
       "6                pubmedbert  \n",
       "7        contrastive_weight  \n",
       "8   term_domain_specificity  \n",
       "9     discriminative_weight  \n",
       "10                quickumls  \n",
       "11                 scispacy  \n",
       "12                   ctakes  \n",
       "13                  metamap  \n",
       "14                     bert  \n",
       "15                  scibert  \n",
       "16               pubmedbert  \n",
       "17       contrastive_weight  \n",
       "18  term_domain_specificity  \n",
       "19    discriminative_weight  \n",
       "20                quickumls  \n",
       "21                 scispacy  \n",
       "22                   ctakes  \n",
       "23                  metamap  \n",
       "24                     bert  \n",
       "25                  scibert  \n",
       "26               pubmedbert  \n",
       "27       contrastive_weight  \n",
       "28  term_domain_specificity  \n",
       "29    discriminative_weight  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_score = \"recall\"\n",
    "threshold = 0.9\n",
    "optimization_score = \"precision\"\n",
    "pd.read_csv(f\"validation_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac0205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d262bc2db33749e6a4a1a6307fb01fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac6f684dacf4213a0f4581e41572949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe5663f37434ad7879445f6559d7c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cc587696984efaa2d28351e6726d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mcc(samples, labels):\n",
    "    tp = (samples & labels).sum()\n",
    "    tn = (~samples & ~labels).sum()\n",
    "    fp = (samples & ~labels).sum()\n",
    "    fn = (~samples & labels).sum()\n",
    "    numerator = tp * tn - fp * fn\n",
    "    denominator = np.log([tp + fp, tp + fn, tn + fp, tn + fn]).sum() * (1 / 2)\n",
    "    mcc = numerator / np.exp(denominator)\n",
    "    return mcc\n",
    "\n",
    "def precision(samples, labels):\n",
    "    tp = (samples & labels).sum()\n",
    "    fp = (samples & ~labels).sum()\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(samples, labels):\n",
    "    tp = (samples & labels).sum()\n",
    "    fn = (~samples & labels).sum()\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "\n",
    "def bootstrap(sample_x, sample_y, labels, metric, n):\n",
    "    base_value = metric(sample_x, labels) - metric(sample_y, labels)\n",
    "    pooled = list(sample_x) + list(sample_y)\n",
    "    num_samples = len(pooled) // 2\n",
    "    metrics = []\n",
    "    for _ in tqdm(range(n), position=3, leave=False):\n",
    "        permutation = np.random.permutation(pooled)\n",
    "        sampled_x = permutation[:num_samples]\n",
    "        sampled_y = permutation[num_samples:]\n",
    "        sampled_metric = metric(sampled_x, labels) - metric(sampled_y, labels)\n",
    "        metrics.append(sampled_metric)\n",
    "    metrics = np.array(metrics)\n",
    "    percentile = sum(base_value > metrics) / n\n",
    "    return percentile\n",
    "\n",
    "def significance_test(df, optimization_func, n=5000):\n",
    "    rows = df.method.apply(lambda x: x.split(\"-\")[0])\n",
    "    percentiles = pd.DataFrame(np.nan, index=rows, columns=rows)\n",
    "    name = df.name\n",
    "    if df.name not in test_causenet.dataset.unique().tolist():\n",
    "        return percentiles\n",
    "#     print(f\"{name:<30}\", end=\"\\r\")\n",
    "    df = df.copy()\n",
    "    df[\"approach_name\"] = (\n",
    "        df.method + \"-\" + df.operator + \"-\" + df.threshold.astype(str) + \"-medical\"\n",
    "    )\n",
    "    value_bool = (test_causenet.dataset == name)\n",
    "    for approach_1_idx, (_, approach_1) in tqdm(list(enumerate(df.iterrows())), position=1, leave=False):\n",
    "        samples_1 = test_causenet_medical.loc[value_bool, approach_1.approach_name].values\n",
    "        for approach_2_idx, (_, approach_2) in tqdm(list(enumerate(df.iterrows())), position=2, leave=False):\n",
    "            if approach_1_idx >= approach_2_idx:\n",
    "                continue\n",
    "            samples_2 = test_causenet_medical.loc[value_bool, approach_2.approach_name].values\n",
    "            percentile = bootstrap(\n",
    "                samples_1, samples_2, test_causenet.loc[value_bool, \"evaluation\"], optimization_func, n\n",
    "            )\n",
    "            percentiles.iloc[approach_1_idx, approach_2_idx] = percentile\n",
    "            percentiles.iloc[approach_2_idx, approach_1_idx] = 1 - percentile\n",
    "    return percentiles\n",
    "\n",
    "\n",
    "n = 100000\n",
    "threshold_score = \"\"\n",
    "threshold = 0.9\n",
    "optimization_score = \"mcc\"\n",
    "if threshold_score:\n",
    "    significance_approaches = pd.read_csv(f\"test_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\")\n",
    "else:\n",
    "    significance_approaches = pd.read_csv(f\"test_best_approaches_{optimization_score}.csv\")\n",
    "\n",
    "\n",
    "if optimization_score == \"precision\":\n",
    "    optimization_func = precision\n",
    "elif optimization_score == \"recall\":\n",
    "    optimization_func = recall\n",
    "elif optimization_score == \"mcc\":\n",
    "    optimization_func = mcc\n",
    "else:\n",
    "    optimization_func = None\n",
    "    \n",
    "significance = (\n",
    "    significance_approaches.groupby(\"dataset\")\n",
    "    .progress_apply(lambda x: significance_test(x, optimization_func, n=n))\n",
    "    .drop(\"macro\", level=0, errors=\"ignore\")\n",
    ")\n",
    "\n",
    "if threshold_score:\n",
    "    significance.to_csv(f\"significance_{optimization_score}_{threshold_score}_{threshold}.csv\")\n",
    "else:\n",
    "    significance.to_csv(f\"significance_{optimization_score}.csv\")\n",
    "significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4386400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quickumls                  0.00000\n",
       "scispacy                   1.00000\n",
       "ctakes                     0.00000\n",
       "metamap                    0.00000\n",
       "health_bert                0.80804\n",
       "health_bert.1              1.00000\n",
       "health_bert.2              1.00000\n",
       "contrastive_weight         1.00000\n",
       "term_domain_specificity    1.00000\n",
       "discriminative_weight          NaN\n",
       "Name: (wikidata, discriminative_weight), dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_significance = pd.read_csv(\"significance_recall_precision_0.9.csv\", index_col=[0, 1])\n",
    "precision_significance.loc[\"wikidata\", \"discriminative_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5882441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quickumls                  1.00000\n",
       "scispacy                   1.00000\n",
       "ctakes                     1.00000\n",
       "metamap                    1.00000\n",
       "health_bert                0.99707\n",
       "health_bert.1              0.99986\n",
       "health_bert.2                  NaN\n",
       "contrastive_weight         1.00000\n",
       "term_domain_specificity    0.53193\n",
       "discriminative_weight      0.98839\n",
       "Name: (wikidata, pmbert), dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_significance = pd.read_csv(\"significance_precision_recall_0.9.csv\", index_col=[0, 1])\n",
    "recall_significance.loc[\"wikidata\", \"pmbert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d5f223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quickumls                  1.00\n",
       "scispacy                   1.00\n",
       "ctakes                     1.00\n",
       "metamap                    1.00\n",
       "health_bert                0.88\n",
       "health_bert.1              1.00\n",
       "health_bert.2               NaN\n",
       "contrastive_weight         1.00\n",
       "term_domain_specificity    0.98\n",
       "discriminative_weight      0.97\n",
       "Name: (wikidata, pmbert), dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_significance = pd.read_csv(\"significance_mcc.csv\", index_col=[0, 1])\n",
    "mcc_significance.loc[\"wikidata\", \"pmbert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde34824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(\n",
    "    values,\n",
    "    bold=False,\n",
    "    bold_axis=0,\n",
    "    bold_command=\"\\highlight\",\n",
    "    bold_idcs=None,\n",
    "    round_to=2,\n",
    "    direction=\"maximize\",\n",
    "):\n",
    "    for row_idx, row in enumerate(values):\n",
    "        for col_idx, value in enumerate(row):\n",
    "            try:\n",
    "                float(value)\n",
    "                values[row_idx, col_idx] = round(float(value), round_to)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    if bold_idcs is None:\n",
    "        bold_idcs = []\n",
    "    for idx, bold_idx in enumerate(bold_idcs):\n",
    "        if bold_idx < 0:\n",
    "            bold_idcs[idx] = values.shape[1 - bold_axis] + bold_idx\n",
    "    if bold:\n",
    "        if bold_axis not in (0, 1):\n",
    "            raise ValueError(f\"invalid axis value, expected 0, 1, got {axis}\")\n",
    "        inf_value = float(\"-inf\") if direction == \"maximize\" else float(\"inf\")\n",
    "        numerical_values = [\n",
    "            [value if isinstance(value, (float, int)) else inf_value for value in row]\n",
    "            for row in values\n",
    "        ]\n",
    "        if direction == \"maximize\":\n",
    "            best_values = np.amax(numerical_values, axis=bold_axis)\n",
    "        else:\n",
    "            best_values = np.amin(numerical_values, axis=bold_axis)\n",
    "        if bold_axis == 1:\n",
    "            values = values.T\n",
    "        for row_idx, row in enumerate(values):\n",
    "            for col_idx, value in enumerate(row):\n",
    "                if (\n",
    "                    bold_axis == 0\n",
    "                    and values[row_idx][col_idx] == best_values[col_idx]\n",
    "                    and col_idx in bold_idcs\n",
    "                ) or (\n",
    "                    bold_axis == 1\n",
    "                    and values[row_idx][col_idx] == best_values[row_idx]\n",
    "                    and row_idx in bold_idcs\n",
    "                ):\n",
    "                    string_value = str(value)\n",
    "                    string_value += \"0\" * (round_to - len(string_value) + 2)\n",
    "                    values[row_idx][col_idx] = f\"{bold_command}{{{string_value}}}\"\n",
    "        if bold_axis == 1:\n",
    "            values = values.T\n",
    "\n",
    "    string_values = []\n",
    "    for row in values:\n",
    "        row_string_values = []\n",
    "        for value in row:\n",
    "            try:\n",
    "                float(value)\n",
    "                string_value = str(value)\n",
    "                string_value += \"0\" * (round_to - len(string_value) + 2)\n",
    "                row_string_values.append(string_value)\n",
    "            except ValueError:\n",
    "                row_string_values.append(str(value))\n",
    "        string_values.append(row_string_values)\n",
    "\n",
    "    out = \" \\\\\\\\\\n\".join(\" & \".join(values) for values in string_values)\n",
    "    out += \" \\\\\\\\\"\n",
    "\n",
    "    print(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def small(string):\n",
    "    return f\"\\small{{{string}}}\"\n",
    "\n",
    "\n",
    "def scriptsize(string):\n",
    "    return f\"\\scriptsize{{{string}}}\"\n",
    "\n",
    "\n",
    "def tiny(string):\n",
    "    return f\"\\\\tiny{{{string}}}\"\n",
    "\n",
    "\n",
    "def rename_method(method_name, parameters=True):\n",
    "\n",
    "    name_dict = {\n",
    "        \"pubmedbert\": \"PubMedBERT\",\n",
    "        \"scibert\": \"SciBERT\",\n",
    "        \"bert\": \"BERT\",\n",
    "        \"mesh\": \"MeSH\",\n",
    "        \"quickumls\": \"QuickUMLS\",\n",
    "        \"umls\": \"UMLS\",\n",
    "        \"contrastive_weight\": \"CW\",\n",
    "        \"term_domain_specificity\": \"TDS\",\n",
    "        \"discriminative_weight\": \"DW\",\n",
    "        \"encyclopedia\": \"ENC\",\n",
    "        \"pubmed\": \"PM\",\n",
    "        \"ctakes\": \"cTakes\",\n",
    "        \"metamap\": \"MetaMap\",\n",
    "        \"scispacy\": \"ScispaCy\",\n",
    "        \"en_core_sci_\": \"\",\n",
    "        \"rx_sno\": \"RS\",\n",
    "        \"full\": \"Full\",\n",
    "        \"noun_phrase\": \"NP\",\n",
    "        \"sentence\": \"S\",\n",
    "    }\n",
    "\n",
    "    for name, replace_name in name_dict.items():\n",
    "        method_name = method_name.replace(name, replace_name)\n",
    "    method_split = method_name.split(\"-\")\n",
    "    params = []\n",
    "    if \"CW\" in method_name or \"DW\" in method_name or \"TDS\" in method_name:\n",
    "        name = method_split[0]\n",
    "        if parameters:\n",
    "            try:\n",
    "                method_split[-2] = (\n",
    "                    \"$n$=\" + method_split[-2].strip(\"()\").split(\",\")[1].strip()\n",
    "                )\n",
    "                method_split[-1] = f\"$M_{{{method_split[-1]}}}$\"\n",
    "                params = method_split[1:]\n",
    "            except IndexError:\n",
    "                pass\n",
    "    elif \"ScispaCy\" in method_name:\n",
    "        name = method_split[0]\n",
    "        if parameters:\n",
    "            try:\n",
    "                params = [method_split[1], f\"\\\\textit{{{method_split[2]}}}\", method_split[3]]\n",
    "            except IndexError:\n",
    "                pass\n",
    "    elif \"health_BERT\" in method_name:\n",
    "        name = method_split[1]\n",
    "        if parameters:\n",
    "            params = method_split[2:]\n",
    "    else:\n",
    "        name = method_split[0] \n",
    "        if parameters:\n",
    "            params = method_split[1:] \n",
    "    if params:\n",
    "        name += \" \" + scriptsize(\", \".join(params))\n",
    "    return name\n",
    "\n",
    "\n",
    "def rename_operator(operator_name):\n",
    "    operator_name = operator_name.replace(\"inf\", \"\\infty\").replace(\"neg_\", \"-\")\n",
    "    value = operator_name.split(\"=\")[1].split(\"_\")[0]\n",
    "    if value[0] == \"-\":\n",
    "        value = r\"\\texttt{--}\\!\" + value[1:]\n",
    "    return f\"$M_{{{value}}}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47a807db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cTakes \\scriptsize{RS, st21pv} & $M_{\\texttt{--}\\!2}$ & 0.00 & 0.00 \\\\\n",
      "MetaMap \\scriptsize{RS, st21pv} & $M_{\\texttt{--}\\!\\infty}$ & 0.67 & 0.05 \\\\\n",
      "QuickUMLS \\scriptsize{RS, 0.8, st21pv} & $M_{\\texttt{--}\\!1}$ & 0.00 & 0.00 \\\\\n",
      "ScispaCy \\scriptsize{RS, \\textit{sm}, 0.9} & $M_{\\texttt{--}\\!\\infty}$ & 0.00 & 0.00 \\\\\n",
      "BERT \\scriptsize{ENC, NP} & $M_{1}$ & 0.91 & 0.77 \\\\\n",
      "SciBERT \\scriptsize{ENC, NP} & $M_{5}$ & 0.94 & 0.77 \\\\\n",
      "PubMedBERT \\scriptsize{ENC, NP} & $M_{2}$ & 0.94 & \\highlight{0.82} \\\\\n",
      "CW \\scriptsize{ENC, $n$=2, $M_{2}$} & $M_{\\texttt{--}\\!1}$ & 0.85 & 0.72 \\\\\n",
      "TDS \\scriptsize{ENC, $n$=2, $M_{1}$} & $M_{1}$ & \\highlight{1.00} & 0.69 \\\\\n",
      "DW \\scriptsize{ENC, $n$=1, $M_{1}$} & $M_{1}$ & \\highlight{1.00} & 0.74 \\\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cTakes \\\\scriptsize{RS, st21pv} & $M_{\\\\texttt{--}\\\\!2}$ & 0.00 & 0.00 \\\\\\\\\\nMetaMap \\\\scriptsize{RS, st21pv} & $M_{\\\\texttt{--}\\\\!\\\\infty}$ & 0.67 & 0.05 \\\\\\\\\\nQuickUMLS \\\\scriptsize{RS, 0.8, st21pv} & $M_{\\\\texttt{--}\\\\!1}$ & 0.00 & 0.00 \\\\\\\\\\nScispaCy \\\\scriptsize{RS, \\\\textit{sm}, 0.9} & $M_{\\\\texttt{--}\\\\!\\\\infty}$ & 0.00 & 0.00 \\\\\\\\\\nBERT \\\\scriptsize{ENC, NP} & $M_{1}$ & 0.91 & 0.77 \\\\\\\\\\nSciBERT \\\\scriptsize{ENC, NP} & $M_{5}$ & 0.94 & 0.77 \\\\\\\\\\nPubMedBERT \\\\scriptsize{ENC, NP} & $M_{2}$ & 0.94 & \\\\highlight{0.82} \\\\\\\\\\nCW \\\\scriptsize{ENC, $n$=2, $M_{2}$} & $M_{\\\\texttt{--}\\\\!1}$ & 0.85 & 0.72 \\\\\\\\\\nTDS \\\\scriptsize{ENC, $n$=2, $M_{1}$} & $M_{1}$ & \\\\highlight{1.00} & 0.69 \\\\\\\\\\nDW \\\\scriptsize{ENC, $n$=1, $M_{1}$} & $M_{1}$ & \\\\highlight{1.00} & 0.74 \\\\\\\\'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"random_full\"\n",
    "# dataset = \"random_support\"\n",
    "# dataset = \"sentence\"\n",
    "# dataset = \"wikidata\"\n",
    "# dataset = \"practitioner_full\"\n",
    "# dataset = \"practitioner_sure\"\n",
    "# dataset = \"practitioner_unsure\"\n",
    "\n",
    "approaches = [\n",
    "    \"ctakes\",\n",
    "    \"metamap\",\n",
    "    \"quickumls\",\n",
    "    \"scispacy\",\n",
    "    \"health_bert\",\n",
    "    \"contrastive\",\n",
    "    \"specificity\",\n",
    "    \"discriminative\",\n",
    "]\n",
    "\n",
    "\n",
    "def key(series):\n",
    "    order = pd.Series(-1, index=series.index)\n",
    "    for idx, approach in enumerate(approaches):\n",
    "        order[series.str.contains(approach)] = idx\n",
    "    return order\n",
    "\n",
    "\n",
    "threshold_score = \"precision\"\n",
    "threshold = 0.9\n",
    "optimization_score = \"recall\"\n",
    "if threshold_score:\n",
    "    pretty_print_approaches = pd.read_csv(f\"test_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\")\n",
    "else:\n",
    "    pretty_print_approaches = pd.read_csv(f\"test_best_approaches_{optimization_score}.csv\")\n",
    "pretty_print_approaches[\"pretty_method\"] = pretty_print_approaches.method.map(\n",
    "    rename_method\n",
    ")\n",
    "pretty_print_approaches[\"pretty_operator\"] = pretty_print_approaches.operator.map(\n",
    "    rename_operator\n",
    ")\n",
    "\n",
    "pretty_print_approaches = pretty_print_approaches.loc[\n",
    "    pretty_print_approaches.dataset == dataset\n",
    "]\n",
    "pretty_print_approaches = pretty_print_approaches.loc[\n",
    "    key(pretty_print_approaches.method) != -1\n",
    "]\n",
    "pretty_print_approaches = pretty_print_approaches.sort_values(by=\"method\", key=key)\n",
    "\n",
    "pprint(\n",
    "    pretty_print_approaches.loc[\n",
    "        :, [\n",
    "            \"pretty_method\", \n",
    "            \"pretty_operator\", \n",
    "            \"precision\", \n",
    "            \"recall\", \n",
    "#             \"f1\", \n",
    "#             \"mcc\"\n",
    "        ]\n",
    "    ].values,\n",
    "    bold=True,\n",
    "    bold_idcs=[-1, -2, -3, -4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d31cc289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.4 0.93 0.56 0.69\n",
      "2 0.49 0.81 0.61 0.78\n",
      "3 0.52 0.65 0.58 0.8\n",
      "4 0.67 0.46 0.55 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    504\n",
       "1    142\n",
       "2     83\n",
       "3    124\n",
       "4    147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_threshold = 0.0\n",
    "dataset = \"random_full\"\n",
    "linker_approaches = pd.read_csv(\n",
    "    f\"best_approaches_{precision_threshold}.csv\", index_col=0\n",
    ")\n",
    "linker_approaches = linker_approaches.loc[linker_approaches.dataset == dataset].iloc[:4]\n",
    "linker_predictions = []\n",
    "for _, method, operator, threshold, *_ in linker_approaches.values:\n",
    "    label = \"-\".join([method, operator, str(threshold), \"medical\"])\n",
    "    linker_predictions.append(\n",
    "        test_causenet_medical.loc[test_causenet.dataset == dataset, label]\n",
    "    )\n",
    "linker_predictions = pd.concat(linker_predictions, axis=1)\n",
    "for threshold in range(1, 5):\n",
    "    combined_predictions = linker_predictions.sum(axis=1) >= threshold\n",
    "    tp = (\n",
    "        combined_predictions\n",
    "        & test_causenet.evaluation.loc[test_causenet.dataset == dataset]\n",
    "    ).sum()\n",
    "    tn = (\n",
    "        ~combined_predictions\n",
    "        & ~test_causenet.evaluation.loc[test_causenet.dataset == dataset]\n",
    "    ).sum()\n",
    "    fp = (\n",
    "        combined_predictions\n",
    "        & ~test_causenet.evaluation.loc[test_causenet.dataset == dataset]\n",
    "    ).sum()\n",
    "    fn = (\n",
    "        ~combined_predictions\n",
    "        & test_causenet.evaluation.loc[test_causenet.dataset == dataset]\n",
    "    ).sum()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(threshold, round(precision, 2), round(recall, 2), round(f1, 2), round(accuracy, 2))\n",
    "linker_predictions.sum(axis=1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4aa451c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method_class</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision-arithmetic_mean</th>\n",
       "      <th>precision-n_gram</th>\n",
       "      <th>precision-arithmetic_mean-reduction</th>\n",
       "      <th>precision-n_gram-reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_full</td>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>-0.028406</td>\n",
       "      <td>-0.028406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_full</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.048485</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.044355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_support</td>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.80315</td>\n",
       "      <td>0.80315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_support</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_support</td>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>-0.034416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentence</td>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.107448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence</td>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>-0.025799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset             method_class  precision  \\\n",
       "0     random_full       contrastive_weight   0.580645   \n",
       "1     random_full  term_domain_specificity   0.666667   \n",
       "2     random_full    discriminative_weight   0.625000   \n",
       "3  random_support       contrastive_weight   0.803150   \n",
       "4  random_support  term_domain_specificity   0.925926   \n",
       "5  random_support    discriminative_weight   0.927273   \n",
       "6        sentence       contrastive_weight   0.563636   \n",
       "7        sentence  term_domain_specificity   0.615385   \n",
       "8        sentence    discriminative_weight   0.591837   \n",
       "\n",
       "  precision-arithmetic_mean precision-n_gram  \\\n",
       "0                  0.552239         0.552239   \n",
       "1                  0.618182              0.7   \n",
       "2                  0.580645            0.625   \n",
       "3                   0.80315          0.80315   \n",
       "4                  0.935185         0.925926   \n",
       "5                  0.892857         0.927273   \n",
       "6                  0.563636         0.563636   \n",
       "7                  0.615385         0.507937   \n",
       "8                  0.596154         0.566038   \n",
       "\n",
       "  precision-arithmetic_mean-reduction precision-n_gram-reduction  \n",
       "0                           -0.028406                  -0.028406  \n",
       "1                           -0.048485                   0.033333  \n",
       "2                           -0.044355                        0.0  \n",
       "3                                 0.0                        0.0  \n",
       "4                            0.009259                       -0.0  \n",
       "5                           -0.034416                        0.0  \n",
       "6                                 0.0                        0.0  \n",
       "7                                 0.0                  -0.107448  \n",
       "8                            0.004317                  -0.025799  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ablation tests\n",
    "threshold_score = \"recall\"\n",
    "threshold = 0.9\n",
    "optimization_score = \"precision\"\n",
    "datasets = [\n",
    "    \"random_full\",\n",
    "    \"random_support\",\n",
    "    \"sentence\",\n",
    "#     \"support\",\n",
    "#     \"wikidata\",\n",
    "#     \"practitioner_full\",\n",
    "#     \"practitioner_sure\",\n",
    "#     \"practitioner_unsure\",\n",
    "]\n",
    "use_test_metrics = True\n",
    "full_train = True\n",
    "if use_test_metrics:\n",
    "    ablation_test_metrics = test_causenet_metrics\n",
    "    ablation_set = \"test\"\n",
    "else:\n",
    "    ablation_test_metrics = None\n",
    "    ablation_set = \"validation\"\n",
    "val_causenet = validation_causenet_metrics.loc[:, [\"dataset\", \"method\", \"operator\"]].drop_duplicates()\n",
    "val_causenet[\"method_class\"] = val_causenet[\"method\"].map(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "\n",
    "if threshold_score:\n",
    "    ablation_best_approaches = pd.read_csv(f\"{ablation_set}_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\", index_col=0)\n",
    "else:\n",
    "    ablation_best_approaches = pd.read_csv(f\"{ablation_set}_best_approaches_{optimization_score}.csv\", index_col=0)\n",
    "\n",
    "ablation_best_approaches = ablation_best_approaches.loc[\n",
    "    ablation_best_approaches.method_class.isin([\"contrastive_weight\", \"discriminative_weight\", \"term_domain_specificity\"]),\n",
    "    [\"dataset\", \"method\", \"operator\", \"method_class\", optimization_score]\n",
    "]\n",
    "ablation_best_approaches = ablation_best_approaches.reset_index(drop=True)\n",
    "ablation_methods = ablation_best_approaches.copy().drop(optimization_score, axis=1)\n",
    "ablation_best_approaches = ablation_best_approaches.loc[:, [\"dataset\", \"method_class\", optimization_score]]\n",
    "\n",
    "def get_ablation_df(ablation_df, validation_metrics, test_metrics=None):\n",
    "    ablation_df = ablation_df.merge(validation_metrics.dropna())\n",
    "    if threshold_score:\n",
    "        ablation_df = ablation_df.loc[ablation_df[threshold_score] >= threshold]\n",
    "    ablation_df = ablation_df.groupby([\"dataset\", \"method_class\"]).apply(lambda x: x.sort_values(optimization_score).iloc[-1]).reset_index(drop=True)\n",
    "    if test_metrics is not None:\n",
    "        ablation_df = ablation_df.merge(test_metrics, how=\"left\", on=[\"dataset\", \"method\", \"operator\", \"threshold\"], suffixes=(\"_to_drop\", \"\"))\n",
    "        ablation_df = ablation_df.drop(ablation_df.filter(like=\"_to_drop\"), axis=1)\n",
    "    ablation_df = ablation_df.loc[:, [\"dataset\", \"method_class\", optimization_score]]\n",
    "    return ablation_df\n",
    "\n",
    "if full_train:\n",
    "    pattern = r\".*-\\(1, 1\\)-.*\"\n",
    "    ablation_arithmetic_mean = get_ablation_df(\n",
    "        val_causenet.loc[val_causenet.method.str.contains(pattern)],\n",
    "        validation_causenet_metrics,\n",
    "        test_causenet_metrics,\n",
    "    )\n",
    "else:\n",
    "    ablation_arithmetic_mean = ablation_methods.copy()\n",
    "    ablation_arithmetic_mean[\"method\"] = ablation_arithmetic_mean[\"method\"].map(lambda x: \"-\".join(x.split(\"-\")[:-1]) + \"-1\")\n",
    "    ablation_arithmetic_mean = get_ablation_df(ablation_arithmetic_mean, validation_causenet_metrics, test_causenet_metrics)\n",
    "ablation_best_approaches = ablation_best_approaches.merge(ablation_arithmetic_mean, on=[\"dataset\", \"method_class\"], suffixes=[\"\", \"-arithmetic_mean\"], how=\"left\")\n",
    "\n",
    "if full_train:\n",
    "    pattern = r\".*-\\(1, .\\)-1\"\n",
    "    ablation_n_gram = get_ablation_df(\n",
    "        val_causenet.loc[val_causenet.method.str.contains(pattern)],\n",
    "        validation_causenet_metrics,\n",
    "        test_causenet_metrics,\n",
    "    )\n",
    "else:\n",
    "    ablation_n_gram = ablation_methods.copy()\n",
    "    ablation_n_gram[\"method\"] = ablation_n_gram[\"method\"].map(lambda x: x.split(\")\")[0][:-1] + \"1)\" + x.split(\")\")[1])\n",
    "    ablation_n_gram = get_ablation_df(ablation_n_gram, validation_causenet_metrics, test_causenet_metrics)\n",
    "ablation_best_approaches = ablation_best_approaches.merge(ablation_n_gram, on=[\"dataset\", \"method_class\"], suffixes=[\"\", \"-n_gram\"], how=\"left\")\n",
    "\n",
    "# if full_train:\n",
    "#     pattern = r\".*-\\(1, 1\\)-1\"\n",
    "#     ablation_arithmetic_mean_n_gram = get_ablation_df(\n",
    "#         val_causenet.loc[val_causenet.method.str.contains(pattern)],\n",
    "#         validation_causenet_metrics,\n",
    "#         test_causenet_metrics,\n",
    "#     )\n",
    "# else:\n",
    "#     ablation_arithmetic_mean_n_gram = ablation_methods.copy()\n",
    "#     ablation_arithmetic_mean_n_gram[\"method\"] = ablation_arithmetic_mean_n_gram[\"method\"].map(lambda x: x.split(\")\")[0][:-1] + \"1)\" + x.split(\")\")[1])\n",
    "#     ablation_arithmetic_mean_n_gram[\"method\"] = ablation_arithmetic_mean_n_gram[\"method\"].map(lambda x: \"-\".join(x.split(\"-\")[:-1]) + \"-1\")\n",
    "#     ablation_arithmetic_mean_n_gram = get_ablation_df(ablation_arithmetic_mean_n_gram, validation_causenet_metrics, test_causenet_metrics)\n",
    "# ablation_best_approaches = ablation_best_approaches.merge(ablation_arithmetic_mean_n_gram, on=[\"dataset\", \"method_class\"], suffixes=[\"\", \"-arithmetic_mean_n_gram\"], how=\"left\")\n",
    "\n",
    "ablation_best_approaches = ablation_best_approaches.merge(\n",
    "    ablation_best_approaches.filter(like=f\"{optimization_score}-\").subtract(ablation_best_approaches[optimization_score].values, axis=0), \n",
    "    suffixes=[\"\", \"-reduction\"],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "ablation_best_approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0cafaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03 & -0.03 \\\\\n",
      "-0.05 & 0.03 \\\\\n",
      "-0.04 & 0.00 \\\\\n",
      "0.00 & 0.00 \\\\\n",
      "0.01 & -0.0 \\\\\n",
      "-0.03 & 0.00 \\\\\n",
      "0.00 & 0.00 \\\\\n",
      "0.00 & -0.11 \\\\\n",
      "0.00 & -0.03 \\\\\n",
      "\n",
      " -0.03 & -0.03 \\\\\n",
      "-0.05 & 0.03 \\\\\n",
      "-0.04 & 0.00 \\\\\n",
      "0.00 & 0.00 \\\\\n",
      "0.01 & -0.0 \\\\\n",
      "-0.03 & 0.00 \\\\\n",
      "0.00 & 0.00 \\\\\n",
      "0.00 & -0.11 \\\\\n",
      "0.00 & -0.03 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\", pprint(ablation_best_approaches.filter(like=\"-reduction\").values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a25e8588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_class</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mcc-n_grams-reduction</th>\n",
       "      <th>mcc-arithmetic_mean-reduction</th>\n",
       "      <th>mcc-n_grams_arithmetic_mean-reduction</th>\n",
       "      <th>mcc-arithmetic_mean_operator-reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>random_full</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.052416</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>-0.041072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>random_full</td>\n",
       "      <td>-0.018574</td>\n",
       "      <td>0.017133</td>\n",
       "      <td>-0.018574</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>random_full</td>\n",
       "      <td>-0.007408</td>\n",
       "      <td>-0.007408</td>\n",
       "      <td>-0.007408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>random_support</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016447</td>\n",
       "      <td>-0.016447</td>\n",
       "      <td>-0.019820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>random_support</td>\n",
       "      <td>-0.030721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030597</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>random_support</td>\n",
       "      <td>-0.008210</td>\n",
       "      <td>0.031269</td>\n",
       "      <td>-0.030219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.065470</td>\n",
       "      <td>0.102184</td>\n",
       "      <td>0.102184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              method_class         dataset  mcc-n_grams-reduction  \\\n",
       "0       contrastive_weight     random_full               0.000000   \n",
       "1  term_domain_specificity     random_full              -0.018574   \n",
       "2    discriminative_weight     random_full              -0.007408   \n",
       "3       contrastive_weight  random_support               0.000000   \n",
       "4  term_domain_specificity  random_support              -0.030721   \n",
       "5    discriminative_weight  random_support              -0.008210   \n",
       "6       contrastive_weight        sentence               0.000000   \n",
       "7  term_domain_specificity        sentence               0.065470   \n",
       "8    discriminative_weight        sentence               0.020682   \n",
       "\n",
       "   mcc-arithmetic_mean-reduction  mcc-n_grams_arithmetic_mean-reduction  \\\n",
       "0                      -0.052416                               0.001387   \n",
       "1                       0.017133                              -0.018574   \n",
       "2                      -0.007408                              -0.007408   \n",
       "3                      -0.016447                              -0.016447   \n",
       "4                       0.000000                              -0.030597   \n",
       "5                       0.031269                              -0.030219   \n",
       "6                       0.052588                               0.052588   \n",
       "7                       0.102184                               0.102184   \n",
       "8                       0.000000                               0.020682   \n",
       "\n",
       "   mcc-arithmetic_mean_operator-reduction  \n",
       "0                               -0.041072  \n",
       "1                                0.000000  \n",
       "2                                0.000000  \n",
       "3                               -0.019820  \n",
       "4                                0.000000  \n",
       "5                                0.000000  \n",
       "6                                     NaN  \n",
       "7                                     NaN  \n",
       "8                                     NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ablation tests\n",
    "threshold_score = \"\"\n",
    "threshold = 0.0\n",
    "optimization_score = \"mcc\"\n",
    "datasets = [\n",
    "    \"random_full\",\n",
    "    \"random_support\",\n",
    "    \"sentence\",\n",
    "#     \"support\",\n",
    "#     \"wikidata\",\n",
    "    #     \"practitioner_full\",\n",
    "    #     \"practitioner_sure\",\n",
    "    #     \"practitioner_unsure\",\n",
    "]\n",
    "eval_ops = [\"p=0_mean\"] + [f\"p={p}_mean\" for p in (1, 2, 5, 10, \"inf\")] + [f\"p=neg_{p}_mean\" for p in (1, 2, 5, 10, \"inf\")]\n",
    "\n",
    "patterns = [\n",
    "    \"contrastive_weight-.*-\\(1, 1\\)-.*\",\n",
    "    \"term_domain_specificity-.*-\\(1, 1\\)-.*\",\n",
    "    \"discriminative_weight-.*-\\(1, 1\\)-.*\",\n",
    "]\n",
    "best_approaches_n_grams = best_approach(\n",
    "    validation_causenet_metrics,\n",
    "    test_causenet_metrics,\n",
    "    patterns,\n",
    "    datasets,\n",
    "    threshold_score,\n",
    "    threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    False,\n",
    ")\n",
    "\n",
    "patterns = [\n",
    "    \"contrastive_weight-.*-\\(1, .\\)-1\",\n",
    "    \"term_domain_specificity-.*-\\(1, .\\)-1\",\n",
    "    \"discriminative_weight-.*-\\(1, .\\)-1\",\n",
    "]\n",
    "best_approaches_arithmetic_mean = best_approach(\n",
    "    validation_causenet_metrics,\n",
    "    test_causenet_metrics,\n",
    "    patterns,\n",
    "    datasets,\n",
    "    threshold_score,\n",
    "    threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# patterns = [\n",
    "#     \"contrastive_weight-.*-\\(1, .\\)-neg_inf\",\n",
    "#     \"term_domain_specificity-.*-\\(1, .\\)-neg_inf\",\n",
    "#     \"discriminative_weight-.*-\\(1, .\\)-neg_inf\",\n",
    "# ]\n",
    "# best_approaches_and = best_approach(\n",
    "#     validation_causenet_metrics,\n",
    "#     test_causenet_metrics,\n",
    "#     patterns,\n",
    "#     datasets,\n",
    "#     threshold_score,\n",
    "#     threshold,\n",
    "#     optimization_score,\n",
    "#     eval_ops,\n",
    "#     False,\n",
    "# )\n",
    "\n",
    "# patterns = [\n",
    "#     \"contrastive_weight-.*-\\(1, .\\)-inf\",\n",
    "#     \"term_domain_specificity-.*-\\(1, .\\)-inf\",\n",
    "#     \"discriminative_weight-.*-\\(1, .\\)-inf\",\n",
    "# ]\n",
    "# best_approaches_or = best_approach(\n",
    "#     validation_causenet_metrics,\n",
    "#     test_causenet_metrics,\n",
    "#     patterns,\n",
    "#     datasets,\n",
    "#     threshold_score,\n",
    "#     threshold,\n",
    "#     optimization_score,\n",
    "#     eval_ops,\n",
    "#     False,\n",
    "# )\n",
    "\n",
    "patterns = [\n",
    "    \"contrastive_weight-.*-\\(1, 1\\)-1\",\n",
    "    \"term_domain_specificity-.*-\\(1, 1\\)-1\",\n",
    "    \"discriminative_weight-.*-\\(1, 1\\)-1\",\n",
    "]\n",
    "best_approaches_n_grams_arithmetic_mean = best_approach(\n",
    "    validation_causenet_metrics,\n",
    "    test_causenet_metrics,\n",
    "    patterns,\n",
    "    datasets,\n",
    "    threshold_score,\n",
    "    threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# patterns = [\n",
    "# #     \"metamap\",\n",
    "# #     \"ctakes\",\n",
    "# #     \"quickumls\",\n",
    "# #     \"scispacy\",\n",
    "# #     \"-bert\",\n",
    "# #     \"scibert\",\n",
    "# #     \"pubmedbert\",\n",
    "#     \"contrastive_weight-.*-\\(1, .\\)-.*\",\n",
    "#     \"term_domain_specificity-.*-\\(1, .\\)-.*\",\n",
    "#     \"discriminative_weight-.*-\\(1, .\\)-.*\",\n",
    "# ]\n",
    "# eval_ops = [\"p=neg_inf_mean\"]\n",
    "# best_approaches_and_operator = best_approach(\n",
    "#     validation_causenet_metrics,\n",
    "#     test_causenet_metrics,\n",
    "#     patterns,\n",
    "#     [dataset for dataset in datasets if dataset != \"sentence\"],\n",
    "#     threshold_score,\n",
    "#     threshold,\n",
    "#     optimization_score,\n",
    "#     eval_ops,\n",
    "#     False,\n",
    "# )\n",
    "\n",
    "# patterns = [\n",
    "# #     \"metamap\",\n",
    "# #     \"ctakes\",\n",
    "# #     \"quickumls\",\n",
    "# #     \"scispacy\",\n",
    "# #     \"-bert\",\n",
    "# #     \"scibert\",\n",
    "# #     \"pubmedbert\",\n",
    "#     \"contrastive_weight-.*-\\(1, .\\)-.*\",\n",
    "#     \"term_domain_specificity-.*-\\(1, .\\)-.*\",\n",
    "#     \"discriminative_weight-.*-\\(1, .\\)-.*\",\n",
    "# ]\n",
    "# eval_ops = [\"p=inf_mean\"]\n",
    "# best_approaches_or_operator = best_approach(\n",
    "#     validation_causenet_metrics,\n",
    "#     test_causenet_metrics,\n",
    "#     patterns,\n",
    "#     [dataset for dataset in datasets if dataset != \"sentence\"],\n",
    "#     threshold_score,\n",
    "#     threshold,\n",
    "#     optimization_score,\n",
    "#     eval_ops,\n",
    "#     False,\n",
    "# )\n",
    "\n",
    "patterns = [\n",
    "#     \"metamap\",\n",
    "#     \"ctakes\",\n",
    "#     \"quickumls\",\n",
    "#     \"scispacy\",\n",
    "#     \"-bert\",\n",
    "#     \"scibert\",\n",
    "#     \"pubmedbert\",\n",
    "    \"contrastive_weight-.*-\\(1, .\\)-.*\",\n",
    "    \"term_domain_specificity-.*-\\(1, .\\)-.*\",\n",
    "    \"discriminative_weight-.*-\\(1, .\\)-.*\",\n",
    "]\n",
    "eval_ops = [\"p=1_mean\"]\n",
    "best_approaches_arithmetic_mean_operator = best_approach(\n",
    "    validation_causenet_metrics,\n",
    "    test_causenet_metrics,\n",
    "    patterns,\n",
    "    [dataset for dataset in datasets if dataset != \"sentence\"],\n",
    "    threshold_score,\n",
    "    threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# patterns = [\n",
    "#     \"health_bert-.*-sentence\",\n",
    "# ]\n",
    "# eval_ops = [\"and\"] + [f\"p={p}_mean\" for p in (1, 2, 5, 10, \"inf\")]\n",
    "# best_approaches_sentence = best_approach(\n",
    "#     test_causenet_metrics,\n",
    "#     patterns,\n",
    "#     datasets,\n",
    "#     threshold_score,\n",
    "#     threshold,\n",
    "#     optimization_score,\n",
    "#     eval_ops,\n",
    "#     False,\n",
    "# )\n",
    "\n",
    "if threshold_score:\n",
    "    best_approaches_comparison = pd.read_csv(f\"test_best_approaches_{optimization_score}_{threshold_score}_{threshold}.csv\")\n",
    "else:\n",
    "    best_approaches_comparison = pd.read_csv(f\"test_best_approaches_{optimization_score}.csv\")\n",
    "\n",
    "best_approaches_comparison = best_approaches_comparison.loc[:, [\"method_class\", \"dataset\", optimization_score]]\n",
    "best_approaches_comparison = best_approaches_comparison.merge(best_approaches_n_grams.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-n_grams\"), how=\"inner\")\n",
    "# best_approaches_comparison = best_approaches_comparison.merge(best_approaches_and.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-and\"), how=\"outer\")\n",
    "# best_approaches_comparison = best_approaches_comparison.merge(best_approaches_or.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-or\"), how=\"outer\")\n",
    "# best_approaches_comparison = best_approaches_comparison.merge(best_approaches_and_operator.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-and_operator\"), how=\"outer\")\n",
    "# best_approaches_comparison = best_approaches_comparison.merge(best_approaches_or_operator.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-or_operator\"), how=\"outer\")\n",
    "best_approaches_comparison = best_approaches_comparison.merge(best_approaches_arithmetic_mean.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-arithmetic_mean\"), how=\"outer\")\n",
    "best_approaches_comparison = best_approaches_comparison.merge(best_approaches_n_grams_arithmetic_mean.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-n_grams_arithmetic_mean\"), how=\"outer\")\n",
    "best_approaches_comparison = best_approaches_comparison.merge(best_approaches_arithmetic_mean_operator.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-arithmetic_mean_operator\"), how=\"outer\")\n",
    "# best_approaches_comparison = best_approaches_comparison.merge(best_approaches_sentence.loc[:, [\"method_class\", \"dataset\", optimization_score]], on=[\"method_class\", \"dataset\"], suffixes=(\"\", \"-sentence\"), how=\"outer\")\n",
    "other_scores = best_approaches_comparison.filter(regex=f\"{optimization_score}-\", axis=1)\n",
    "reduction = other_scores.subtract(best_approaches_comparison[optimization_score].values, axis=0)\n",
    "best_approaches_comparison = pd.concat([best_approaches_comparison, reduction.add_suffix(\"-reduction\")], axis=1)\n",
    "best_approaches_comparison.filter(regex=f\"method_class|dataset|{optimization_score}-.*reduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81e4639d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202769</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-inf</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>179.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366053</td>\n",
       "      <td>0.22500</td>\n",
       "      <td>0.018994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197951</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-10</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>179.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366053</td>\n",
       "      <td>0.22500</td>\n",
       "      <td>0.018994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202406</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-inf</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>179.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366428</td>\n",
       "      <td>0.22625</td>\n",
       "      <td>0.026878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189206</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>179.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366428</td>\n",
       "      <td>0.22625</td>\n",
       "      <td>0.026878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198017</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-5</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>179.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.22750</td>\n",
       "      <td>0.032939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219698</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>153.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.786632</td>\n",
       "      <td>0.89625</td>\n",
       "      <td>0.722668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224747</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-0</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>139.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.90500</td>\n",
       "      <td>0.724402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215309</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-0</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>132.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.781065</td>\n",
       "      <td>0.90750</td>\n",
       "      <td>0.724726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229103</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-0</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>130.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.780781</td>\n",
       "      <td>0.90875</td>\n",
       "      <td>0.726838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220028</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-0</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>141.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.729583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1589 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset                                           method    operator  \\\n",
       "202769  sentence  term_domain_specificity-encyclopedia-(1, 2)-inf  p=inf_mean   \n",
       "197951  sentence   term_domain_specificity-encyclopedia-(1, 1)-10  p=inf_mean   \n",
       "202406  sentence  term_domain_specificity-encyclopedia-(1, 1)-inf  p=inf_mean   \n",
       "189206  sentence    term_domain_specificity-encyclopedia-(1, 1)-1  p=inf_mean   \n",
       "198017  sentence    term_domain_specificity-encyclopedia-(1, 1)-5  p=inf_mean   \n",
       "...          ...                                              ...         ...   \n",
       "219698  sentence    term_domain_specificity-encyclopedia-(1, 1)-1  p=inf_mean   \n",
       "224747  sentence    term_domain_specificity-encyclopedia-(1, 3)-0  p=inf_mean   \n",
       "215309  sentence    term_domain_specificity-encyclopedia-(1, 1)-0  p=inf_mean   \n",
       "229103  sentence    term_domain_specificity-encyclopedia-(1, 3)-0  p=inf_mean   \n",
       "220028  sentence    term_domain_specificity-encyclopedia-(1, 2)-0  p=inf_mean   \n",
       "\n",
       "       threshold     tp     fp     tn    fn  precision    recall        f1  \\\n",
       "202769    0.2424  179.0  620.0    1.0   0.0   0.224030  1.000000  0.366053   \n",
       "197951    0.1818  179.0  620.0    1.0   0.0   0.224030  1.000000  0.366053   \n",
       "202406    0.2424  179.0  619.0    2.0   0.0   0.224311  1.000000  0.366428   \n",
       "189206    0.0606  179.0  619.0    2.0   0.0   0.224311  1.000000  0.366428   \n",
       "198017    0.1818  179.0  618.0    3.0   0.0   0.224592  1.000000  0.366803   \n",
       "...          ...    ...    ...    ...   ...        ...       ...       ...   \n",
       "219698    0.4848  153.0   57.0  564.0  26.0   0.728571  0.854749  0.786632   \n",
       "224747    0.5455  139.0   36.0  585.0  40.0   0.794286  0.776536  0.785311   \n",
       "215309    0.4242  132.0   27.0  594.0  47.0   0.830189  0.737430  0.781065   \n",
       "229103    0.6061  130.0   24.0  597.0  49.0   0.844156  0.726257  0.780781   \n",
       "220028    0.4848  141.0   37.0  584.0  38.0   0.792135  0.787709  0.789916   \n",
       "\n",
       "        accuracy       mcc  \n",
       "202769   0.22500  0.018994  \n",
       "197951   0.22500  0.018994  \n",
       "202406   0.22625  0.026878  \n",
       "189206   0.22625  0.026878  \n",
       "198017   0.22750  0.032939  \n",
       "...          ...       ...  \n",
       "219698   0.89625  0.722668  \n",
       "224747   0.90500  0.724402  \n",
       "215309   0.90750  0.724726  \n",
       "229103   0.90875  0.726838  \n",
       "220028   0.90625  0.729583  \n",
       "\n",
       "[1589 rows x 13 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_causenet_metrics.loc[(validation_causenet_metrics.dataset == \"sentence\") & (validation_causenet_metrics.method.str.contains(\"term\")) & (validation_causenet_metrics.method.str.contains(\"enc\"))].dropna().sort_values(\"mcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a81515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534089</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-10</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>4.8485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.028198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538445</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-10</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>4.9091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.028198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542801</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-10</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>4.9697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.028198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525377</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-10</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>4.7273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.028198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529733</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 3)-10</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>4.7879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.028198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276755</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 2)-2</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>1.2727</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.675396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232832</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-2</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241544</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-2</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.687865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219698</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.690849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237188</th>\n",
       "      <td>sentence</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-2</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.697213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset                                          method    operator  \\\n",
       "534089  sentence  term_domain_specificity-encyclopedia-(1, 3)-10  p=inf_mean   \n",
       "538445  sentence  term_domain_specificity-encyclopedia-(1, 3)-10  p=inf_mean   \n",
       "542801  sentence  term_domain_specificity-encyclopedia-(1, 3)-10  p=inf_mean   \n",
       "525377  sentence  term_domain_specificity-encyclopedia-(1, 3)-10  p=inf_mean   \n",
       "529733  sentence  term_domain_specificity-encyclopedia-(1, 3)-10  p=inf_mean   \n",
       "...          ...                                             ...         ...   \n",
       "276755  sentence   term_domain_specificity-encyclopedia-(1, 2)-2  p=inf_mean   \n",
       "232832  sentence   term_domain_specificity-encyclopedia-(1, 1)-2  p=inf_mean   \n",
       "241544  sentence   term_domain_specificity-encyclopedia-(1, 1)-2  p=inf_mean   \n",
       "219698  sentence   term_domain_specificity-encyclopedia-(1, 1)-1  p=inf_mean   \n",
       "237188  sentence   term_domain_specificity-encyclopedia-(1, 1)-2  p=inf_mean   \n",
       "\n",
       "       threshold    tp    fp     tn    fn  precision    recall        f1  \\\n",
       "534089    4.8485   1.0   3.0  162.0  34.0   0.250000  0.028571  0.051282   \n",
       "538445    4.9091   1.0   3.0  162.0  34.0   0.250000  0.028571  0.051282   \n",
       "542801    4.9697   1.0   3.0  162.0  34.0   0.250000  0.028571  0.051282   \n",
       "525377    4.7273   1.0   3.0  162.0  34.0   0.250000  0.028571  0.051282   \n",
       "529733    4.7879   1.0   3.0  162.0  34.0   0.250000  0.028571  0.051282   \n",
       "...          ...   ...   ...    ...   ...        ...       ...       ...   \n",
       "276755    1.2727  24.0   7.0  158.0  11.0   0.774194  0.685714  0.727273   \n",
       "232832    0.6667  32.0  20.0  145.0   3.0   0.615385  0.914286  0.735632   \n",
       "241544    0.7879  29.0  14.0  151.0   6.0   0.674419  0.828571  0.743590   \n",
       "219698    0.4848  28.0  12.0  153.0   7.0   0.700000  0.800000  0.746667   \n",
       "237188    0.7273  30.0  15.0  150.0   5.0   0.666667  0.857143  0.750000   \n",
       "\n",
       "        accuracy       mcc  \n",
       "534089     0.815  0.028198  \n",
       "538445     0.815  0.028198  \n",
       "542801     0.815  0.028198  \n",
       "525377     0.815  0.028198  \n",
       "529733     0.815  0.028198  \n",
       "...          ...       ...  \n",
       "276755     0.910  0.675396  \n",
       "232832     0.885  0.687000  \n",
       "241544     0.900  0.687865  \n",
       "219698     0.905  0.690849  \n",
       "237188     0.900  0.697213  \n",
       "\n",
       "[1007 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet_metrics.loc[(test_causenet_metrics.dataset == \"sentence\") & (test_causenet_metrics.method.str.contains(\"term\")) & (test_causenet_metrics.method.str.contains(\"enc\"))].dropna().sort_values(\"mcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc3d74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrastive_weight & random_full & 0.77 & 0.77 & 0.62 & 0.73 & 0.64 & 0.71 & 0.00 & -0.15 & -0.05 & -0.13 & -0.07 \\\\\n",
      "term_domain_specificity & random_full & 0.74 & 0.72 & 0.53 & 0.67 & 0.64 & 0.74 & -0.02 & -0.21 & -0.07 & -0.09 & 0.00 \\\\\n",
      "discriminative_weight & random_full & 0.79 & 0.79 & 0.59 & 0.68 & 0.68 & 0.73 & -0.01 & -0.21 & -0.12 & -0.11 & -0.06 \\\\\n",
      "contrastive_weight & random_support & 0.66 & 0.65 & 0.59 & 0.67 & 0.56 & 0.68 & -0.02 & -0.07 & 0.00 & -0.1 & 0.02 \\\\\n",
      "term_domain_specificity & random_support & 0.79 & 0.76 & 0.69 & 0.82 & 0.75 & 0.80 & -0.03 & -0.1 & 0.03 & -0.03 & 0.01 \\\\\n",
      "discriminative_weight & random_support & 0.79 & 0.76 & 0.64 & 0.82 & 0.75 & 0.78 & -0.03 & -0.14 & 0.03 & -0.04 & -0.01 \\\\\n",
      "contrastive_weight & sentence & 0.58 & 0.63 & 0.44 & 0.60 & nan0 & nan0 & 0.05 & -0.14 & 0.02 & nan0 & nan0 \\\\\n",
      "term_domain_specificity & sentence & 0.59 & 0.69 & 0.38 & 0.58 & nan0 & nan0 & 0.10 & -0.21 & -0.01 & nan0 & nan0 \\\\\n",
      "discriminative_weight & sentence & 0.68 & 0.70 & 0.42 & 0.61 & nan0 & nan0 & 0.02 & -0.26 & -0.08 & nan0 & nan0 \\\\\n"
     ]
    }
   ],
   "source": [
    "pprint(best_approaches_comparison.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deb7d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_class</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mcc</th>\n",
       "      <th>mcc-n_grams</th>\n",
       "      <th>mcc-and</th>\n",
       "      <th>mcc-or</th>\n",
       "      <th>mcc-and_operator</th>\n",
       "      <th>mcc-or_operator</th>\n",
       "      <th>mcc-n_grams-reduction</th>\n",
       "      <th>mcc-and-reduction</th>\n",
       "      <th>mcc-or-reduction</th>\n",
       "      <th>mcc-and_operator-reduction</th>\n",
       "      <th>mcc-or_operator-reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>random_full</td>\n",
       "      <td>0.773024</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.067676</td>\n",
       "      <td>-0.060824</td>\n",
       "      <td>-0.039824</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.079276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>random_full</td>\n",
       "      <td>0.737719</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.6208</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>-0.116919</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>-0.005719</td>\n",
       "      <td>0.115681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>random_full</td>\n",
       "      <td>0.792553</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.059747</td>\n",
       "      <td>-0.112353</td>\n",
       "      <td>-0.019553</td>\n",
       "      <td>-0.045053</td>\n",
       "      <td>0.059747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>random_support</td>\n",
       "      <td>0.664306</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.6134</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.030294</td>\n",
       "      <td>-0.050906</td>\n",
       "      <td>0.040194</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.030294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>random_support</td>\n",
       "      <td>0.786652</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>-0.086152</td>\n",
       "      <td>0.050748</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.040648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>random_support</td>\n",
       "      <td>0.786713</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>-0.112513</td>\n",
       "      <td>0.036287</td>\n",
       "      <td>-0.023413</td>\n",
       "      <td>0.033487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contrastive_weight</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.575206</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>-0.115706</td>\n",
       "      <td>0.022094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>term_domain_specificity</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.588665</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102135</td>\n",
       "      <td>-0.094865</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>discriminative_weight</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.682604</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.4936</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>-0.189004</td>\n",
       "      <td>-0.047804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              method_class         dataset       mcc  mcc-n_grams  mcc-and  \\\n",
       "0       contrastive_weight     random_full  0.773024       0.8407   0.7122   \n",
       "1  term_domain_specificity     random_full  0.737719       0.8029   0.6208   \n",
       "2    discriminative_weight     random_full  0.792553       0.8523   0.6802   \n",
       "3       contrastive_weight  random_support  0.664306       0.6946   0.6134   \n",
       "4  term_domain_specificity  random_support  0.786652       0.8189   0.7005   \n",
       "5    discriminative_weight  random_support  0.786713       0.7987   0.6742   \n",
       "6       contrastive_weight        sentence  0.575206       0.6348   0.4595   \n",
       "7  term_domain_specificity        sentence  0.588665       0.6908   0.4938   \n",
       "8    discriminative_weight        sentence  0.682604       0.7033   0.4936   \n",
       "\n",
       "   mcc-or  mcc-and_operator  mcc-or_operator  mcc-n_grams-reduction  \\\n",
       "0  0.7332            0.7834           0.8523               0.067676   \n",
       "1  0.7281            0.7320           0.8534               0.065181   \n",
       "2  0.7730            0.7475           0.8523               0.059747   \n",
       "3  0.7045            0.6648           0.6946               0.030294   \n",
       "4  0.8374            0.7881           0.8273               0.032248   \n",
       "5  0.8230            0.7633           0.8202               0.011987   \n",
       "6  0.5973               NaN              NaN               0.059594   \n",
       "7  0.6025               NaN              NaN               0.102135   \n",
       "8  0.6348               NaN              NaN               0.020696   \n",
       "\n",
       "   mcc-and-reduction  mcc-or-reduction  mcc-and_operator-reduction  \\\n",
       "0          -0.060824         -0.039824                    0.010376   \n",
       "1          -0.116919         -0.009619                   -0.005719   \n",
       "2          -0.112353         -0.019553                   -0.045053   \n",
       "3          -0.050906          0.040194                    0.000494   \n",
       "4          -0.086152          0.050748                    0.001448   \n",
       "5          -0.112513          0.036287                   -0.023413   \n",
       "6          -0.115706          0.022094                         NaN   \n",
       "7          -0.094865          0.013835                         NaN   \n",
       "8          -0.189004         -0.047804                         NaN   \n",
       "\n",
       "   mcc-or_operator-reduction  \n",
       "0                   0.079276  \n",
       "1                   0.115681  \n",
       "2                   0.059747  \n",
       "3                   0.030294  \n",
       "4                   0.040648  \n",
       "5                   0.033487  \n",
       "6                        NaN  \n",
       "7                        NaN  \n",
       "8                        NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_approaches_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8429827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2808061/3637449074.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  best_approaches_comparison.loc[best_approaches_comparison.method_class.str.contains(\"bert\")].filter(regex=\"method_class|dataset|mcc-.*reduction\").mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mcc-and_operator-reduction               -0.037100\n",
       "mcc-or_operator-reduction                -0.029211\n",
       "mcc-arithmetic_mean_operator-reduction   -0.014589\n",
       "mcc-n_grams-reduction                          NaN\n",
       "mcc-arithmetic_mean-reduction                  NaN\n",
       "mcc-n_grams_arithmetic_mean-reduction          NaN\n",
       "mcc-sentence-reduction                   -0.078333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_approaches_comparison.loc[best_approaches_comparison.method_class.str.contains(\"bert\")].filter(regex=\"method_class|dataset|mcc-.*reduction\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "81e16b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcc-and_operator-reduction</th>\n",
       "      <th>mcc-or_operator-reduction</th>\n",
       "      <th>mcc-arithmetic_mean_operator-reduction</th>\n",
       "      <th>mcc-n_grams-reduction</th>\n",
       "      <th>mcc-arithmetic_mean-reduction</th>\n",
       "      <th>mcc-n_grams_arithmetic_mean-reduction</th>\n",
       "      <th>mcc-sentence-reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>-0.033133</td>\n",
       "      <td>-0.031700</td>\n",
       "      <td>-0.013867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrastive_weight</th>\n",
       "      <td>-0.080933</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>-0.033833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005400</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctakes</th>\n",
       "      <td>-0.039567</td>\n",
       "      <td>-0.040767</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discriminative_weight</th>\n",
       "      <td>-0.061667</td>\n",
       "      <td>-0.025167</td>\n",
       "      <td>-0.001433</td>\n",
       "      <td>-0.007800</td>\n",
       "      <td>-0.004467</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metamap</th>\n",
       "      <td>-0.010633</td>\n",
       "      <td>-0.129567</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubmedbert</th>\n",
       "      <td>-0.030333</td>\n",
       "      <td>-0.034400</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.078333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickumls</th>\n",
       "      <td>-0.019333</td>\n",
       "      <td>-0.053167</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scibert</th>\n",
       "      <td>-0.047833</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.019900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scispacy</th>\n",
       "      <td>-0.033833</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>-0.010567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_domain_specificity</th>\n",
       "      <td>-0.043700</td>\n",
       "      <td>-0.018200</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.003733</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.003733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mcc-and_operator-reduction  \\\n",
       "method_class                                          \n",
       "bert                                      -0.033133   \n",
       "contrastive_weight                        -0.080933   \n",
       "ctakes                                    -0.039567   \n",
       "discriminative_weight                     -0.061667   \n",
       "metamap                                   -0.010633   \n",
       "pubmedbert                                -0.030333   \n",
       "quickumls                                 -0.019333   \n",
       "scibert                                   -0.047833   \n",
       "scispacy                                  -0.033833   \n",
       "term_domain_specificity                   -0.043700   \n",
       "\n",
       "                         mcc-or_operator-reduction  \\\n",
       "method_class                                         \n",
       "bert                                     -0.031700   \n",
       "contrastive_weight                       -0.034733   \n",
       "ctakes                                   -0.040767   \n",
       "discriminative_weight                    -0.025167   \n",
       "metamap                                  -0.129567   \n",
       "pubmedbert                               -0.034400   \n",
       "quickumls                                -0.053167   \n",
       "scibert                                  -0.021533   \n",
       "scispacy                                 -0.000967   \n",
       "term_domain_specificity                  -0.018200   \n",
       "\n",
       "                         mcc-arithmetic_mean_operator-reduction  \\\n",
       "method_class                                                      \n",
       "bert                                                  -0.013867   \n",
       "contrastive_weight                                    -0.033833   \n",
       "ctakes                                                -0.009967   \n",
       "discriminative_weight                                 -0.001433   \n",
       "metamap                                               -0.000300   \n",
       "pubmedbert                                            -0.010000   \n",
       "quickumls                                             -0.001600   \n",
       "scibert                                               -0.019900   \n",
       "scispacy                                              -0.010567   \n",
       "term_domain_specificity                               -0.002367   \n",
       "\n",
       "                         mcc-n_grams-reduction  mcc-arithmetic_mean-reduction  \\\n",
       "method_class                                                                    \n",
       "bert                                       NaN                            NaN   \n",
       "contrastive_weight                    0.000000                      -0.005400   \n",
       "ctakes                                     NaN                            NaN   \n",
       "discriminative_weight                -0.007800                      -0.004467   \n",
       "metamap                                    NaN                            NaN   \n",
       "pubmedbert                                 NaN                            NaN   \n",
       "quickumls                                  NaN                            NaN   \n",
       "scibert                                    NaN                            NaN   \n",
       "scispacy                                   NaN                            NaN   \n",
       "term_domain_specificity              -0.003733                      -0.001300   \n",
       "\n",
       "                         mcc-n_grams_arithmetic_mean-reduction  \\\n",
       "method_class                                                     \n",
       "bert                                                       NaN   \n",
       "contrastive_weight                                   -0.007133   \n",
       "ctakes                                                     NaN   \n",
       "discriminative_weight                                -0.011500   \n",
       "metamap                                                    NaN   \n",
       "pubmedbert                                                 NaN   \n",
       "quickumls                                                  NaN   \n",
       "scibert                                                    NaN   \n",
       "scispacy                                                   NaN   \n",
       "term_domain_specificity                              -0.003733   \n",
       "\n",
       "                         mcc-sentence-reduction  \n",
       "method_class                                     \n",
       "bert                                        NaN  \n",
       "contrastive_weight                          NaN  \n",
       "ctakes                                      NaN  \n",
       "discriminative_weight                       NaN  \n",
       "metamap                                     NaN  \n",
       "pubmedbert                            -0.078333  \n",
       "quickumls                                   NaN  \n",
       "scibert                                     NaN  \n",
       "scispacy                                    NaN  \n",
       "term_domain_specificity                     NaN  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_approaches_comparison.filter(regex=\"method_class|dataset|mcc-.*reduction\").groupby(\"method_class\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a70317",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_approaches_comparison.loc[best_approaches_comparison.method_class.str.contains(\"bert\")].filter(regex=\"method_class|dataset|mcc-.*reduction\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f2ed402b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>term_domain_specificity-encyclopedia-(1, 2)-1-p=1_mean-1.5152-medical</th>\n",
       "      <th>health_bert-pubmedbert-encyclopedia-noun_phrase-p=2_mean-0.7778-medical</th>\n",
       "      <th>term_domain_specificity-encyclopedia-(1, 2)-1-p=1_mean</th>\n",
       "      <th>health_bert-pubmedbert-encyclopedia-noun_phrase-p=2_mean</th>\n",
       "      <th>medical_score-cause-term_domain_specificity-encyclopedia-(1, 2)-1</th>\n",
       "      <th>medical_score-effect-term_domain_specificity-encyclopedia-(1, 2)-1</th>\n",
       "      <th>medical_score-cause-health_bert-pubmedbert-encyclopedia-noun_phrase</th>\n",
       "      <th>medical_score-effect-health_bert-pubmedbert-encyclopedia-noun_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>yeasts</td>\n",
       "      <td>foods to spoil</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.265092</td>\n",
       "      <td>0.786864</td>\n",
       "      <td>1.451931</td>\n",
       "      <td>1.078254</td>\n",
       "      <td>0.823840</td>\n",
       "      <td>0.748062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>behaviors</td>\n",
       "      <td>acute increase in risk</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.378466</td>\n",
       "      <td>0.822416</td>\n",
       "      <td>1.284063</td>\n",
       "      <td>1.472870</td>\n",
       "      <td>0.735180</td>\n",
       "      <td>0.901247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>prevention of feeding</td>\n",
       "      <td>reduced adult survival</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.978863</td>\n",
       "      <td>0.810400</td>\n",
       "      <td>1.061718</td>\n",
       "      <td>0.896008</td>\n",
       "      <td>0.876438</td>\n",
       "      <td>0.738479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>contact with a liquid metal</td>\n",
       "      <td>decrease in strength</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.689443</td>\n",
       "      <td>0.812767</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>0.735852</td>\n",
       "      <td>0.716680</td>\n",
       "      <td>0.898637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>popcorn popped</td>\n",
       "      <td>18 cups of a healthy , fat-free snack</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.390647</td>\n",
       "      <td>0.824895</td>\n",
       "      <td>2.039687</td>\n",
       "      <td>0.741608</td>\n",
       "      <td>0.703389</td>\n",
       "      <td>0.930670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>developmental trauma</td>\n",
       "      <td>posttraumatic mental health disturbances</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.729015</td>\n",
       "      <td>0.707731</td>\n",
       "      <td>1.564975</td>\n",
       "      <td>1.893054</td>\n",
       "      <td>0.739970</td>\n",
       "      <td>0.673952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>trauma</td>\n",
       "      <td>cognitively reframe negative belief systems</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.544147</td>\n",
       "      <td>0.759928</td>\n",
       "      <td>1.972124</td>\n",
       "      <td>1.116169</td>\n",
       "      <td>0.869753</td>\n",
       "      <td>0.631276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>blockade of histaminergic receptors</td>\n",
       "      <td>sedation</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.168777</td>\n",
       "      <td>0.671174</td>\n",
       "      <td>1.678949</td>\n",
       "      <td>2.658605</td>\n",
       "      <td>0.329198</td>\n",
       "      <td>0.890268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>mutations in mt-tf</td>\n",
       "      <td>associated disorders</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.633024</td>\n",
       "      <td>0.735424</td>\n",
       "      <td>0.961713</td>\n",
       "      <td>2.304336</td>\n",
       "      <td>0.523025</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>early postpartum period</td>\n",
       "      <td>nebal</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.378697</td>\n",
       "      <td>0.640671</td>\n",
       "      <td>1.643018</td>\n",
       "      <td>3.114376</td>\n",
       "      <td>0.891864</td>\n",
       "      <td>0.159678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cause  \\\n",
       "2053                               yeasts   \n",
       "2066                            behaviors   \n",
       "2086                prevention of feeding   \n",
       "2106          contact with a liquid metal   \n",
       "2147                       popcorn popped   \n",
       "...                                   ...   \n",
       "2613                 developmental trauma   \n",
       "2656                               trauma   \n",
       "2667  blockade of histaminergic receptors   \n",
       "2719                   mutations in mt-tf   \n",
       "2893              early postpartum period   \n",
       "\n",
       "                                           effect  evaluation  \\\n",
       "2053                               foods to spoil           0   \n",
       "2066                       acute increase in risk           0   \n",
       "2086                       reduced adult survival           0   \n",
       "2106                         decrease in strength           0   \n",
       "2147        18 cups of a healthy , fat-free snack           0   \n",
       "...                                           ...         ...   \n",
       "2613     posttraumatic mental health disturbances           1   \n",
       "2656  cognitively reframe negative belief systems           1   \n",
       "2667                                     sedation           1   \n",
       "2719                         associated disorders           1   \n",
       "2893                                        nebal           1   \n",
       "\n",
       "      term_domain_specificity-encyclopedia-(1, 2)-1-p=1_mean-1.5152-medical  \\\n",
       "2053                                              False                       \n",
       "2066                                              False                       \n",
       "2086                                              False                       \n",
       "2106                                              False                       \n",
       "2147                                              False                       \n",
       "...                                                 ...                       \n",
       "2613                                               True                       \n",
       "2656                                               True                       \n",
       "2667                                               True                       \n",
       "2719                                               True                       \n",
       "2893                                               True                       \n",
       "\n",
       "      health_bert-pubmedbert-encyclopedia-noun_phrase-p=2_mean-0.7778-medical  \\\n",
       "2053                                               True                         \n",
       "2066                                               True                         \n",
       "2086                                               True                         \n",
       "2106                                               True                         \n",
       "2147                                               True                         \n",
       "...                                                 ...                         \n",
       "2613                                              False                         \n",
       "2656                                              False                         \n",
       "2667                                              False                         \n",
       "2719                                              False                         \n",
       "2893                                              False                         \n",
       "\n",
       "      term_domain_specificity-encyclopedia-(1, 2)-1-p=1_mean  \\\n",
       "2053                                           1.265092        \n",
       "2066                                           1.378466        \n",
       "2086                                           0.978863        \n",
       "2106                                           0.689443        \n",
       "2147                                           1.390647        \n",
       "...                                                 ...        \n",
       "2613                                           1.729015        \n",
       "2656                                           1.544147        \n",
       "2667                                           2.168777        \n",
       "2719                                           1.633024        \n",
       "2893                                           2.378697        \n",
       "\n",
       "      health_bert-pubmedbert-encyclopedia-noun_phrase-p=2_mean  \\\n",
       "2053                                           0.786864          \n",
       "2066                                           0.822416          \n",
       "2086                                           0.810400          \n",
       "2106                                           0.812767          \n",
       "2147                                           0.824895          \n",
       "...                                                 ...          \n",
       "2613                                           0.707731          \n",
       "2656                                           0.759928          \n",
       "2667                                           0.671174          \n",
       "2719                                           0.735424          \n",
       "2893                                           0.640671          \n",
       "\n",
       "      medical_score-cause-term_domain_specificity-encyclopedia-(1, 2)-1  \\\n",
       "2053                                           1.451931                   \n",
       "2066                                           1.284063                   \n",
       "2086                                           1.061718                   \n",
       "2106                                           0.643035                   \n",
       "2147                                           2.039687                   \n",
       "...                                                 ...                   \n",
       "2613                                           1.564975                   \n",
       "2656                                           1.972124                   \n",
       "2667                                           1.678949                   \n",
       "2719                                           0.961713                   \n",
       "2893                                           1.643018                   \n",
       "\n",
       "      medical_score-effect-term_domain_specificity-encyclopedia-(1, 2)-1  \\\n",
       "2053                                           1.078254                    \n",
       "2066                                           1.472870                    \n",
       "2086                                           0.896008                    \n",
       "2106                                           0.735852                    \n",
       "2147                                           0.741608                    \n",
       "...                                                 ...                    \n",
       "2613                                           1.893054                    \n",
       "2656                                           1.116169                    \n",
       "2667                                           2.658605                    \n",
       "2719                                           2.304336                    \n",
       "2893                                           3.114376                    \n",
       "\n",
       "      medical_score-cause-health_bert-pubmedbert-encyclopedia-noun_phrase  \\\n",
       "2053                                           0.823840                     \n",
       "2066                                           0.735180                     \n",
       "2086                                           0.876438                     \n",
       "2106                                           0.716680                     \n",
       "2147                                           0.703389                     \n",
       "...                                                 ...                     \n",
       "2613                                           0.739970                     \n",
       "2656                                           0.869753                     \n",
       "2667                                           0.329198                     \n",
       "2719                                           0.523025                     \n",
       "2893                                           0.891864                     \n",
       "\n",
       "      medical_score-effect-health_bert-pubmedbert-encyclopedia-noun_phrase  \n",
       "2053                                           0.748062                     \n",
       "2066                                           0.901247                     \n",
       "2086                                           0.738479                     \n",
       "2106                                           0.898637                     \n",
       "2147                                           0.930670                     \n",
       "...                                                 ...                     \n",
       "2613                                           0.673952                     \n",
       "2656                                           0.631276                     \n",
       "2667                                           0.890268                     \n",
       "2719                                           0.898966                     \n",
       "2893                                           0.159678                     \n",
       "\n",
       "[78 rows x 11 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different classifications between methods\n",
    "\n",
    "# method_1_name = \"discriminative_weight_pubmed_(1, 1)_1\"\n",
    "# method_2_name = \"discriminative_weight_pubmed_(1, 2)_1\"\n",
    "# op_1 = \"and\"\n",
    "# op_2 = \"and\"\n",
    "# threshold_1 = \"66\"\n",
    "# threshold_2 = \"66\"\n",
    "\n",
    "sort = False\n",
    "ascending=False\n",
    "dataset = \"random_full\"\n",
    "method_1 = \"term_domain_specificity\"\n",
    "method_2 = \"pubmedbert\"\n",
    "method_1_data = best_approaches.loc[best_approaches.dataset == dataset].set_index(\"method_class\").loc[method_1]\n",
    "method_2_data = best_approaches.loc[best_approaches.dataset == dataset].set_index(\"method_class\").loc[method_2]\n",
    "method_1_name = method_1_data.method\n",
    "method_2_name = method_2_data.method\n",
    "op_1 = method_1_data.operator\n",
    "op_2 = method_2_data.operator\n",
    "threshold_1 = method_1_data.threshold\n",
    "threshold_2 = method_2_data.threshold\n",
    "\n",
    "medical_label_1 = \"-\".join([method_1_name, op_1, threshold_1, \"medical\"])\n",
    "medical_label_2 = \"-\".join([method_2_name, op_2, threshold_2, \"medical\"])\n",
    "combined_label_1 = \"-\".join([method_1_name, op_1])\n",
    "combined_label_2 = \"-\".join([method_2_name, op_2])\n",
    "score_label_1 = \"-\".join([\"medical_score\", \"{}\", method_1_name])\n",
    "score_label_2 = \"-\".join([\"medical_score\", \"{}\", method_2_name])\n",
    "\n",
    "labels = [\n",
    "    \"cause\",\n",
    "    \"effect\",\n",
    "    \"evaluation\",\n",
    "    medical_label_1,\n",
    "    medical_label_2,\n",
    "    combined_label_1,\n",
    "    combined_label_2,\n",
    "    score_label_1.format(\"cause\"),\n",
    "    score_label_1.format(\"effect\"),\n",
    "    score_label_2.format(\"cause\"),\n",
    "    score_label_2.format(\"effect\"),\n",
    "]\n",
    "\n",
    "df_filter = pd.Series(True, index=test_causenet_medical.index)\n",
    "df_filter = df_filter & (test_causenet.dataset == dataset)\n",
    "df_filter = df_filter & (\n",
    "    test_causenet_medical[medical_label_1] != test_causenet_medical[medical_label_2]\n",
    ")\n",
    "\n",
    "health_causenet_errors = pd.concat(\n",
    "    [\n",
    "        test_causenet_medical.loc[df_filter, [medical_label_1, medical_label_2]],\n",
    "        test_causenet.loc[\n",
    "            df_filter, \n",
    "            [\n",
    "                \"cause\", \n",
    "                \"effect\", \n",
    "                \"evaluation\",\n",
    "                score_label_1.format(\"cause\"),\n",
    "                score_label_2.format(\"cause\"),\n",
    "                score_label_1.format(\"effect\"),\n",
    "                score_label_2.format(\"effect\"),\n",
    "            ]\n",
    "        ],\n",
    "        test_causenet_combined.loc[df_filter, [combined_label_1, combined_label_2]]\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "health_causenet_errors = health_causenet_errors.loc[:, labels]\n",
    "# if sort:\n",
    "#     sort_index = (\n",
    "#         (health_causenet_errors.iloc[:, -2] + health_causenet_errors.iloc[:, -1])\n",
    "#         .sort_values(ascending=ascending)\n",
    "#         .index\n",
    "#     )\n",
    "#     health_causenet_errors = health_causenet_errors.loc[sort_index]\n",
    "health_causenet_errors = health_causenet_errors.sort_values([\"evaluation\", medical_label_1, medical_label_2])\n",
    "# pprint(health_causenet_errors.head(40).values)\n",
    "health_causenet_errors.to_csv(f\"errors-{method_1_name}_vs_{method_2_name}.csv\")\n",
    "health_causenet_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9230350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-0-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-1-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-10-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-2-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-5-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-inf-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_1-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_10-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_2-p=neg_inf_mean</th>\n",
       "      <th>contrastive_weight-encyclopedia-(1, 1)-neg_5-p=neg_inf_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-1-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-10-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-2-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-5-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-inf-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_1-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_10-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_2-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_5-p=inf_mean</th>\n",
       "      <th>term_domain_specificity-textbook-(1, 3)-neg_inf-p=inf_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>67.798467</td>\n",
       "      <td>69.873389</td>\n",
       "      <td>81.021766</td>\n",
       "      <td>71.888447</td>\n",
       "      <td>76.781316</td>\n",
       "      <td>87.466554</td>\n",
       "      <td>65.785161</td>\n",
       "      <td>56.733299</td>\n",
       "      <td>63.941180</td>\n",
       "      <td>59.866545</td>\n",
       "      <td>...</td>\n",
       "      <td>2.450630</td>\n",
       "      <td>4.369429</td>\n",
       "      <td>3.006363</td>\n",
       "      <td>3.917971</td>\n",
       "      <td>4.876814</td>\n",
       "      <td>1.517960</td>\n",
       "      <td>0.972206</td>\n",
       "      <td>1.309982</td>\n",
       "      <td>1.075320</td>\n",
       "      <td>0.871251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>53.404462</td>\n",
       "      <td>45.028554</td>\n",
       "      <td>83.878408</td>\n",
       "      <td>55.873511</td>\n",
       "      <td>73.393219</td>\n",
       "      <td>96.347242</td>\n",
       "      <td>49.300597</td>\n",
       "      <td>40.157628</td>\n",
       "      <td>46.456866</td>\n",
       "      <td>42.368076</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669797</td>\n",
       "      <td>3.487047</td>\n",
       "      <td>1.706123</td>\n",
       "      <td>2.804447</td>\n",
       "      <td>4.343902</td>\n",
       "      <td>1.604569</td>\n",
       "      <td>1.465112</td>\n",
       "      <td>1.577273</td>\n",
       "      <td>1.517156</td>\n",
       "      <td>1.356729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>36.196968</td>\n",
       "      <td>37.868074</td>\n",
       "      <td>46.163057</td>\n",
       "      <td>39.412924</td>\n",
       "      <td>42.954835</td>\n",
       "      <td>52.253608</td>\n",
       "      <td>34.496975</td>\n",
       "      <td>26.442183</td>\n",
       "      <td>32.883602</td>\n",
       "      <td>29.233749</td>\n",
       "      <td>...</td>\n",
       "      <td>2.272307</td>\n",
       "      <td>3.893345</td>\n",
       "      <td>2.885903</td>\n",
       "      <td>3.527776</td>\n",
       "      <td>4.343902</td>\n",
       "      <td>3.151732</td>\n",
       "      <td>2.649571</td>\n",
       "      <td>3.039347</td>\n",
       "      <td>2.807944</td>\n",
       "      <td>2.473020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>66.769359</td>\n",
       "      <td>65.401842</td>\n",
       "      <td>86.514810</td>\n",
       "      <td>68.387864</td>\n",
       "      <td>77.029185</td>\n",
       "      <td>99.276880</td>\n",
       "      <td>63.948984</td>\n",
       "      <td>53.224631</td>\n",
       "      <td>61.561945</td>\n",
       "      <td>56.804852</td>\n",
       "      <td>...</td>\n",
       "      <td>1.545380</td>\n",
       "      <td>2.988535</td>\n",
       "      <td>1.911380</td>\n",
       "      <td>2.583086</td>\n",
       "      <td>3.473478</td>\n",
       "      <td>0.704371</td>\n",
       "      <td>0.275668</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.324796</td>\n",
       "      <td>0.225322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>88.013589</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>83.560917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "      <td>1.016444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>76.391128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "      <td>1.452753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>76.504865</td>\n",
       "      <td>78.551420</td>\n",
       "      <td>88.832206</td>\n",
       "      <td>80.376113</td>\n",
       "      <td>84.575021</td>\n",
       "      <td>99.697278</td>\n",
       "      <td>74.278987</td>\n",
       "      <td>67.729842</td>\n",
       "      <td>71.958744</td>\n",
       "      <td>67.729842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357910</td>\n",
       "      <td>3.984017</td>\n",
       "      <td>2.007217</td>\n",
       "      <td>3.203975</td>\n",
       "      <td>5.279735</td>\n",
       "      <td>0.631362</td>\n",
       "      <td>0.261043</td>\n",
       "      <td>0.470005</td>\n",
       "      <td>0.316599</td>\n",
       "      <td>0.204198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>79.863367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "      <td>1.448440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>71.656369</td>\n",
       "      <td>73.834796</td>\n",
       "      <td>85.429542</td>\n",
       "      <td>75.745252</td>\n",
       "      <td>80.244733</td>\n",
       "      <td>99.505255</td>\n",
       "      <td>69.213718</td>\n",
       "      <td>52.146408</td>\n",
       "      <td>66.576907</td>\n",
       "      <td>58.985863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.169939</td>\n",
       "      <td>3.168266</td>\n",
       "      <td>1.624856</td>\n",
       "      <td>2.524385</td>\n",
       "      <td>4.150999</td>\n",
       "      <td>0.835512</td>\n",
       "      <td>0.347240</td>\n",
       "      <td>0.676116</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.264950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>64.208187</td>\n",
       "      <td>66.655366</td>\n",
       "      <td>77.352805</td>\n",
       "      <td>68.868648</td>\n",
       "      <td>73.637673</td>\n",
       "      <td>83.735240</td>\n",
       "      <td>61.680533</td>\n",
       "      <td>56.979176</td>\n",
       "      <td>59.258053</td>\n",
       "      <td>58.232736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813104</td>\n",
       "      <td>3.237702</td>\n",
       "      <td>1.342456</td>\n",
       "      <td>2.529321</td>\n",
       "      <td>4.150999</td>\n",
       "      <td>0.402811</td>\n",
       "      <td>0.262203</td>\n",
       "      <td>0.355625</td>\n",
       "      <td>0.297592</td>\n",
       "      <td>0.209602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 5104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contrastive_weight-encyclopedia-(1, 1)-0-p=neg_inf_mean  \\\n",
       "2003                                          67.798467         \n",
       "2006                                          53.404462         \n",
       "2009                                          36.196968         \n",
       "2010                                          66.769359         \n",
       "2050                                          83.560917         \n",
       "...                                                 ...         \n",
       "2958                                          76.391128         \n",
       "2981                                          76.504865         \n",
       "2983                                          79.863367         \n",
       "2985                                          71.656369         \n",
       "2998                                          64.208187         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-1-p=neg_inf_mean  \\\n",
       "2003                                          69.873389         \n",
       "2006                                          45.028554         \n",
       "2009                                          37.868074         \n",
       "2010                                          65.401842         \n",
       "2050                                          83.560917         \n",
       "...                                                 ...         \n",
       "2958                                          76.391128         \n",
       "2981                                          78.551420         \n",
       "2983                                          79.863367         \n",
       "2985                                          73.834796         \n",
       "2998                                          66.655366         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-10-p=neg_inf_mean  \\\n",
       "2003                                          81.021766          \n",
       "2006                                          83.878408          \n",
       "2009                                          46.163057          \n",
       "2010                                          86.514810          \n",
       "2050                                          83.560917          \n",
       "...                                                 ...          \n",
       "2958                                          76.391128          \n",
       "2981                                          88.832206          \n",
       "2983                                          79.863367          \n",
       "2985                                          85.429542          \n",
       "2998                                          77.352805          \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-2-p=neg_inf_mean  \\\n",
       "2003                                          71.888447         \n",
       "2006                                          55.873511         \n",
       "2009                                          39.412924         \n",
       "2010                                          68.387864         \n",
       "2050                                          83.560917         \n",
       "...                                                 ...         \n",
       "2958                                          76.391128         \n",
       "2981                                          80.376113         \n",
       "2983                                          79.863367         \n",
       "2985                                          75.745252         \n",
       "2998                                          68.868648         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-5-p=neg_inf_mean  \\\n",
       "2003                                          76.781316         \n",
       "2006                                          73.393219         \n",
       "2009                                          42.954835         \n",
       "2010                                          77.029185         \n",
       "2050                                          83.560917         \n",
       "...                                                 ...         \n",
       "2958                                          76.391128         \n",
       "2981                                          84.575021         \n",
       "2983                                          79.863367         \n",
       "2985                                          80.244733         \n",
       "2998                                          73.637673         \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-inf-p=neg_inf_mean  \\\n",
       "2003                                          87.466554           \n",
       "2006                                          96.347242           \n",
       "2009                                          52.253608           \n",
       "2010                                          99.276880           \n",
       "2050                                          88.013589           \n",
       "...                                                 ...           \n",
       "2958                                          76.391128           \n",
       "2981                                          99.697278           \n",
       "2983                                          79.863367           \n",
       "2985                                          99.505255           \n",
       "2998                                          83.735240           \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_1-p=neg_inf_mean  \\\n",
       "2003                                          65.785161             \n",
       "2006                                          49.300597             \n",
       "2009                                          34.496975             \n",
       "2010                                          63.948984             \n",
       "2050                                          83.560917             \n",
       "...                                                 ...             \n",
       "2958                                          76.391128             \n",
       "2981                                          74.278987             \n",
       "2983                                          79.863367             \n",
       "2985                                          69.213718             \n",
       "2998                                          61.680533             \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_10-p=neg_inf_mean  \\\n",
       "2003                                          56.733299              \n",
       "2006                                          40.157628              \n",
       "2009                                          26.442183              \n",
       "2010                                          53.224631              \n",
       "2050                                          83.560917              \n",
       "...                                                 ...              \n",
       "2958                                          76.391128              \n",
       "2981                                          67.729842              \n",
       "2983                                          79.863367              \n",
       "2985                                          52.146408              \n",
       "2998                                          56.979176              \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_2-p=neg_inf_mean  \\\n",
       "2003                                          63.941180             \n",
       "2006                                          46.456866             \n",
       "2009                                          32.883602             \n",
       "2010                                          61.561945             \n",
       "2050                                          83.560917             \n",
       "...                                                 ...             \n",
       "2958                                          76.391128             \n",
       "2981                                          71.958744             \n",
       "2983                                          79.863367             \n",
       "2985                                          66.576907             \n",
       "2998                                          59.258053             \n",
       "\n",
       "      contrastive_weight-encyclopedia-(1, 1)-neg_5-p=neg_inf_mean  ...  \\\n",
       "2003                                          59.866545            ...   \n",
       "2006                                          42.368076            ...   \n",
       "2009                                          29.233749            ...   \n",
       "2010                                          56.804852            ...   \n",
       "2050                                          83.560917            ...   \n",
       "...                                                 ...            ...   \n",
       "2958                                          76.391128            ...   \n",
       "2981                                          67.729842            ...   \n",
       "2983                                          79.863367            ...   \n",
       "2985                                          58.985863            ...   \n",
       "2998                                          58.232736            ...   \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-1-p=inf_mean  \\\n",
       "2003                                           2.450630      \n",
       "2006                                           1.669797      \n",
       "2009                                           2.272307      \n",
       "2010                                           1.545380      \n",
       "2050                                           1.016444      \n",
       "...                                                 ...      \n",
       "2958                                           1.452753      \n",
       "2981                                           1.357910      \n",
       "2983                                           1.448440      \n",
       "2985                                           1.169939      \n",
       "2998                                           0.813104      \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-10-p=inf_mean  \\\n",
       "2003                                           4.369429       \n",
       "2006                                           3.487047       \n",
       "2009                                           3.893345       \n",
       "2010                                           2.988535       \n",
       "2050                                           1.016444       \n",
       "...                                                 ...       \n",
       "2958                                           1.452753       \n",
       "2981                                           3.984017       \n",
       "2983                                           1.448440       \n",
       "2985                                           3.168266       \n",
       "2998                                           3.237702       \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-2-p=inf_mean  \\\n",
       "2003                                           3.006363      \n",
       "2006                                           1.706123      \n",
       "2009                                           2.885903      \n",
       "2010                                           1.911380      \n",
       "2050                                           1.016444      \n",
       "...                                                 ...      \n",
       "2958                                           1.452753      \n",
       "2981                                           2.007217      \n",
       "2983                                           1.448440      \n",
       "2985                                           1.624856      \n",
       "2998                                           1.342456      \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-5-p=inf_mean  \\\n",
       "2003                                           3.917971      \n",
       "2006                                           2.804447      \n",
       "2009                                           3.527776      \n",
       "2010                                           2.583086      \n",
       "2050                                           1.016444      \n",
       "...                                                 ...      \n",
       "2958                                           1.452753      \n",
       "2981                                           3.203975      \n",
       "2983                                           1.448440      \n",
       "2985                                           2.524385      \n",
       "2998                                           2.529321      \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-inf-p=inf_mean  \\\n",
       "2003                                           4.876814        \n",
       "2006                                           4.343902        \n",
       "2009                                           4.343902        \n",
       "2010                                           3.473478        \n",
       "2050                                           1.016444        \n",
       "...                                                 ...        \n",
       "2958                                           1.452753        \n",
       "2981                                           5.279735        \n",
       "2983                                           1.448440        \n",
       "2985                                           4.150999        \n",
       "2998                                           4.150999        \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_1-p=inf_mean  \\\n",
       "2003                                           1.517960          \n",
       "2006                                           1.604569          \n",
       "2009                                           3.151732          \n",
       "2010                                           0.704371          \n",
       "2050                                           1.016444          \n",
       "...                                                 ...          \n",
       "2958                                           1.452753          \n",
       "2981                                           0.631362          \n",
       "2983                                           1.448440          \n",
       "2985                                           0.835512          \n",
       "2998                                           0.402811          \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_10-p=inf_mean  \\\n",
       "2003                                           0.972206           \n",
       "2006                                           1.465112           \n",
       "2009                                           2.649571           \n",
       "2010                                           0.275668           \n",
       "2050                                           1.016444           \n",
       "...                                                 ...           \n",
       "2958                                           1.452753           \n",
       "2981                                           0.261043           \n",
       "2983                                           1.448440           \n",
       "2985                                           0.347240           \n",
       "2998                                           0.262203           \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_2-p=inf_mean  \\\n",
       "2003                                           1.309982          \n",
       "2006                                           1.577273          \n",
       "2009                                           3.039347          \n",
       "2010                                           0.490566          \n",
       "2050                                           1.016444          \n",
       "...                                                 ...          \n",
       "2958                                           1.452753          \n",
       "2981                                           0.470005          \n",
       "2983                                           1.448440          \n",
       "2985                                           0.676116          \n",
       "2998                                           0.355625          \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_5-p=inf_mean  \\\n",
       "2003                                           1.075320          \n",
       "2006                                           1.517156          \n",
       "2009                                           2.807944          \n",
       "2010                                           0.324796          \n",
       "2050                                           1.016444          \n",
       "...                                                 ...          \n",
       "2958                                           1.452753          \n",
       "2981                                           0.316599          \n",
       "2983                                           1.448440          \n",
       "2985                                           0.446379          \n",
       "2998                                           0.297592          \n",
       "\n",
       "      term_domain_specificity-textbook-(1, 3)-neg_inf-p=inf_mean  \n",
       "2003                                           0.871251           \n",
       "2006                                           1.356729           \n",
       "2009                                           2.473020           \n",
       "2010                                           0.225322           \n",
       "2050                                           1.016444           \n",
       "...                                                 ...           \n",
       "2958                                           1.452753           \n",
       "2981                                           0.204198           \n",
       "2983                                           1.448440           \n",
       "2985                                           0.264950           \n",
       "2998                                           0.209602           \n",
       "\n",
       "[78 rows x 5104 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet_combined.loc[df_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "32787a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>cause_origin</th>\n",
       "      <th>effect_origin</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>discriminative_weight-encyclopedia-(1, 1)-2-arithmetic_mean-60-medical</th>\n",
       "      <th>medical_score-cause-discriminative_weight-encyclopedia-(1, 1)-2</th>\n",
       "      <th>medical_score-effect-discriminative_weight-encyclopedia-(1, 1)-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>fungus</td>\n",
       "      <td>acute respiratory tract infection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>55.314004</td>\n",
       "      <td>97.148067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>fungus</td>\n",
       "      <td>acute respiratory disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>55.314004</td>\n",
       "      <td>89.256963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>sulfur mustard exposure</td>\n",
       "      <td>anemia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>39.658172</td>\n",
       "      <td>130.575664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>brain development</td>\n",
       "      <td>brain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>54.176588</td>\n",
       "      <td>75.984139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>iodine</td>\n",
       "      <td>iodine exposure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>88.756517</td>\n",
       "      <td>77.461914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12103</th>\n",
       "      <td>congenital transmission</td>\n",
       "      <td>placental transmission</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>77.179237</td>\n",
       "      <td>44.643437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12134</th>\n",
       "      <td>surgical procedure</td>\n",
       "      <td>Surgical smoke</td>\n",
       "      <td>wd:Q796194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>91.435716</td>\n",
       "      <td>29.187455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>autosomal recessive</td>\n",
       "      <td>autosomal recessive disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>90.370322</td>\n",
       "      <td>90.974421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12284</th>\n",
       "      <td>destruction</td>\n",
       "      <td>bleeding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>18.037685</td>\n",
       "      <td>137.648458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12321</th>\n",
       "      <td>absence</td>\n",
       "      <td>atrophic vaginitis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>27.144537</td>\n",
       "      <td>98.659483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cause                             effect  \\\n",
       "4057                    fungus  acute respiratory tract infection   \n",
       "4073                    fungus          acute respiratory disease   \n",
       "4103   sulfur mustard exposure                             anemia   \n",
       "4178         brain development                              brain   \n",
       "4197                    iodine                    iodine exposure   \n",
       "...                        ...                                ...   \n",
       "12103  congenital transmission             placental transmission   \n",
       "12134       surgical procedure                     Surgical smoke   \n",
       "12136      autosomal recessive        autosomal recessive disease   \n",
       "12284              destruction                           bleeding   \n",
       "12321                  absence                 atrophic vaginitis   \n",
       "\n",
       "      cause_origin effect_origin  evaluation  \\\n",
       "4057           NaN   wd:Q7189713           0   \n",
       "4073           NaN   wd:Q7189713           0   \n",
       "4103           NaN   wd:Q7189713           0   \n",
       "4178           NaN           NaN           0   \n",
       "4197           NaN   wd:Q7189713           0   \n",
       "...            ...           ...         ...   \n",
       "12103  wd:Q7189713           NaN           0   \n",
       "12134   wd:Q796194           NaN           0   \n",
       "12136          NaN   wd:Q7189713           0   \n",
       "12284          NaN   wd:Q7189713           0   \n",
       "12321          NaN   wd:Q7189713           0   \n",
       "\n",
       "       discriminative_weight-encyclopedia-(1, 1)-2-arithmetic_mean-60-medical  \\\n",
       "4057                                                True                        \n",
       "4073                                                True                        \n",
       "4103                                                True                        \n",
       "4178                                                True                        \n",
       "4197                                                True                        \n",
       "...                                                  ...                        \n",
       "12103                                               True                        \n",
       "12134                                               True                        \n",
       "12136                                               True                        \n",
       "12284                                               True                        \n",
       "12321                                               True                        \n",
       "\n",
       "       medical_score-cause-discriminative_weight-encyclopedia-(1, 1)-2  \\\n",
       "4057                                           55.314004                 \n",
       "4073                                           55.314004                 \n",
       "4103                                           39.658172                 \n",
       "4178                                           54.176588                 \n",
       "4197                                           88.756517                 \n",
       "...                                                  ...                 \n",
       "12103                                          77.179237                 \n",
       "12134                                          91.435716                 \n",
       "12136                                          90.370322                 \n",
       "12284                                          18.037685                 \n",
       "12321                                          27.144537                 \n",
       "\n",
       "       medical_score-effect-discriminative_weight-encyclopedia-(1, 1)-2  \n",
       "4057                                           97.148067                 \n",
       "4073                                           89.256963                 \n",
       "4103                                          130.575664                 \n",
       "4178                                           75.984139                 \n",
       "4197                                           77.461914                 \n",
       "...                                                  ...                 \n",
       "12103                                          44.643437                 \n",
       "12134                                          29.187455                 \n",
       "12136                                          90.974421                 \n",
       "12284                                         137.648458                 \n",
       "12321                                          98.659483                 \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascending = False\n",
    "sort = False\n",
    "method = \"discriminative_weight-encyclopedia-(1, 1)-2\"\n",
    "op = \"arithmetic_mean\"\n",
    "threshold = \"60\"\n",
    "medical_label = \"-\".join([method, op, threshold, \"medical\"])\n",
    "labels = [\n",
    "    \"cause\",\n",
    "    \"effect\",\n",
    "    \"cause_origin\",\n",
    "    \"effect_origin\",\n",
    "    f\"medical_score-cause-{method}\",\n",
    "    f\"medical_score-effect-{method}\",\n",
    "]\n",
    "dataset = \"wikidata\"\n",
    "errors = [\n",
    "    #     \"tp\",\n",
    "    \"fp\",\n",
    "    #     \"tn\",\n",
    "    #     \"fn\",\n",
    "]\n",
    "value_filter = pd.Series(True, index=test_causenet_medical.index)\n",
    "if dataset:\n",
    "    value_filter = value_filter & ((test_causenet.dataset == dataset).values)\n",
    "if errors:\n",
    "    error_filter = pd.Series(False, index=test_causenet_medical.index)\n",
    "    if \"tp\" in errors:\n",
    "        error_filter = error_filter | (test_causenet_medical[medical_label] == 1) & (\n",
    "            evaluation.values == 1\n",
    "        )\n",
    "    if \"fp\" in errors:\n",
    "        error_filter = error_filter | (test_causenet_medical[medical_label] == 1) & (\n",
    "            evaluation.values == 0\n",
    "        )\n",
    "    if \"tn\" in errors:\n",
    "        error_filter = error_filter | (test_causenet_medical[medical_label] == 0) & (\n",
    "            evaluation.values == 0\n",
    "        )\n",
    "    if \"fn\" in errors:\n",
    "        error_filter = error_filter | (test_causenet_medical[medical_label] == 0) & (\n",
    "            evaluation.values == 1\n",
    "        )\n",
    "    value_filter = value_filter & error_filter\n",
    "health_causenet_errors = pd.concat(\n",
    "    [\n",
    "        test_causenet.loc[value_filter.values, labels],\n",
    "        test_causenet_medical.loc[value_filter.values, [medical_label]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "health_causenet_errors[\"evaluation\"] = evaluation.loc[value_filter.values].values\n",
    "health_causenet_errors = health_causenet_errors.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"cause\",\n",
    "        \"effect\",\n",
    "        \"cause_origin\",\n",
    "        \"effect_origin\",\n",
    "        \"evaluation\",\n",
    "        medical_label,\n",
    "        f\"medical_score-cause-{method}\",\n",
    "        f\"medical_score-effect-{method}\",\n",
    "    ],\n",
    "]\n",
    "if sort:\n",
    "    sort_index = (\n",
    "        (health_causenet_errors.iloc[:, -2] + health_causenet_errors.iloc[:, -1])\n",
    "        .sort_values(ascending=ascending)\n",
    "        .index\n",
    "    )\n",
    "    health_causenet_errors = health_causenet_errors.loc[sort_index]\n",
    "# else:\n",
    "#     health_causenet_errors = health_causenet_errors.sample(health_causenet_errors.shape[0])\n",
    "health_causenet_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41202056",
   "metadata": {},
   "source": [
    "# Sentence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b05c4d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>operator</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>method_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_full</td>\n",
       "      <td>quickumls-rx_sno-1.0</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.4923</td>\n",
       "      <td>quickumls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_full</td>\n",
       "      <td>scispacy-rx_sno-en_core_sci_lg-0.6</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.3535</td>\n",
       "      <td>152.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>scispacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_full</td>\n",
       "      <td>ctakes-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>119.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>ctakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_full</td>\n",
       "      <td>metamap-rx_sno</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.5657</td>\n",
       "      <td>165.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.4271</td>\n",
       "      <td>metamap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-bert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>180.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-scibert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4343</td>\n",
       "      <td>188.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.7094</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>scibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_full</td>\n",
       "      <td>health_bert-pubmedbert-encyclopedia-noun_phrase</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.596</td>\n",
       "      <td>179.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>pubmedbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_full</td>\n",
       "      <td>contrastive_weight-encyclopedia-(1, 1)-5</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>66.3636</td>\n",
       "      <td>164.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>contrastive_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_full</td>\n",
       "      <td>term_domain_specificity-encyclopedia-(1, 1)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>189.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>term_domain_specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_full</td>\n",
       "      <td>discriminative_weight-encyclopedia-(1, 2)-1</td>\n",
       "      <td>p=inf_mean</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>182.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>discriminative_weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset                                           method    operator  \\\n",
       "0  random_full                             quickumls-rx_sno-1.0  p=inf_mean   \n",
       "1  random_full               scispacy-rx_sno-en_core_sci_lg-0.6  p=inf_mean   \n",
       "2  random_full                                    ctakes-rx_sno  p=inf_mean   \n",
       "3  random_full                                   metamap-rx_sno  p=inf_mean   \n",
       "4  random_full        health_bert-bert-encyclopedia-noun_phrase  p=inf_mean   \n",
       "5  random_full     health_bert-scibert-encyclopedia-noun_phrase  p=inf_mean   \n",
       "6  random_full  health_bert-pubmedbert-encyclopedia-noun_phrase  p=inf_mean   \n",
       "7  random_full         contrastive_weight-encyclopedia-(1, 1)-5  p=inf_mean   \n",
       "8  random_full    term_domain_specificity-encyclopedia-(1, 1)-1  p=inf_mean   \n",
       "9  random_full      discriminative_weight-encyclopedia-(1, 2)-1  p=inf_mean   \n",
       "\n",
       "  threshold     tp     fp     tn     fn  precision  recall      f1  accuracy  \\\n",
       "0    0.4141  125.0   70.0  706.0   99.0     0.6410  0.5580  0.5967     0.831   \n",
       "1    0.3535  152.0  138.0  638.0   72.0     0.5241  0.6786  0.5914     0.790   \n",
       "2    0.4545  119.0   59.0  717.0  105.0     0.6685  0.5312  0.5920     0.836   \n",
       "3    0.5657  165.0  191.0  585.0   59.0     0.4635  0.7366  0.5690     0.750   \n",
       "4    0.6768  180.0   41.0  735.0   44.0     0.8145  0.8036  0.8090     0.915   \n",
       "5    0.4343  188.0   77.0  699.0   36.0     0.7094  0.8393  0.7689     0.887   \n",
       "6     0.596  179.0   39.0  737.0   45.0     0.8211  0.7991  0.8100     0.916   \n",
       "7   66.3636  164.0   39.0  737.0   60.0     0.8079  0.7321  0.7681     0.901   \n",
       "8    0.4848  189.0   61.0  715.0   35.0     0.7560  0.8438  0.7975     0.904   \n",
       "9   33.3333  182.0   49.0  727.0   42.0     0.7879  0.8125  0.8000     0.909   \n",
       "\n",
       "      mcc             method_class  \n",
       "0  0.4923                quickumls  \n",
       "1  0.4601                 scispacy  \n",
       "2  0.4962                   ctakes  \n",
       "3  0.4271                  metamap  \n",
       "4  0.7544                     bert  \n",
       "5  0.6991                  scibert  \n",
       "6  0.7562               pubmedbert  \n",
       "7  0.7068       contrastive_weight  \n",
       "8  0.7367  term_domain_specificity  \n",
       "9  0.7413    discriminative_weight  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = [\n",
    "    \"quickumls\",\n",
    "    \"scispacy\",\n",
    "    \"ctakes\",\n",
    "    \"metamap\",\n",
    "    \"-bert\",\n",
    "    \"scibert\",\n",
    "    \"pubmedbert\",\n",
    "    \"contrastive\",\n",
    "    \"specificity\",\n",
    "    \"discriminative\",\n",
    "]\n",
    "\n",
    "precision_threshold = 0.0\n",
    "datasets = [\n",
    "    \"random_full\",\n",
    "    #     \"random_support\",\n",
    "    #     \"support\",\n",
    "]\n",
    "macro = False\n",
    "eval_ops = [\"p=inf_mean\"]\n",
    "optimization_score = \"mcc\"\n",
    "\n",
    "best_approaches = best_approach(\n",
    "    sentence_test_causenet_metrics,\n",
    "    patterns,\n",
    "    datasets,\n",
    "    precision_threshold,\n",
    "    optimization_score,\n",
    "    eval_ops,\n",
    "    macro,\n",
    ")\n",
    "best_approaches.to_csv(f\"sentence_best_approaches_{optimization_score}_{precision_threshold}.csv\")\n",
    "best_approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "be7b42e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaMap & 0.46 & 0.74 & 0.57 & 0.43 \\\\\n",
      "cTakes & 0.67 & 0.53 & 0.59 & 0.50 \\\\\n",
      "QuickUMLS & 0.64 & 0.56 & 0.60 & 0.49 \\\\\n",
      "ScispaCy & 0.52 & 0.68 & 0.59 & 0.46 \\\\\n",
      "BERT & 0.81 & 0.80 & \\highlight{0.81} & 0.75 \\\\\n",
      "SciBERT & 0.71 & \\highlight{0.84} & 0.77 & 0.70 \\\\\n",
      "PubMedBERT & 0.82 & 0.80 & \\highlight{0.81} & \\highlight{0.76} \\\\\n",
      "CW & 0.81 & 0.73 & 0.77 & 0.71 \\\\\n",
      "TDS & 0.76 & \\highlight{0.84} & 0.80 & 0.74 \\\\\n",
      "DW & 0.79 & 0.81 & 0.80 & 0.74 \\\\\n"
     ]
    }
   ],
   "source": [
    "# dataset = \"wikidata\"\n",
    "dataset = \"random_full\"\n",
    "# dataset = \"random_support\"\n",
    "# dataset = \"practitioner_full\"\n",
    "# dataset = \"practitioner_sure\"\n",
    "# dataset = \"practitioner_unsure\"\n",
    "\n",
    "approaches = [\n",
    "    \"metamap\",\n",
    "    \"ctakes\",\n",
    "    \"quickumls\",\n",
    "    \"scispacy\",\n",
    "    \"-bert\",\n",
    "    \"scibert\",\n",
    "    \"pubmedbert\",\n",
    "    \"contrastive\",\n",
    "    \"specificity\",\n",
    "    \"discriminative\",\n",
    "]\n",
    "\n",
    "\n",
    "def key(series):\n",
    "    order = pd.Series(-1, index=series.index)\n",
    "    for idx, approach in enumerate(approaches):\n",
    "        order[series.str.contains(approach)] = idx\n",
    "    return order\n",
    "\n",
    "\n",
    "pretty_print_approaches = best_approaches.copy()\n",
    "pretty_print_approaches[\"pretty_method\"] = pretty_print_approaches.method.map(\n",
    "    lambda x: rename_method(x, False)\n",
    ")\n",
    "pretty_print_approaches[\"pretty_operator\"] = pretty_print_approaches.operator.map(\n",
    "    rename_operator\n",
    ")\n",
    "\n",
    "pretty_print_approaches = pretty_print_approaches.loc[\n",
    "    pretty_print_approaches.dataset == dataset\n",
    "]\n",
    "pretty_print_approaches = pretty_print_approaches.loc[\n",
    "    key(pretty_print_approaches.method) != -1\n",
    "]\n",
    "pretty_print_approaches = pretty_print_approaches.sort_values(by=\"method\", key=key)\n",
    "\n",
    "pprint(\n",
    "    pretty_print_approaches.loc[\n",
    "        :, [\"pretty_method\", \"precision\", \"recall\", \"f1\", \"mcc\"]\n",
    "    ].values,\n",
    "    bold=True,\n",
    "    bold_idcs=[-1, -2, -3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b4e5a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Tax1 affects a wide variety of cellular signalling pathways leading to transcriptional activation, proliferation and ultimately transformation.',\n",
       "  20.262015825725552,\n",
       "  1],\n",
       " ['Activation of the Met receptor also results in an increase in receptor-mediated activation of PLC-γ which catalyzes the generation of IP3 (Inositol 1,4,5-Trisphosphate) and DAG (Diacylglycerol) from PIP2 (Phosphatidylinositol 4,5-Bisphosphate), which act as second messenger molecules to mobilize intracellular Calcium and activate PKC (Protein Kinase-C) respectively.',\n",
       "  10.051872146599177,\n",
       "  1],\n",
       " ['In conditions of high metabolic flux requiring energy production, the mitochondrial failure to meet the energetic demand results in high production of ROS causing cell death.',\n",
       "  33.1154380609626,\n",
       "  1],\n",
       " ['Advances in both our understanding of the RHD locus and its variants, as well as technical improvements in the extraction and amplification of cell-free fetal DNA in maternal plasma, have led to incorporation of non-invasive diagnosis of RHD genotype into routine prenatal care in the United Kingdom, France, and the Netherlands (6).',\n",
       "  28.40529424723335,\n",
       "  1],\n",
       " ['The continuing harm caused by tobacco use in the United States and abroad necessitates that tobacco policy research remain front and center.',\n",
       "  19.563383503613103,\n",
       "  1],\n",
       " ['According to his pension papers, this wound caused a \"loss of memory and an affliction of the eyes\" which affected him the rest of his life.',\n",
       "  26.779201976122277,\n",
       "  1],\n",
       " ['The analysis in Drosophila supports this hypothesis: lack of Dg function results in tumor-like structures and abnormal cell movement because of the lack of epithelial integrity and cellular polarity (Deng, 2003).',\n",
       "  34.46938059166527,\n",
       "  1],\n",
       " ['Williams Syndrome (WS) is a neurodevelopmental disorder caused by a hemizygous microdeletion on 7q11.23, involving about 25 genes.',\n",
       "  34.77429215607209,\n",
       "  1],\n",
       " ['Despite all the pain and misery resulting from the cuts already inflicted, Osborne and his government are on �negative watch� from the ratings agency Moody�s.',\n",
       "  19.743697109038152,\n",
       "  1],\n",
       " ['After adjusting for age, body mass index and smoking, OC use was significantly associated (P<0.05) with higher plasma retinol, 25-hydroxyvitamin D, total iron-binding capacity, total cholesterol, LDL-cholesterol and triacylglycerol concentrations.',\n",
       "  33.193282902672465,\n",
       "  1]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"random_full\"\n",
    "# method = \"health_bert-encyclopedia-noun_phrase\"\n",
    "method = \"discriminative_weight-encyclopedia-(1, 1)-1\"\n",
    "operator = \"or\"\n",
    "# threshold = \"0.64\"\n",
    "threshold = \"35\"\n",
    "label_name = \"-\".join((method, operator, threshold)) + \"-medical\"\n",
    "score_name = \"medical_score-cause-\" + method\n",
    "filter_bool = (\n",
    "    (sentence_test_causenet.dataset == dataset)\n",
    "    & ~sentence_test_causenet_medical[label_name]\n",
    "    & sentence_test_causenet.evaluation\n",
    ")\n",
    "sentence_test_causenet.loc[filter_bool, [\"cause\", score_name, \"evaluation\"]].rename(\n",
    "    {score_name: \"medical_score\"}, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1053f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"random_full\"\n",
    "method_1 = \"health_bert-encyclopedia-noun_phrase\"\n",
    "method_2 = \"discriminative_weight-encyclopedia-(1, 1)-1\"\n",
    "threshold_1 = \"0.64\"\n",
    "threshold_2 = \"35\"\n",
    "label_name_1 = \"-\".join((method_1, \"or\", threshold)) + \"-medical\"\n",
    "label_name_2 = \"-\".join((method_2, \"or\", threshold)) + \"-medical\"\n",
    "score_name = \"medical_score-cause-\" + method\n",
    "filter_bool = (\n",
    "    (sentence_test_causenet.dataset == dataset)\n",
    "    & ~sentence_test_causenet_medical[label_name]\n",
    "    & sentence_test_causenet.evaluation\n",
    ")\n",
    "sentence_test_causenet.loc[filter_bool, [\"cause\", score_name, \"evaluation\"]].rename(\n",
    "    {score_name: \"medical_score\"}, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10558705",
   "metadata": {},
   "source": [
    "# Sentence vs Phrase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6090f31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['discriminative_weight-encyclopedia-(1, 3)-1-and-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-0-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-5-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-10-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-15-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-20-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-25-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-30-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-35-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-40-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-45-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-50-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-55-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-60-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-65-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-70-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-75-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-80-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-85-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-90-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-95-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-100-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-105-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-110-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-115-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-120-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-125-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-130-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-135-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-140-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-145-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-150-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-155-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=2_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=2_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=2_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=2_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=2_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=5_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=5_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=5_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=5_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=5_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=10_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=10_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=10_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=10_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=10_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=inf_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=inf_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=inf_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=inf_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=inf_mean-160-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-and-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-and-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-and-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-and-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-and-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-1-p=1_mean-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-10-p=1_mean-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-2-p=1_mean-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-5-p=1_mean-165-medical',\n",
       " 'discriminative_weight-encyclopedia-(1, 3)-inf-p=1_mean-165-medical',\n",
       " ...]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([method for method in test_causenet_medical if \"discriminative_weight-encyclopedia-(1, 3)\" in method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "86813049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of health related predictions:\n",
      "phrase_prediction      38\n",
      "sentence_prediction    80\n",
      "dtype: int64\n",
      "\n",
      "number of incorrect health related predictions:\n",
      "phrase_prediction      26\n",
      "sentence_prediction    70\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>sentence</th>\n",
       "      <th>phrase_label</th>\n",
       "      <th>sentence_label</th>\n",
       "      <th>phrase_prediction</th>\n",
       "      <th>sentence_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>use of some of these services</td>\n",
       "      <td>additional charges</td>\n",
       "      <td>Use of some of these services may result in ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>surgery</td>\n",
       "      <td>long postoperative recovery</td>\n",
       "      <td>,[url=\"http://bezutuwoli.wordpress.com\"]medica...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>heavy concentration</td>\n",
       "      <td>body to become tense</td>\n",
       "      <td>Heavy concentration will also tend to cause yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>opportunistic condition</td>\n",
       "      <td>life forms in the blood</td>\n",
       "      <td>This opportunistic condition causes life forms...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>over-stimulation of the lateral hypothalamus</td>\n",
       "      <td>overeating</td>\n",
       "      <td>Over-stimulation of the lateral hypothalamus c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>early season competition</td>\n",
       "      <td>significant yield reductions</td>\n",
       "      <td>Moreover, you may have significant yield reduc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>plant-parasitic nematodes</td>\n",
       "      <td>diseases</td>\n",
       "      <td>Management of nematode and insect-borne plant ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>material change in your physical behaviors</td>\n",
       "      <td>material change in your subsequent physical he...</td>\n",
       "      <td>If the offering is rigorous and results in a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>path</td>\n",
       "      <td>bridge crossing the stream</td>\n",
       "      <td>The path leads you to a bridge crossing the st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>medical neglect of a patient at another nursin...</td>\n",
       "      <td>abuse</td>\n",
       "      <td>That dispute arose when HRS found indications ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  cause  \\\n",
       "2000                      use of some of these services   \n",
       "2012                                            surgery   \n",
       "2024                                heavy concentration   \n",
       "2031                            opportunistic condition   \n",
       "2033       over-stimulation of the lateral hypothalamus   \n",
       "...                                                 ...   \n",
       "2960                           early season competition   \n",
       "2973                          plant-parasitic nematodes   \n",
       "2985         material change in your physical behaviors   \n",
       "2993                                               path   \n",
       "2996  medical neglect of a patient at another nursin...   \n",
       "\n",
       "                                                 effect  \\\n",
       "2000                                 additional charges   \n",
       "2012                        long postoperative recovery   \n",
       "2024                               body to become tense   \n",
       "2031                            life forms in the blood   \n",
       "2033                                         overeating   \n",
       "...                                                 ...   \n",
       "2960                       significant yield reductions   \n",
       "2973                                           diseases   \n",
       "2985  material change in your subsequent physical he...   \n",
       "2993                         bridge crossing the stream   \n",
       "2996                                              abuse   \n",
       "\n",
       "                                               sentence  phrase_label  \\\n",
       "2000  Use of some of these services may result in ad...             0   \n",
       "2012  ,[url=\"http://bezutuwoli.wordpress.com\"]medica...             1   \n",
       "2024  Heavy concentration will also tend to cause yo...             0   \n",
       "2031  This opportunistic condition causes life forms...             0   \n",
       "2033  Over-stimulation of the lateral hypothalamus c...             1   \n",
       "...                                                 ...           ...   \n",
       "2960  Moreover, you may have significant yield reduc...             0   \n",
       "2973  Management of nematode and insect-borne plant ...             1   \n",
       "2985  If the offering is rigorous and results in a m...             0   \n",
       "2993  The path leads you to a bridge crossing the st...             0   \n",
       "2996  That dispute arose when HRS found indications ...             0   \n",
       "\n",
       "      sentence_label  phrase_prediction  sentence_prediction  \n",
       "2000             0.0              False                 True  \n",
       "2012             1.0               True                False  \n",
       "2024             0.0              False                 True  \n",
       "2031             1.0              False                 True  \n",
       "2033             1.0              False                 True  \n",
       "...              ...                ...                  ...  \n",
       "2960             0.0              False                 True  \n",
       "2973             0.0               True                False  \n",
       "2985             0.0               True                False  \n",
       "2993             0.0              False                 True  \n",
       "2996             0.0               True                False  \n",
       "\n",
       "[118 rows x 7 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_threshold = 0.0\n",
    "dataset = \"random_full\"\n",
    "approach = \"health_bert\"\n",
    "phrase_approaches = pd.read_csv(\n",
    "    f\"best_approaches_{precision_threshold}.csv\", index_col=0\n",
    ")\n",
    "phrase_approaches = phrase_approaches.loc[phrase_approaches.dataset == \"random_full\"]\n",
    "sentence_approaches = pd.read_csv(\n",
    "    f\"sentence_best_approaches_{precision_threshold}.csv\", index_col=0\n",
    ")\n",
    "\n",
    "phrase_predictions = []\n",
    "sentence_predictions = []\n",
    "for _, method, operator, threshold, *_ in phrase_approaches.values:\n",
    "    try:\n",
    "        label = \"-\".join([method, operator, str(threshold), \"medical\"])\n",
    "        phrase_predictions.append(\n",
    "            test_causenet_medical.loc[test_causenet.dataset == dataset, label]\n",
    "        )\n",
    "    except KeyError:\n",
    "        threshold = int(threshold)\n",
    "        label = \"-\".join([method, operator, str(threshold), \"medical\"])\n",
    "        phrase_predictions.append(\n",
    "            test_causenet_medical.loc[test_causenet.dataset == dataset, label]\n",
    "        )\n",
    "for _, method, operator, threshold, *_ in sentence_approaches.values:\n",
    "    try:\n",
    "        label = \"-\".join([method, operator, str(threshold), \"medical\"])\n",
    "        sentence_predictions.append(\n",
    "            sentence_test_causenet_medical.loc[test_causenet.dataset == dataset, label]\n",
    "        )\n",
    "    except KeyError:\n",
    "        threshold = int(threshold)\n",
    "        label = \"-\".join([method, operator, str(threshold), \"medical\"])\n",
    "        sentence_predictions.append(\n",
    "            sentence_test_causenet_medical.loc[test_causenet.dataset == dataset, label]\n",
    "        )\n",
    "phrase_predictions = pd.concat(phrase_predictions, axis=1)\n",
    "sentence_predictions = pd.concat(sentence_predictions, axis=1)\n",
    "phrase_predictions.columns = [\n",
    "    column.split(\"-\")[0] for column in phrase_predictions.columns\n",
    "]\n",
    "sentence_predictions.columns = [\n",
    "    column.split(\"-\")[0] for column in sentence_predictions.columns\n",
    "]\n",
    "different_predictions = phrase_predictions != sentence_predictions\n",
    "different_predictions = sentence_test_causenet.loc[sentence_test_causenet.dataset == dataset].loc[\n",
    "    different_predictions[approach].values, [\"cause\", \"effect\", \"sentence\"]\n",
    "].join(phrase_predictions[approach].rename(\"phrase_prediction\")).join(\n",
    "    sentence_predictions[approach].rename(\"sentence_prediction\")\n",
    ").join(\n",
    "    test_causenet.evaluation.rename(\"phrase_label\")\n",
    ").join(\n",
    "    sentence_test_causenet.manual_evaluation.rename(\"sentence_label\")\n",
    ").loc[\n",
    "    :,\n",
    "    [\n",
    "        \"cause\",\n",
    "        \"effect\",\n",
    "        \"sentence\",\n",
    "        \"phrase_label\",\n",
    "        \"sentence_label\",\n",
    "        \"phrase_prediction\",\n",
    "        \"sentence_prediction\",\n",
    "    ],\n",
    "]\n",
    "different_predictions.to_csv(\n",
    "    f\"sentence_phrase_differences_{approach}.csv\"\n",
    ")\n",
    "print(\"number of health related predictions:\")\n",
    "print(different_predictions[[\"phrase_prediction\", \"sentence_prediction\"]].sum())\n",
    "print()\n",
    "print(\"number of incorrect health related predictions:\")\n",
    "print(pd.Series([(different_predictions.phrase_prediction != different_predictions.phrase_label).sum(), \n",
    "     (different_predictions.sentence_prediction != different_predictions.sentence_label).sum()], index=[\"phrase_prediction\", \"sentence_prediction\"]))\n",
    "print()\n",
    "different_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efee958",
   "metadata": {},
   "source": [
    "# Wikidata Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c4f4561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>cause_origin</th>\n",
       "      <th>effect_origin</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>discriminative_weight-encyclopedia-(1, 1)-2-arithmetic_mean-60-medical</th>\n",
       "      <th>medical_score-cause-discriminative_weight-encyclopedia-(1, 1)-2</th>\n",
       "      <th>medical_score-effect-discriminative_weight-encyclopedia-(1, 1)-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8870</th>\n",
       "      <td>influenza virus</td>\n",
       "      <td>acute viral respiratory tract infection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>59.648677</td>\n",
       "      <td>90.764568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cause                                   effect cause_origin  \\\n",
       "8870  influenza virus  acute viral respiratory tract infection          NaN   \n",
       "\n",
       "     effect_origin  evaluation  \\\n",
       "8870   wd:Q7189713           0   \n",
       "\n",
       "      discriminative_weight-encyclopedia-(1, 1)-2-arithmetic_mean-60-medical  \\\n",
       "8870                                               True                        \n",
       "\n",
       "      medical_score-cause-discriminative_weight-encyclopedia-(1, 1)-2  \\\n",
       "8870                                          59.648677                 \n",
       "\n",
       "      medical_score-effect-discriminative_weight-encyclopedia-(1, 1)-2  \n",
       "8870                                          90.764568                 "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_causenet_errors.loc[health_causenet_errors.cause == \"influenza virus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0b9f38f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence & 2.99 & pain & 110.18 \\\\\n",
      "absinthe & 15.01 & absinthism & 102.56 \\\\\n",
      "influenza virus & 59.65 & acute viral respiratory tract infection & 90.76 \\\\\n",
      "pathogen transmission & 16.11 & infection & 125.95 \\\\\n",
      "antigen & 72.94 & antibody & 88.75 \\\\\n",
      "orthocresol & 97.87 & O-Cresol exposure & 45.40 \\\\\n",
      "Enterobius vermicularis & 22.09 & enterobiasis & 140.73 \\\\\n",
      "electroencephalograph & 74.95 & electroencephalogram & 90.74 \\\\\n",
      "postterm pregnancy & 66.61 & postmature infant & 124.94 \\\\\n",
      "fungus & 55.31 & acute respiratory tract infection & 97.15 \\\\\n"
     ]
    }
   ],
   "source": [
    "pprint(health_causenet_errors.iloc[:, [0, -2, 1, -1]].values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efe6c170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>cause_origin</th>\n",
       "      <th>effect_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>Chernobyl disaster</td>\n",
       "      <td>The Elephant's Foot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>1518 Smallpox Epidemic in the Caribbean</td>\n",
       "      <td>death</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q2996394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>influenza</td>\n",
       "      <td>2017–18 United States flu season</td>\n",
       "      <td>wd:Q2996394|wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>mercury</td>\n",
       "      <td>Niigata Minamata disease</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>mercury</td>\n",
       "      <td>Minamata disease</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q2996394|wd:Q7189713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12571</th>\n",
       "      <td>screen time</td>\n",
       "      <td>effect of computers on sleep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>ciguatoxins</td>\n",
       "      <td>Ciguatera</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692</th>\n",
       "      <td>industrial disaster</td>\n",
       "      <td>2020 Norilsk oil spill</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12758</th>\n",
       "      <td>laboratory accident</td>\n",
       "      <td>Lanzhou Brucellosis outbreak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>oxidizing agent</td>\n",
       "      <td>oxidation</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cause  \\\n",
       "4029                        Chernobyl disaster   \n",
       "4104   1518 Smallpox Epidemic in the Caribbean   \n",
       "4199                                 influenza   \n",
       "4224                                   mercury   \n",
       "4232                                   mercury   \n",
       "...                                        ...   \n",
       "12571                              screen time   \n",
       "12597                              ciguatoxins   \n",
       "12692                      industrial disaster   \n",
       "12758                      laboratory accident   \n",
       "12832                          oxidizing agent   \n",
       "\n",
       "                                 effect             cause_origin  \\\n",
       "4029                The Elephant's Foot                      NaN   \n",
       "4104                              death             wd:Q87075524   \n",
       "4199   2017–18 United States flu season  wd:Q2996394|wd:Q7189713   \n",
       "4224           Niigata Minamata disease             wd:Q87075524   \n",
       "4232                   Minamata disease             wd:Q87075524   \n",
       "...                                 ...                      ...   \n",
       "12571      effect of computers on sleep                      NaN   \n",
       "12597                         Ciguatera             wd:Q87075524   \n",
       "12692            2020 Norilsk oil spill             wd:Q87075524   \n",
       "12758      Lanzhou Brucellosis outbreak                      NaN   \n",
       "12832                         oxidation             wd:Q87075524   \n",
       "\n",
       "                 effect_origin  \n",
       "4029              wd:Q87075524  \n",
       "4104               wd:Q2996394  \n",
       "4199              wd:Q87075524  \n",
       "4224               wd:Q7189713  \n",
       "4232   wd:Q2996394|wd:Q7189713  \n",
       "...                        ...  \n",
       "12571             wd:Q87075524  \n",
       "12597              wd:Q7189713  \n",
       "12692                      NaN  \n",
       "12758             wd:Q87075524  \n",
       "12832                      NaN  \n",
       "\n",
       "[285 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_causenet.loc[\n",
    "    (test_causenet.cause_origin == \"wd:Q87075524\")\n",
    "    | (test_causenet.effect_origin == \"wd:Q87075524\"),\n",
    "    [\"cause\", \"effect\", \"cause_origin\", \"effect_origin\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "56b2c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cause</th>\n",
       "      <th>effect</th>\n",
       "      <th>cause_origin</th>\n",
       "      <th>effect_origin</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>discriminative_weight-encyclopedia-(1, 1)-2-quadratic_mean-70-medical</th>\n",
       "      <th>medical_score-cause-discriminative_weight-encyclopedia-(1, 1)-2</th>\n",
       "      <th>medical_score-effect-discriminative_weight-encyclopedia-(1, 1)-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12242</th>\n",
       "      <td>industrial fire</td>\n",
       "      <td>2020 Beirut explosions</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.641798</td>\n",
       "      <td>1.351716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>cyhexatin</td>\n",
       "      <td>Cyhexatin exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.403617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>police brutality in the United States</td>\n",
       "      <td>police abolition movement</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.945855</td>\n",
       "      <td>9.824162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>cholera</td>\n",
       "      <td>fourth cholera pandemic</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>25.354130</td>\n",
       "      <td>14.766918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>Rickettsia prowazekii</td>\n",
       "      <td>Romanian typhus outbreak during WWI</td>\n",
       "      <td>wd:Q39833</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>36.778013</td>\n",
       "      <td>32.138526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>irritant</td>\n",
       "      <td>irritation</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>57.799507</td>\n",
       "      <td>105.716477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>flood</td>\n",
       "      <td>Aberfan disaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.888599</td>\n",
       "      <td>2.801296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9617</th>\n",
       "      <td>ethylene glycol monomethyl ether</td>\n",
       "      <td>2-Methoxyethanol exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>39.504633</td>\n",
       "      <td>45.403617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8423</th>\n",
       "      <td>methyl isocyanate</td>\n",
       "      <td>methyl isocyanate allergic asthma</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>20.435050</td>\n",
       "      <td>74.366094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>reproductive toxicant</td>\n",
       "      <td>reproductive system disease</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>29.215627</td>\n",
       "      <td>58.717142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>cholera</td>\n",
       "      <td>1853 Stockholm cholera outbreak</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>25.354130</td>\n",
       "      <td>13.544932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>poisonous mushroom</td>\n",
       "      <td>mushroom poisoning</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q5850078|wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>41.073742</td>\n",
       "      <td>64.914913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11361</th>\n",
       "      <td>Xylella fastidiosa</td>\n",
       "      <td>2013–20 olive quick decline syndrome outbreak</td>\n",
       "      <td>wd:Q39833</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7.169206</td>\n",
       "      <td>41.998405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>FluBot</td>\n",
       "      <td>phishing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.491997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10488</th>\n",
       "      <td>methoxyethanol acetate</td>\n",
       "      <td>Methyl Cellosolve acetate exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>14.879946</td>\n",
       "      <td>33.785361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>mass hysteria</td>\n",
       "      <td>1983 West Bank fainting epidemic</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>14.829538</td>\n",
       "      <td>67.918259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>bubonic plague</td>\n",
       "      <td>2017 Madagascar plague outbreak</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>24.874660</td>\n",
       "      <td>13.092369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>methanol</td>\n",
       "      <td>2012 Czech Republic methanol poisonings</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q5850078|wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>38.740144</td>\n",
       "      <td>24.191212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10778</th>\n",
       "      <td>HN-1</td>\n",
       "      <td>HN1 exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.403617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>1518 Smallpox Epidemic in the Caribbean</td>\n",
       "      <td>death</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.944071</td>\n",
       "      <td>11.304299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>coal dust</td>\n",
       "      <td>coal dust explosion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18.138690</td>\n",
       "      <td>14.821982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>ethylene glycol</td>\n",
       "      <td>ethylene glycol exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>54.744966</td>\n",
       "      <td>58.071793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>p-dinitrobenzene</td>\n",
       "      <td>1,4-dinitrobenzene exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.403617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>plague</td>\n",
       "      <td>Black Death in England</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>24.384659</td>\n",
       "      <td>2.286154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>list of books burned in 1933</td>\n",
       "      <td>persecution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.614743</td>\n",
       "      <td>0.465216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11234</th>\n",
       "      <td>occupational hazard</td>\n",
       "      <td>occupational cardiovascular disease</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26.351091</td>\n",
       "      <td>64.047240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8400</th>\n",
       "      <td>sodium fluoroacetate</td>\n",
       "      <td>sodium fluoroacetate exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>48.372761</td>\n",
       "      <td>54.168949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>influenza</td>\n",
       "      <td>epidemic</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>58.293501</td>\n",
       "      <td>22.494298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>pandemic H1N1/09 virus</td>\n",
       "      <td>2009 Flu pandemic in Mexico</td>\n",
       "      <td>wd:Q39833|wd:Q2826767|wd:Q5850078</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>35.250625</td>\n",
       "      <td>2.487114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>Zika virus</td>\n",
       "      <td>2015–16 Zika virus epidemic</td>\n",
       "      <td>wd:Q39833|wd:Q2826767|wd:Q5850078</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>43.114946</td>\n",
       "      <td>32.495348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>2016 Turkish coup d'état attempt</td>\n",
       "      <td>Purges in Turkey 2016/17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.069758</td>\n",
       "      <td>2.286154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>water-reactive substance</td>\n",
       "      <td>chemical hazard</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>47.250784</td>\n",
       "      <td>20.121838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8188</th>\n",
       "      <td>tetrodotoxin</td>\n",
       "      <td>tetrodotoxin poisoning</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q5850078|wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>16.719291</td>\n",
       "      <td>65.928993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10551</th>\n",
       "      <td>police brutality</td>\n",
       "      <td>George Floyd protests in Ohio</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.177539</td>\n",
       "      <td>2.044818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>tear gas</td>\n",
       "      <td>bleeding</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>36.368307</td>\n",
       "      <td>137.648458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>pandemic H1N1/09 virus</td>\n",
       "      <td>2009 flu pandemic in North America</td>\n",
       "      <td>wd:Q39833|wd:Q2826767|wd:Q5850078</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>35.250625</td>\n",
       "      <td>31.674858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956</th>\n",
       "      <td>food adulteration</td>\n",
       "      <td>adulterated food</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>21.899387</td>\n",
       "      <td>22.574080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>strychnine</td>\n",
       "      <td>strychnine poisoning</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q5850078|wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>14.018833</td>\n",
       "      <td>65.613479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>hexane</td>\n",
       "      <td>n-hexane exposure</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>wd:Q7189713</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10.066463</td>\n",
       "      <td>68.362964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>Rohingya genocide</td>\n",
       "      <td>refugee crisis</td>\n",
       "      <td>wd:Q87075524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.226647</td>\n",
       "      <td>4.763179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cause  \\\n",
       "12242                          industrial fire   \n",
       "8175                                 cyhexatin   \n",
       "12222    police brutality in the United States   \n",
       "5122                                   cholera   \n",
       "9689                     Rickettsia prowazekii   \n",
       "4654                                  irritant   \n",
       "4566                                     flood   \n",
       "9617          ethylene glycol monomethyl ether   \n",
       "8423                         methyl isocyanate   \n",
       "9461                     reproductive toxicant   \n",
       "4723                                   cholera   \n",
       "6851                        poisonous mushroom   \n",
       "11361                       Xylella fastidiosa   \n",
       "4833                                    FluBot   \n",
       "10488                   methoxyethanol acetate   \n",
       "6140                             mass hysteria   \n",
       "7549                            bubonic plague   \n",
       "4684                                  methanol   \n",
       "10778                                     HN-1   \n",
       "4104   1518 Smallpox Epidemic in the Caribbean   \n",
       "8113                                 coal dust   \n",
       "7508                           ethylene glycol   \n",
       "10453                         p-dinitrobenzene   \n",
       "5765                                    plague   \n",
       "6892              list of books burned in 1933   \n",
       "11234                      occupational hazard   \n",
       "8400                      sodium fluoroacetate   \n",
       "4657                                 influenza   \n",
       "9901                    pandemic H1N1/09 virus   \n",
       "7513                                Zika virus   \n",
       "10832         2016 Turkish coup d'état attempt   \n",
       "10113                 water-reactive substance   \n",
       "8188                              tetrodotoxin   \n",
       "10551                         police brutality   \n",
       "4957                                  tear gas   \n",
       "9883                    pandemic H1N1/09 virus   \n",
       "8956                         food adulteration   \n",
       "7477                                strychnine   \n",
       "6025                                    hexane   \n",
       "7673                         Rohingya genocide   \n",
       "\n",
       "                                              effect  \\\n",
       "12242                         2020 Beirut explosions   \n",
       "8175                              Cyhexatin exposure   \n",
       "12222                      police abolition movement   \n",
       "5122                         fourth cholera pandemic   \n",
       "9689             Romanian typhus outbreak during WWI   \n",
       "4654                                      irritation   \n",
       "4566                                Aberfan disaster   \n",
       "9617                       2-Methoxyethanol exposure   \n",
       "8423               methyl isocyanate allergic asthma   \n",
       "9461                     reproductive system disease   \n",
       "4723                 1853 Stockholm cholera outbreak   \n",
       "6851                              mushroom poisoning   \n",
       "11361  2013–20 olive quick decline syndrome outbreak   \n",
       "4833                                        phishing   \n",
       "10488             Methyl Cellosolve acetate exposure   \n",
       "6140                1983 West Bank fainting epidemic   \n",
       "7549                 2017 Madagascar plague outbreak   \n",
       "4684         2012 Czech Republic methanol poisonings   \n",
       "10778                                   HN1 exposure   \n",
       "4104                                           death   \n",
       "8113                             coal dust explosion   \n",
       "7508                        ethylene glycol exposure   \n",
       "10453                    1,4-dinitrobenzene exposure   \n",
       "5765                          Black Death in England   \n",
       "6892                                     persecution   \n",
       "11234            occupational cardiovascular disease   \n",
       "8400                   sodium fluoroacetate exposure   \n",
       "4657                                        epidemic   \n",
       "9901                     2009 Flu pandemic in Mexico   \n",
       "7513                     2015–16 Zika virus epidemic   \n",
       "10832                       Purges in Turkey 2016/17   \n",
       "10113                                chemical hazard   \n",
       "8188                          tetrodotoxin poisoning   \n",
       "10551                  George Floyd protests in Ohio   \n",
       "4957                                        bleeding   \n",
       "9883              2009 flu pandemic in North America   \n",
       "8956                                adulterated food   \n",
       "7477                            strychnine poisoning   \n",
       "6025                               n-hexane exposure   \n",
       "7673                                  refugee crisis   \n",
       "\n",
       "                            cause_origin            effect_origin  evaluation  \\\n",
       "12242                       wd:Q87075524             wd:Q87075524           1   \n",
       "8175                        wd:Q87075524              wd:Q7189713           1   \n",
       "12222                       wd:Q87075524                      NaN           0   \n",
       "5122                         wd:Q7189713             wd:Q87075524           1   \n",
       "9689                           wd:Q39833             wd:Q87075524           1   \n",
       "4654                        wd:Q87075524              wd:Q7189713           1   \n",
       "4566                                 NaN             wd:Q87075524           0   \n",
       "9617                        wd:Q87075524              wd:Q7189713           1   \n",
       "8423                        wd:Q87075524              wd:Q7189713           1   \n",
       "9461                        wd:Q87075524              wd:Q7189713           1   \n",
       "4723                         wd:Q7189713             wd:Q87075524           1   \n",
       "6851                        wd:Q87075524  wd:Q5850078|wd:Q7189713           1   \n",
       "11361                          wd:Q39833             wd:Q87075524           1   \n",
       "4833                                 NaN             wd:Q87075524           0   \n",
       "10488                       wd:Q87075524              wd:Q7189713           1   \n",
       "6140                         wd:Q7189713             wd:Q87075524           1   \n",
       "7549                         wd:Q7189713             wd:Q87075524           1   \n",
       "4684                        wd:Q87075524  wd:Q5850078|wd:Q7189713           1   \n",
       "10778                       wd:Q87075524              wd:Q7189713           1   \n",
       "4104                        wd:Q87075524                      NaN           0   \n",
       "8113                                 NaN             wd:Q87075524           0   \n",
       "7508                        wd:Q87075524              wd:Q7189713           1   \n",
       "10453                       wd:Q87075524              wd:Q7189713           1   \n",
       "5765                         wd:Q7189713             wd:Q87075524           1   \n",
       "6892                                 NaN             wd:Q87075524           0   \n",
       "11234                       wd:Q87075524              wd:Q7189713           1   \n",
       "8400                        wd:Q87075524              wd:Q7189713           1   \n",
       "4657                         wd:Q7189713             wd:Q87075524           1   \n",
       "9901   wd:Q39833|wd:Q2826767|wd:Q5850078             wd:Q87075524           1   \n",
       "7513   wd:Q39833|wd:Q2826767|wd:Q5850078             wd:Q87075524           1   \n",
       "10832                                NaN             wd:Q87075524           0   \n",
       "10113                       wd:Q87075524                      NaN           0   \n",
       "8188                        wd:Q87075524  wd:Q5850078|wd:Q7189713           1   \n",
       "10551                       wd:Q87075524                      NaN           0   \n",
       "4957                        wd:Q87075524              wd:Q7189713           1   \n",
       "9883   wd:Q39833|wd:Q2826767|wd:Q5850078             wd:Q87075524           1   \n",
       "8956                        wd:Q87075524                      NaN           0   \n",
       "7477                        wd:Q87075524  wd:Q5850078|wd:Q7189713           1   \n",
       "6025                        wd:Q87075524              wd:Q7189713           1   \n",
       "7673                        wd:Q87075524                      NaN           0   \n",
       "\n",
       "       discriminative_weight-encyclopedia-(1, 1)-2-quadratic_mean-70-medical  \\\n",
       "12242                                              False                       \n",
       "8175                                               False                       \n",
       "12222                                              False                       \n",
       "5122                                               False                       \n",
       "9689                                               False                       \n",
       "4654                                                True                       \n",
       "4566                                               False                       \n",
       "9617                                               False                       \n",
       "8423                                               False                       \n",
       "9461                                               False                       \n",
       "4723                                               False                       \n",
       "6851                                               False                       \n",
       "11361                                              False                       \n",
       "4833                                               False                       \n",
       "10488                                              False                       \n",
       "6140                                               False                       \n",
       "7549                                               False                       \n",
       "4684                                               False                       \n",
       "10778                                              False                       \n",
       "4104                                               False                       \n",
       "8113                                               False                       \n",
       "7508                                               False                       \n",
       "10453                                              False                       \n",
       "5765                                               False                       \n",
       "6892                                               False                       \n",
       "11234                                              False                       \n",
       "8400                                               False                       \n",
       "4657                                               False                       \n",
       "9901                                               False                       \n",
       "7513                                               False                       \n",
       "10832                                              False                       \n",
       "10113                                              False                       \n",
       "8188                                               False                       \n",
       "10551                                              False                       \n",
       "4957                                                True                       \n",
       "9883                                               False                       \n",
       "8956                                               False                       \n",
       "7477                                               False                       \n",
       "6025                                               False                       \n",
       "7673                                               False                       \n",
       "\n",
       "       medical_score-cause-discriminative_weight-encyclopedia-(1, 1)-2  \\\n",
       "12242                                           1.641798                 \n",
       "8175                                            0.000000                 \n",
       "12222                                           2.945855                 \n",
       "5122                                           25.354130                 \n",
       "9689                                           36.778013                 \n",
       "4654                                           57.799507                 \n",
       "4566                                            0.888599                 \n",
       "9617                                           39.504633                 \n",
       "8423                                           20.435050                 \n",
       "9461                                           29.215627                 \n",
       "4723                                           25.354130                 \n",
       "6851                                           41.073742                 \n",
       "11361                                           7.169206                 \n",
       "4833                                            0.000000                 \n",
       "10488                                          14.879946                 \n",
       "6140                                           14.829538                 \n",
       "7549                                           24.874660                 \n",
       "4684                                           38.740144                 \n",
       "10778                                           0.000000                 \n",
       "4104                                            2.944071                 \n",
       "8113                                           18.138690                 \n",
       "7508                                           54.744966                 \n",
       "10453                                           0.000000                 \n",
       "5765                                           24.384659                 \n",
       "6892                                            5.614743                 \n",
       "11234                                          26.351091                 \n",
       "8400                                           48.372761                 \n",
       "4657                                           58.293501                 \n",
       "9901                                           35.250625                 \n",
       "7513                                           43.114946                 \n",
       "10832                                           2.069758                 \n",
       "10113                                          47.250784                 \n",
       "8188                                           16.719291                 \n",
       "10551                                           0.177539                 \n",
       "4957                                           36.368307                 \n",
       "9883                                           35.250625                 \n",
       "8956                                           21.899387                 \n",
       "7477                                           14.018833                 \n",
       "6025                                           10.066463                 \n",
       "7673                                            0.226647                 \n",
       "\n",
       "       medical_score-effect-discriminative_weight-encyclopedia-(1, 1)-2  \n",
       "12242                                           1.351716                 \n",
       "8175                                           45.403617                 \n",
       "12222                                           9.824162                 \n",
       "5122                                           14.766918                 \n",
       "9689                                           32.138526                 \n",
       "4654                                          105.716477                 \n",
       "4566                                            2.801296                 \n",
       "9617                                           45.403617                 \n",
       "8423                                           74.366094                 \n",
       "9461                                           58.717142                 \n",
       "4723                                           13.544932                 \n",
       "6851                                           64.914913                 \n",
       "11361                                          41.998405                 \n",
       "4833                                            1.491997                 \n",
       "10488                                          33.785361                 \n",
       "6140                                           67.918259                 \n",
       "7549                                           13.092369                 \n",
       "4684                                           24.191212                 \n",
       "10778                                          45.403617                 \n",
       "4104                                           11.304299                 \n",
       "8113                                           14.821982                 \n",
       "7508                                           58.071793                 \n",
       "10453                                          45.403617                 \n",
       "5765                                            2.286154                 \n",
       "6892                                            0.465216                 \n",
       "11234                                          64.047240                 \n",
       "8400                                           54.168949                 \n",
       "4657                                           22.494298                 \n",
       "9901                                            2.487114                 \n",
       "7513                                           32.495348                 \n",
       "10832                                           2.286154                 \n",
       "10113                                          20.121838                 \n",
       "8188                                           65.928993                 \n",
       "10551                                           2.044818                 \n",
       "4957                                          137.648458                 \n",
       "9883                                           31.674858                 \n",
       "8956                                           22.574080                 \n",
       "7477                                           65.613479                 \n",
       "6025                                           68.362964                 \n",
       "7673                                            4.763179                 "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which origins are exclusive\n",
    "health_causenet_errors.loc[\n",
    "    (health_causenet_errors.cause_origin == \"wd:Q87075524\")\n",
    "    | (health_causenet_errors.effect_origin == \"wd:Q87075524\")\n",
    "].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a820bb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wd:Q87075524</th>\n",
       "      <td>668</td>\n",
       "      <td>78</td>\n",
       "      <td>0.104558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q39833</th>\n",
       "      <td>815</td>\n",
       "      <td>128</td>\n",
       "      <td>0.135737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q5850078</th>\n",
       "      <td>959</td>\n",
       "      <td>158</td>\n",
       "      <td>0.141450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q2826767</th>\n",
       "      <td>495</td>\n",
       "      <td>85</td>\n",
       "      <td>0.146552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q289472</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q86746756</th>\n",
       "      <td>225</td>\n",
       "      <td>57</td>\n",
       "      <td>0.202128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q15788410</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q796194</th>\n",
       "      <td>57</td>\n",
       "      <td>40</td>\n",
       "      <td>0.412371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q2996394</th>\n",
       "      <td>1230</td>\n",
       "      <td>943</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd:Q7189713</th>\n",
       "      <td>1021</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.512183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label           fn    tp      perc\n",
       "origin                            \n",
       "wd:Q87075524   668    78  0.104558\n",
       "wd:Q39833      815   128  0.135737\n",
       "wd:Q5850078    959   158  0.141450\n",
       "wd:Q2826767    495    85  0.146552\n",
       "wd:Q289472      20     4  0.166667\n",
       "wd:Q86746756   225    57  0.202128\n",
       "wd:Q15788410     6     3  0.333333\n",
       "wd:Q796194      57    40  0.412371\n",
       "wd:Q2996394   1230   943  0.433962\n",
       "wd:Q7189713   1021  1072  0.512183"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = health_causenet_errors.iloc[:, 5]\n",
    "fn = ~health_causenet_errors.iloc[:, 5]\n",
    "error_origin = (\n",
    "    test_wikidata.set_index([\"cause\", \"effect\"])\n",
    "    .loc[\n",
    "        health_causenet_errors.set_index([\"cause\", \"effect\"]).index,\n",
    "        [\"cause_origin\", \"effect_origin\"],\n",
    "    ]\n",
    "    .reset_index()\n",
    ")\n",
    "error_origin[\"label\"] = \"tp\"\n",
    "error_origin.loc[fn.values, \"label\"] = \"fn\"\n",
    "error_cause_origin = (\n",
    "    error_origin.set_index([\"label\", \"cause\"])\n",
    "    .cause_origin.str.split(\"|\", expand=True)\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .drop(\"level_2\", axis=1)\n",
    "    .drop_duplicates()\n",
    "    .rename({0: \"origin\"}, axis=1)\n",
    ")\n",
    "error_effect_origin = (\n",
    "    error_origin.set_index([\"label\", \"effect\"])\n",
    "    .cause_origin.str.split(\"|\", expand=True)\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .drop(\"level_2\", axis=1)\n",
    "    .drop_duplicates()\n",
    "    .rename({0: \"origin\"}, axis=1)\n",
    ")\n",
    "origin_value_counts = (\n",
    "    error_cause_origin.groupby(\"label\").origin.value_counts()\n",
    "    + error_effect_origin.groupby(\"label\").origin.value_counts()\n",
    ").unstack(0)\n",
    "origin_value_counts[\"perc\"] = origin_value_counts.tp / origin_value_counts.sum(axis=1)\n",
    "origin_value_counts.sort_values(\"perc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
